[
  {
    "objectID": "posts/7-2.합성곱신경망(CNN핵심레이어,CNN의학습원리,FashionMNIST).html",
    "href": "posts/7-2.합성곱신경망(CNN핵심레이어,CNN의학습원리,FashionMNIST).html",
    "title": "7-2. 합성곱신경망(CNN 핵심 레이어, CNN의 학습원리, FashionMNIST)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport torchvision\nimport matplotlib.pyplot as plt\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. CNN 핵심 레이어\n\nA. torch.nn.ReLU\n\n\nB. torch.nn.MaxPool2d\n\n\nC. torch.nn.Conv2d\n\nNote\n입력이 1장의 흑백이미지이고 출력도 1장의 흑백이미지일 경우 컨볼루션 계산과정 요약[1]\n\n윈도우생성: kernel_size = (?,?) 인 윈도우를 만듦\nsub-img생성: 입력 이미지에 윈도우를 통과시켜 (?,?) 크기의 sub-img를 만듦.\n연산: sub-img의 각 원소에 conv.weight의 값을 원소별로 (=element-wisely) 곱하고 결과를 더함. (만약에 conv.bias가 있다면 최종결과에 bias를 더함)\n이동&반복: 윈도우를 stride 만큼 이동하여 반복. (stride=1 이라면 한칸씩, stride=2 라면 두칸씩 이동)\n\n\n- (예시1) 재현\n“A guide to convolution arithmetic for deep learning” (Dumoulin and Visin 2016) 에 나온 그림재현\n\nref: https://arxiv.org/abs/1603.07285\n\n\n\n\nFig: conv2d 계산과정시각화\n\n\n[1] 입력shape=(1,1,?,?) 이고 출력의shape=(1,1,?,?)일 경우\n\nimg = torch.tensor([\n    [3,3,2,1,0],\n    [0,0,1,3,1],\n    [3,1,2,2,3],\n    [2,0,0,2,2],\n    [2,0,0,0,1]\n]).reshape(1,1,5,5).float()\nimg\n\ntensor([[[[3., 3., 2., 1., 0.],\n          [0., 0., 1., 3., 1.],\n          [3., 1., 2., 2., 3.],\n          [2., 0., 0., 2., 2.],\n          [2., 0., 0., 0., 1.]]]])\n\n\n\nconv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,bias=False)\nconv.weight.data = torch.tensor([[[\n    [ 0.0, 1.0, 2.0],\n    [ 2.0, 2.0, 0.0],\n    [ 0.0, 1.0, 2.0]\n]]])\n\n\nconv(img)\n\ntensor([[[[12., 12., 17.],\n          [10., 17., 19.],\n          [ 9.,  6., 14.]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n- (예시2) 이동평균\n\nimg = torch.arange(1,17).float().reshape(1,1,4,4)\nimg\n\ntensor([[[[ 1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.]]]])\n\n\n\nconv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=1,bias=False)\nconv.weight.data = conv.weight.data*0 + 1/4\nconv.weight.data\n\ntensor([[[[0.2500, 0.2500],\n          [0.2500, 0.2500]]]])\n\n\n\nconv(img)\n\ntensor([[[[ 3.5000,  4.5000,  5.5000],\n          [ 7.5000,  8.5000,  9.5000],\n          [11.5000, 12.5000, 13.5000]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n- (예시3) 2개의 이미지\n\n개념: (1,1,?,?) \\(\\to\\) (1,1,?,?) 의 conv를 observation 별로 적용\nconv 에 포함된 파라메터 수는 (1,1,?,?) \\(\\to\\) (1,1,?,?) 인 경우와 (n,1,?,?) \\(\\to\\) (n,1,?,?)인 경우가 동일\n\n\nimgs = torch.arange(1,33).float().reshape(2,1,4,4)\nconv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=1,bias=False)\nconv.weight.data = conv.weight.data*0 + 1/4\n\n\nimgs\n\ntensor([[[[ 1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.]]],\n\n\n        [[[17., 18., 19., 20.],\n          [21., 22., 23., 24.],\n          [25., 26., 27., 28.],\n          [29., 30., 31., 32.]]]])\n\n\n\nconv(imgs)\n\ntensor([[[[ 3.5000,  4.5000,  5.5000],\n          [ 7.5000,  8.5000,  9.5000],\n          [11.5000, 12.5000, 13.5000]]],\n\n\n        [[[19.5000, 20.5000, 21.5000],\n          [23.5000, 24.5000, 25.5000],\n          [27.5000, 28.5000, 29.5000]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n\nconv.weight.shape\n\ntorch.Size([1, 1, 2, 2])\n\n\n- (예시4) 2개의 이미지, 2개의 out_channels\n\n개념: (1,1,?,?) \\(\\to\\) (1,1,?,?) 의 conv를 한번 적용, 그것과 별개로 (1,1,?,?) \\(\\to\\) (1,1,?,?) 인 다른 conv를 적용함. (즉 하나의 observation당 2번 conv변환) 이것을 observation별로 반복\n(1,1,?,?) \\(\\to\\) (1,2,?,?) 인 경우는 (1,1,?,?) \\(\\to\\) (1,1,?,?)인 경우보다 conv에 포함된 파라메터 수가 2배 많음\n그런데 (1,1,?,?) \\(\\to\\) (1,2,?,?) 인 경우와 (n,1,?,?) \\(\\to\\) (n,2,?,?)인 경우는 conv에 포함된 파라메터 수가 같음.\n따라서 (n,1,?,?) \\(\\to\\) (n,2,?,?) 인 경우는 (1,1,?,?) \\(\\to\\) (1,1,?,?)인 경우보다 conv에 포함된 파라메터 수가 2배 많음\n\n\nimg = torch.arange(1,33).float().reshape(2,1,4,4)\nconv = torch.nn.Conv2d(in_channels=1,out_channels=2,kernel_size=2,stride=1,bias=False)\n\n\nimg\n\ntensor([[[[ 1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.]]],\n\n\n        [[[17., 18., 19., 20.],\n          [21., 22., 23., 24.],\n          [25., 26., 27., 28.],\n          [29., 30., 31., 32.]]]])\n\n\n\nconv.weight.data[0] = conv.weight.data[0]*0 +1/4\nconv.weight.data[1] = conv.weight.data[0]*0\n\n\nconv(img)\n\ntensor([[[[ 3.5000,  4.5000,  5.5000],\n          [ 7.5000,  8.5000,  9.5000],\n          [11.5000, 12.5000, 13.5000]],\n\n         [[ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000]]],\n\n\n        [[[19.5000, 20.5000, 21.5000],\n          [23.5000, 24.5000, 25.5000],\n          [27.5000, 28.5000, 29.5000]],\n\n         [[ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n\nconv(img)\n\ntensor([[[[ 3.5000,  4.5000,  5.5000],\n          [ 7.5000,  8.5000,  9.5000],\n          [11.5000, 12.5000, 13.5000]],\n\n         [[ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000]]],\n\n\n        [[[19.5000, 20.5000, 21.5000],\n          [23.5000, 24.5000, 25.5000],\n          [27.5000, 28.5000, 29.5000]],\n\n         [[ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n\n\n\n4. CNN의 학습원리\n\nA. data\n- 아래의 4개의 이미지\n\nimg0 = torch.tensor([\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n]).reshape(1, 1, 16, 16) \nimg1 = 0.1-torch.einsum('nchw-&gt;ncwh', img0.clone())\nimg2 = torch.zeros((1, 1, 16, 16))\nfor i in range(16):\n    for j in range(16):\n        if j &lt;= i:  # 대각선 아래 삼각형\n            img2[0, 0, i, j] = 0.1\n# 빈 이미지\nimg3 = torch.zeros((1, 1, 16, 16))\nblock_size = 2\n# 블록 단위로 채우기\nfor i in range(0, 16, block_size):\n    for j in range(0, 16, block_size):\n        if ((i // block_size) + (j // block_size)) % 2 == 0:\n            img3[0, 0, i:i+block_size, j:j+block_size] = 0.1\n\n- squeeze() 차원이 1인 것을 없애줌\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(img0.squeeze(),cmap=\"gray\")\naxs[0][1].imshow(img1.squeeze(),cmap=\"gray\")\naxs[1][0].imshow(img2.squeeze(),cmap=\"gray\")\naxs[1][1].imshow(img3.squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nimgs = torch.concat([img0,img1,img2,img3],axis=0)\nimgs.shape\n\ntorch.Size([4, 1, 16, 16])\n\n\n\n\nB. vertical edge\n\nv_conv = torch.nn.Conv2d(\n    in_channels=1,\n    out_channels=1,\n    kernel_size=4,\n    bias=False\n)\n\n\nv_conv.weight.data = torch.tensor([[[\n    [ 0, 0, 0, 0],\n    [ 0, 1.0, -1.0, 0],\n    [0, 1.0, -1.0, 0],\n    [ 0, 0, 0, 0]\n]]])\n\n- v_conv는 좌우방향의 펙셀 변화, 즉 수직 방향의 엣지를 감지하는데 적절\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(v_conv(imgs)[0].squeeze().data,cmap=\"gray\")\naxs[0][1].imshow(v_conv(imgs)[1].squeeze().data,cmap=\"gray\")\naxs[1][0].imshow(v_conv(imgs)[2].squeeze().data,cmap=\"gray\")\naxs[1][1].imshow(v_conv(imgs)[3].squeeze().data,cmap=\"gray\")\n\n\n\n\n\n\n\n\n\n\nC. horizontal edge\n\nh_conv = torch.nn.Conv2d(\n    in_channels=1,\n    out_channels=1,\n    kernel_size=4,\n    bias=False\n)\n\n\nh_conv.weight.data = torch.tensor([[[\n    [ 0, 0, 0, 0],\n    [ 0, -1.0, -1.0, 0],\n    [0, 1.0, 1.0, 0],\n    [ 0, 0, 0, 0]\n]]])\n\n- h_conv는 위아래 방향의 픽셀 변화, 즉 수평 방향의 엣지를 감지하는데 적절\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(h_conv(imgs)[0].squeeze().data,cmap=\"gray\")\naxs[0][1].imshow(h_conv(imgs)[1].squeeze().data,cmap=\"gray\")\naxs[1][0].imshow(h_conv(imgs)[2].squeeze().data,cmap=\"gray\")\naxs[1][1].imshow(h_conv(imgs)[3].squeeze().data,cmap=\"gray\")\n\n\n\n\n\n\n\n\n\n\nD. 이동평균\n\nm_conv = torch.nn.Conv2d(\n    in_channels=1,\n    out_channels=1,\n    kernel_size=4,\n)\nm_conv.weight.data = m_conv.weight.data*0 + 1/16\nm_conv.bias.data = m_conv.bias.data*0 - 0.05\n\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(m_conv(imgs)[0].squeeze().data,cmap=\"gray\")\naxs[0][1].imshow(m_conv(imgs)[1].squeeze().data,cmap=\"gray\")\naxs[1][0].imshow(m_conv(imgs)[2].squeeze().data,cmap=\"gray\")\naxs[1][1].imshow(m_conv(imgs)[3].squeeze().data,cmap=\"gray\")\n\n\n\n\n\n\n\n\n\n\nE. (C,D,E) + relu + mp\n\nrelu = torch.nn.ReLU()\nmp = torch.nn.MaxPool2d(kernel_size=13)\n\n\nmp(relu(v_conv(imgs)))\n\ntensor([[[[0.2000]]],\n\n\n        [[[0.0000]]],\n\n\n        [[[0.1000]]],\n\n\n        [[[0.2000]]]], grad_fn=&lt;MaxPool2DWithIndicesBackward0&gt;)\n\n\n\nmp(relu(h_conv(imgs)))\n\ntensor([[[[0.0000]]],\n\n\n        [[[0.2000]]],\n\n\n        [[[0.1000]]],\n\n\n        [[[0.2000]]]], grad_fn=&lt;MaxPool2DWithIndicesBackward0&gt;)\n\n\n\nmp(relu(m_conv(imgs)))\n\ntensor([[[[5.0000e-02]]],\n\n\n        [[[5.0000e-02]]],\n\n\n        [[[5.0000e-02]]],\n\n\n        [[[9.3132e-10]]]], grad_fn=&lt;MaxPool2DWithIndicesBackward0&gt;)\n\n\n\n\nF. 구조\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1,out_channels=3,kernel_size=4),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=13),\n    torch.nn.Flatten()\n)\nnet[0].weight.data = torch.concat(\n    [v_conv.weight.data,\n     h_conv.weight.data,\n     m_conv.weight.data],axis=0)\nnet[0].bias.data = torch.tensor([0.0,0.0, -0.05])\n\n\nplt.matshow(net(imgs).data,cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nnet(imgs).shape\n\ntorch.Size([4, 3])\n\n\n\n출력은 (n,3)으로 정리되어서 나온다. 이 시점부터는 더 이상 이미지가 입력이라고 생각하지 않아도 되고, 단순히 (n, 3) 크기의 숫자 데이터가 입력으로 주어진 것처럼 보면 된다. 즉 이제부터는 이 (n,3) 데이터를 입력으로 받는 신경망을 설계하면 된다.\n\n\n\n\nG. mp의 역할?\n- 샘플이미지\n\nimg = torch.zeros((1, 1, 16, 16))\ntriangle_size = 4\nfor i in range(triangle_size):\n    for j in range(triangle_size):\n        if j &lt;= i:  # 아래 방향 직각삼각형 (왼쪽 위 꼭짓점 기준)\n            img[0, 0, i, j] = 1.0\n\n\nplt.imshow(img.squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n- mp 1회\n\nmp = torch.nn.MaxPool2d(kernel_size=2)\nplt.imshow(mp(img).squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n- mp 2~4회\n\nmp = torch.nn.MaxPool2d(kernel_size=2)\nplt.imshow(mp(mp(img)).squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nmp = torch.nn.MaxPool2d(kernel_size=2)\nplt.imshow(mp(mp(mp(img))).squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n- maxpooling은 이미지를 “캐리커처화” 한다고 비유할 수 있음. 디테일은 버리고, 중요한 특징만 뽑아서 과장되게 요약한다.\n\n\n4. FashionMNIST\n- CNN\n\n\\(\\to\\) 2d // flatten(conv(특징) - relu(특징추가) - maxpooling(요약))\n\\(\\to\\) 1d // 단순신경망(그냥 펼친걸로 신경망)\n\n- 데이터\n\ntrain_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=False)\ntrain_dataset = torch.utils.data.Subset(train_dataset, range(5000))\nto_tensor = torchvision.transforms.ToTensor()\nX = torch.stack([to_tensor(img) for img, lbl in train_dataset]).to(\"cuda:0\")\ny = torch.tensor([lbl for img, lbl in train_dataset])\ny = torch.nn.functional.one_hot(y).float().to(\"cuda:0\")\n\n- 2d를 처리하고 flatten하는 네트워크\n\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),\n    torch.nn.Flatten()\n).to(\"cuda:0\")\n\n\nnet1(X).shape\n\ntorch.Size([5000, 2304])\n\n\n\n출력은 (n,2304)으로 정리되어서 나온다. 이 시점부터는 더 이상 이미지가 입력이라고 생각하지 않아도 되고, 단순히 (n, 2304) 크기의 숫자 데이터가 입력으로 주어진 것처럼 보면 된다. 즉 이제부터는 이 (n,2304) 데이터를 입력으로 받는 신경망을 설계하면 된다.\n\n- 1d를 처리하는 네트워크\n\nnet2= torch.nn.Sequential(\n    torch.nn.Linear(2304,10),\n).to(\"cuda:0\")\n\n- 두 네트워크를 결합\n\nnet = torch.nn.Sequential(\n    net1,\n    net2\n)\nnet(X).shape\n\ntorch.Size([5000, 10])\n\n\n- 최종적인 코드\n\nnet = torch.nn.Sequential(\n    net1,\n    net2\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr=torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(100):\n    #1\n    netout = net(X)\n    #2\n    loss = loss_fn(netout,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()\n\ntensor(0.8806, device='cuda:0')"
  },
  {
    "objectID": "posts/9-2.생성모형(GenerativeAdversarialNetwork(GAN)).html",
    "href": "posts/9-2.생성모형(GenerativeAdversarialNetwork(GAN)).html",
    "title": "9-1. 생성모형(Generative Adversarial Network(GAN))",
    "section": "",
    "text": "1. imports\n\nimport torch \nimport torchvision\nimport matplotlib.pyplot as plt \n\n\n\n2. GAN(Goodfellow et al. 2014) intro\n\nA. 잡썰..\n- 저자: 이안굿펠로우\n\n천재임\n지도교수가 요수아 벤지오\n\n- 저는 아래의 논문 읽고 소름돋았어요..\n\nhttps://arxiv.org/abs/1406.2661\n\n- 최근 10년간 머신러닝 분야에서 가장 혁신적인 아이디어이다. (얀르쿤, 2014년 시점..)\n- 야사와 만화로 배우는 인공지능\n\nhttps://wedatalab.tistory.com/125\n\n\n\nB. GAN의 원리\n- GAN의 원리는 경찰과 위조지폐범이 서로 선의의(?) 경쟁을 통하여 서로 발전하는 모형으로 설명할 수 있다.\n\nThe generative model can be thought of as analogous to a team of fakers, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency. Competition in this game drives both teams to improve their methods until the counterfeits are indistiguishable from the genuine articles.\n\n- 서로 적대적인(adversarial) 네트워크(network)를 동시에 학습시켜 가짜이미지를 만든다(generate)\n- 무식한 상황극..\n\n위조범: 가짜돈을 만들어서 부자가 되어야지! (가짜돈을 그림)\n경찰: (위조범이 만든 돈을 보고) 이건 가짜다!\n위조범: 걸렸군.. 더 정교하게 만들어야지..\n경찰: (깜빡 속으며) 이건 진짠가?… –&gt; 상사에게 혼남 –&gt; 판별능력 업그레이드 –&gt; 이건 가짜다!!\n위조범: 더 정교하게 만들자..\n경찰: 더 판별능력을 업그레이드 하자!\n반복..\n\n- 굉장히 우수한 경찰조차도 진짜와 가짜를 구분하지 못할때(=진짜 이미지를 0.5의 확률로만 진짜라고 말할때 = 가짜 이미지를 0.5의 확률로만 가짜라고 말할때) 학습을 멈춘다.\n\n\nC. 생성모형이란? (쉬운 설명)\n- 사진속에 들어있는 동물이 개인지 고양이인지 맞출수 있는 기계와 개와 고양이를 그릴수 있는 기계중 어떤것이 더 시각적보에 대한 이해가 깊다고 볼 수 있는가?\n- 진정으로 인공지능이 이미지자료를 이해했다면, 이미지를 만들수도 있어야 한다. \\(\\to\\) 이미지를 생성하는 모형을 만들어보자 \\(\\to\\) 성공\n\n- 뭘 분류하려는 목적을 가진게 판별모형이면 뭘 만들려는 목적을 가진게 생성모형이고 생성모형이 더 우수하다.\n\n명언: 만들수 없다면 이해하지 못한 것이다, 리처드 파인만 (천재 물리학자)\n\n\n\nD. 생성모형이란? 통계학과 버전의 설명\n- 이미지 \\(\\boldsymbol{X}\\) 가 주어졌을 경우 라벨을 \\(y\\) 라고 하자.\n- 이미지를 보고 라벨을 맞추는 일은 \\(p(y| \\boldsymbol{X})\\)에 관심이 있다고 볼 수 있다. – 판별모형\n- 이미지를 생성하는 일은 \\(p(\\boldsymbol{X},y)\\)에 관심이 있는것이다. – 생성모형\n- 데이터의 생성확률 \\(p(\\boldsymbol{X},y)\\)을 알면 클래스의 사후확률 \\(p(y|\\boldsymbol{X})\\)를 알 수 있음. (아래의 수식 참고) 하지만 역은 불가능\n\\[p(y|{\\boldsymbol X}) = \\frac{p({\\boldsymbol X},y)}{p({\\boldsymbol X})} = \\frac{p({\\boldsymbol X},y)}{\\sum_{y}p({\\boldsymbol X},y)}\\]\n\n즉 이미지를 생성하는일은 분류문제보다 더 어려운 일이라 해석가능\n\n\n\nE. 철학의 차이\n\n명언: 제한된 정보만으로 어떤 문제를 풀 때, 그 과정에서 원래의 문제보다 일반적인 문제를 풀지 말고 (=문제를 괜히 어렵게 만들어서 풀지 말고), 가능한 원래의 문제를 직접 풀어야한다. 배프닉 (SVM 창시자)\n\n- 따라서 배프닉의 원리에 의하면 일반적인 분류문제를 해결할때 “판별모형이 생성모형보다 더 바람직한 접근법”이라 할 수 있음. 즉 개와 고양이를 구분할 때, 그려진 개와 고양이 사진을 잘 구분하면 되는 것이지 굳이 개와 고양이를 그릴줄 알아야하는건 아니라는 의미.\n* 예전에는 머신러닝의 응용분야가 “분류/회귀”에 한정된 느낌이었는데 요즘은 생성모형도 인기있음.\n\n마인드가 되게 달라요\n\n\n\n\n4. GAN의 구현\n\nA. Data\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=False)\nto_tensor = torchvision.transforms.ToTensor()\nX_real = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==3])\n\n\nplt.imshow(X_real[0].squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\n\nB. 페이커 생성\n- net_faker : noise \\(\\to\\) 가짜이미지”를 만들자\n- 네트워크의 입력 : (n,??)인 랜덤으로 뽑은 숫자\n\ntorch.randn(1,4) # 이게 입력으로 온다고 상상하자. \n\ntensor([[ 0.3833,  1.4574,  0.6266, -0.1444]])\n\n\n- 네트워크의 출력: (n,1,28,28)의 텐서\n\nclass FlattenToImage(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,X):\n        return X.reshape(-1,1,28,28)\nnet_facker = torch.nn.Sequential(\n    torch.nn.Linear(4,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,784),\n    torch.nn.Sigmoid(), # 출력을 0~1로 눌러주기 위한 레이어 // 저한테는 일종의 문화충격\n    FlattenToImage()\n)\n\n\nnet_facker(torch.randn(1,4)).shape\n\ntorch.Size([1, 1, 28, 28])\n\n\n\n\nC. 경찰 생성\n- net_police : 진짜 이미지 \\(\\to\\) 0 , 가짜 이미지 \\(\\to\\) 1 과 같은 네트워크 설계\n- 네트워크의 입력 : (n,1,28,28) 인 이미지\n- 네트워크의 출력 : 0, 1\n\nnet_police = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,30),\n    torch.nn.ReLU(),\n    torch.nn.Linear(30,1),\n    torch.nn.Sigmoid()\n)\n\n\n\nD. 바보 경찰과 바보 페이커\n- 데이터\n\nreal_image = X_real[[0]]  # 진짜이미지\nfake_image = net_facker(torch.randn(1,4)).data # 가짜이미지\n\n- 경찰 네트워크가 가짜 이미지와, 진짜 이미지를 봤을 때 각각 어떤 판단을 할까\n-진짜 이미지를 봤을 때\n\nnet_police(real_image) # -&gt; 0으로 가야함\n\ntensor([[0.4829]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n- 가짜 이미지를 봤을 떄\n\nnet_police(fake_image) # -&gt; 1로 가야함\n\ntensor([[0.4764]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n- 아직 아쉬운 판단..\n\n\nE. 똑똑해진 경찰\n- 데이터를 정리\n\n원래 \\(n=6131\\)개의 이미지자료가 있었음. 이를 \\({\\bf X}_{real}\\) 로 저장했었음.\n\\({\\bf X}_{fake}\\)는 net_facker의 output으로 생성하고 꼬리표 제거.\n\\({\\bf X}_{real}\\)에 대응하는 \\({\\bf y}_{real}\\) 생성. 진짜이미지는 라벨을 0으로 정함.\n\\({\\bf X}_{faker}\\)에 대응하는 \\({\\bf y}_{fake}\\) 생성. 가짜이미지는 라벨을 1로 정함.\n\n\nX_fake = net_facker(torch.randn(6131,4)).data\ny_real = torch.zeros((6131,1))\ny_fake = torch.ones((6131,1))\n\n- step1: X_real, X_fake를 보고 각각 yhat_real, yhat_fake를 만드는 과정\n\nyhat_real = net_police(X_real)\nyhat_fake = net_police(X_fake)\n\n- step2: 경찰의 미덕은 (1) 가짜이미지를 가짜라고 하고 (2) 진짜이미지를 진짜라고 해야함.\n- 즉 yhat_real 은 거의 0의 값으로, 그리고 yhat_fake는 1이 되도록 설계해야함. (yhat_real \\(\\approx\\) y_real 이고 yhat_fake \\(\\approx\\) y_fake 이어야 함) 이러면 경찰이 잘하는것.\n\nbce = torch.nn.BCELoss()\n\n\nloss_police = bce(yhat_real,y_real) + bce(yhat_fake,y_fake) \nloss_police\n\ntensor(1.3918, grad_fn=&lt;AddBackward0&gt;)\n\n\n- 합쳐서 계산하는 방법\n\ntorch.concat([X_real,X_fake],axis=0).shape\n\ntorch.Size([12262, 1, 28, 28])\n\n\n\ntorch.concat([y_real,y_fake],axis=0).shape\n\ntorch.Size([12262, 1])\n\n\n\nbce(net_police(torch.concat([X_real,X_fake],axis=0)),torch.concat([y_real,y_fake],axis=0))*2\n\ntensor(1.3918, grad_fn=&lt;MulBackward0&gt;)\n\n\n-step 3~4\n\n# net_police = torch.nn.Sequential(\n#     torch.nn.Flatten(),\n#     torch.nn.Linear(784,30),\n#     torch.nn.ReLU(),\n#     torch.nn.Linear(30,1),\n#     torch.nn.Sigmoid()\n# )\nbce = torch.nn.BCELoss()\noptimizr_police = torch.optim.Adam(net_police.parameters())\nfor epoc in range(30):\n    X_fake = net_facker(torch.randn(6131,4)).data\n    # step1 -- yhat을 얻음\n    yhat_real = net_police(X_real)\n    yhat_fake = net_police(X_fake)\n    # step2  -- loss를 계산\n    loss_police = bce(yhat_real,y_real) + bce(yhat_fake,y_fake)\n    # step3  -- 미분 \n    loss_police.backward()\n    # step4 -- update \n    optimizr_police.step()\n    optimizr_police.zero_grad()\n\n- 경찰의 실력향상 감상\n\nnet_police(X_real) # 거의 0으로 \n\ntensor([[0.0099],\n        [0.0126],\n        [0.0132],\n        ...,\n        [0.0165],\n        [0.1010],\n        [0.0247]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nnet_police(net_facker(torch.randn(6131,4)).data) # 거의 1로\n\ntensor([[0.9775],\n        [0.9775],\n        [0.9773],\n        ...,\n        [0.9773],\n        [0.9773],\n        [0.9775]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n- 꽤 우수한 경찰..\n\nfig, ax = plt.subplots(1,2)\nax[0].imshow(X_fake[[2]].squeeze(),cmap=\"gray\")\nax[0].set_title(f\"police output = {net_police(X_fake[[2]]).item():.4f}\")\nax[1].imshow(X_real[[-1]].squeeze(),cmap=\"gray\")\nax[1].set_title(f\"police output = {net_police(X_real[[-1]]).item():.4f}\")\n\nText(0.5, 1.0, 'police output = 0.0247')\n\n\n\n\n\n\n\n\n\n\n\nF. 더 똑똑해지는 페이커\n- step1 : noise \\(\\to\\) X_fake\n\nX_fake = net_facker(torch.randn(6131,4))\n# 여기서는 X_fake가 데이터가 아니고 네트워크 출력이므로 꼬리표를 제거하지 말아야함\n\n- step2: 손실함수 - 페이커의 미덕 (잘 훈련된) 경찰이 가짜이미지를 진짜라고 판단하는 것. 즉 yhat_fake \\(\\approx\\) y_real 이어야 페이커의 실력이 우수하다고 볼 수 있음.\n\nyhat_fake = net_police(X_fake)\nloss_faker = bce(yhat_fake, y_real) \n# 가짜이미지를 보고 잘 훈련된 경찰도  \n# 진짜 이미지라고 깜빡 속으면 \n# 위조범의 실력이 좋다고 볼 수 있다는 의미\n\n\nclass FlattenToImage(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,X):\n        return X.reshape(-1,1,28,28)\nnet_facker = torch.nn.Sequential(\n    torch.nn.Linear(4,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,784),\n    torch.nn.Sigmoid(), # 출력을 0~1로 눌러주기 위한 레이어 // 저한테는 일종의 문화충격\n    FlattenToImage()\n)\nbce = torch.nn.BCELoss()\noptimizr_facker = torch.optim.Adam(net_facker.parameters())\n\n\nfor epoc in range(1):\n    # step1 -- yhat을 얻음\n    X_fake = net_facker(torch.randn(6131,4))\n    # step2  -- loss를 계산\n    yhat_fake = net_police(X_fake)\n    loss_faker = bce(yhat_fake,y_real)\n    # step3  -- 미분 \n    loss_faker.backward()\n    # step4 -- update \n    optimizr_facker.step()\n    optimizr_facker.zero_grad()\n\n- 위조범의 실력향상 감상\n\nplt.imshow(X_fake[[0]].squeeze().data,cmap=\"gray\")\n\n\n\n\n\n\n\n\n\n\nG. 경쟁학습 (최종코드)\n\ntorch.manual_seed(43052)\nnet_police = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,30),\n    torch.nn.ReLU(),\n    torch.nn.Linear(30,1),\n    torch.nn.Sigmoid()\n)\nclass FlattenToImage(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,X):\n        return X.reshape(-1,1,28,28)\nnet_facker = torch.nn.Sequential(\n    torch.nn.Linear(4,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,784),\n    torch.nn.Sigmoid(), # 출력을 0~1로 눌러주기 위한 레이어 // 저한테는 일종의 문화충격\n    FlattenToImage()\n)\nbce = torch.nn.BCELoss()\noptimizr_police = torch.optim.Adam(net_police.parameters(),lr=0.001, betas=(0.5,0.999))\noptimizr_facker = torch.optim.Adam(net_facker.parameters(),lr=0.0002, betas=(0.5,0.999))\n\n\nfor epoc in range(1000):\n    #--- net_police 를 훈련 \n    #step1\n    X_fake = net_facker(torch.randn(6131,4)).data # 여기에서 X_fake는 data를 의미\n    yhat_real = net_police(X_real)\n    yhat_fake = net_police(X_fake)\n    #step2\n    loss_police = bce(yhat_real,y_real) + bce(yhat_fake,y_fake)\n    #step3\n    loss_police.backward()\n    #step4\n    optimizr_police.step()\n    optimizr_police.zero_grad()\n    #--- net_faker 를 훈련 \n    #step1\n    X_fake = net_facker(torch.randn(6131,4)) # 이때 X_fake는 net의 out을 의미 \n    #step2\n    yhat_fake = net_police(X_fake)\n    loss_facker = bce(yhat_fake, y_real)\n    #step3\n    loss_facker.backward()\n    #step4\n    optimizr_facker.step()\n    optimizr_facker.zero_grad()\n\n\nfig, ax  = plt.subplots(2,5,figsize=(10,4))\nk=0\nfor i in range(2):\n    for j in range(5):\n        ax[i][j].imshow(X_fake[[k]].data.squeeze(),cmap=\"gray\")\n        ax[i][j].set_title(f\"police out = {net_police(X_fake[[k]]).item():.4f}\")\n        k= k+1\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n5. 초기 GAN의 한계점\n- 두 네트워크의 균형이 매우 중요함 – 균형이 깨지는 순간 학습은 실패함\n- 생성되는 이미지의 다양성이 부족한 경우가 발생함. (mode collapse)\nGoodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. “Generative Adversarial Nets.” Advances in Neural Information Processing Systems 27.\n- 적당히 비슷해야함\n\n경찰이 너무 똑똑하면 (판별을 잘하면)..학습을 다 못해버림\n아니면 속이는 다 똑같은 이미지 생성"
  },
  {
    "objectID": "posts/6-1.신경망(데이터분석코딩패턴).html",
    "href": "posts/6-1.신경망(데이터분석코딩패턴).html",
    "title": "6-1. 신경망(데이터분석 코딩패턴)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport torchvision\nimport matplotlib.pyplot as plt\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n# 복습\n# --- \n# 시벤코정리 - 다 맞출수있어 (train) \n# 오버피팅 - 그게 의미가 없을텐데 (test 에서 잘하는게 의미가 있다) \n# 드랍아웃 - 대충대충 학습하면 오히려 좋을지도 --&gt; 이게 성공함 // 랜덤포레스트?\n#----#\n# GPU 메모리 아깝다.. (비싸거든) \n# 그래서 확률적경사하강법 \n# 꼭 돈이 없어서 이 알고리즘을 만든것 같지만 그런건 아님 \n# 확률적경사하강법은 알고리즘 자체에 장점이 있음 \n# -- 장점1: 데이터를 조금씩쓰면서 update // 대충대충하는 느낌 ---&gt; 오버핏을 눌러주는 효과 // 배깅?\n# -- 장점2: global min 이 있고, local min 있을때, local min을 잘 탈출하는 효과가 있음 \n\n- 오늘할것: train/test 이 존재하는 데이터 셋팅에서 Dropout 레이어도, 미니배치, GPU쓰기\n\nA. 일반적인 train/test 셋팅\n- Step1 : 데이터 정리\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\ntest_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0 = torch.stack([to_tensor(img) for img, lbl in train_dataset if lbl==0])\nX1 = torch.stack([to_tensor(img) for img, lbl in train_dataset if lbl==1])\nX = torch.concat([X0,X1],axis=0).reshape(-1,784)\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nXX0 = torch.stack([to_tensor(img) for img, lbl in test_dataset if lbl==0])\nXX1 = torch.stack([to_tensor(img) for img, lbl in test_dataset if lbl==1])\nXX = torch.concat([XX0,XX1],axis=0).reshape(-1,784)\nyy = torch.tensor([0.0]*len(XX0) + [1.0]*len(XX1)).reshape(-1,1)\n\n\nX.shape, y.shape\n\n(torch.Size([12665, 784]), torch.Size([12665, 1]))\n\n\n\nXX.shape, yy.shape\n\n(torch.Size([2115, 784]), torch.Size([2115, 1]))\n\n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,501):\n    #---에폭시작---# \n    # 1 \n    yhat = net(X) \n    # 2 \n    loss = loss_fn(yhat,y) \n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #---에폭끝---# \n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    if (epoc % 50) ==0:\n        acc = ((net(X).data &gt; 0.5) == y).float().mean().item()\n        print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=50       train_acc = 0.4677\n# of epochs=100      train_acc = 0.4677\n# of epochs=150      train_acc = 0.4757\n# of epochs=200      train_acc = 0.5295\n# of epochs=250      train_acc = 0.6632\n# of epochs=300      train_acc = 0.7929\n# of epochs=350      train_acc = 0.8731\n# of epochs=400      train_acc = 0.9206\n# of epochs=450      train_acc = 0.9465\n# of epochs=500      train_acc = 0.9634\n\n\n- Step4: 예측 & 결과분석\n-train acc\n\n((net(X).data &gt; 0.5) == y).float().mean()\n\ntensor(0.9634)\n\n\n- test acc\n\n((net(XX).data&gt;0.5) == yy).float().mean()\n\ntensor(0.9749)\n\n\n\n\nB. Dropout 사용\n- Step1: 데이터정리\n\npass\n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.Dropout(0.9),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,501):\n    net.train()\n    #---에폭시작---# \n    # 1 \n    yhat = net(X) \n    # 2 \n    loss = loss_fn(yhat,y) \n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #---에폭끝---# \n    net.eval()\n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    if (epoc % 50) ==0:\n        acc = ((net(X).data &gt; 0.5) == y).float().mean().item()\n        print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=50       train_acc = 0.4677\n# of epochs=100      train_acc = 0.4677\n# of epochs=150      train_acc = 0.4744\n# of epochs=200      train_acc = 0.5215\n# of epochs=250      train_acc = 0.6435\n# of epochs=300      train_acc = 0.7675\n# of epochs=350      train_acc = 0.8468\n# of epochs=400      train_acc = 0.8978\n# of epochs=450      train_acc = 0.9301\n# of epochs=500      train_acc = 0.9492\n\n\n- Step4: 예측 & 결과분석\n- train acc\n\n((net(X).data &gt; 0.5) == y).float().mean()\n\ntensor(0.9492)\n\n\n- test acc\n\n((net(XX).data&gt;0.5) == yy).float().mean()\n\ntensor(0.9626)\n\n\n\n\nC. GPU도 사용\n- step1: 데이터 정리\n\npass\n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.Dropout(0.9),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,501):\n    net.train()\n    #---에폭시작---# \n    X = X.to(\"cuda:0\")\n    y = y.to(\"cuda:0\")\n    # 1 \n    yhat = net(X) \n    # 2 \n    loss = loss_fn(yhat,y) \n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #---에폭끝---# \n    net.eval()\n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    if (epoc % 50) ==0:\n        acc = ((net(X).data &gt; 0.5) == y).float().mean().item()\n        print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=50       train_acc = 0.4677\n# of epochs=100      train_acc = 0.4677\n# of epochs=150      train_acc = 0.4745\n# of epochs=200      train_acc = 0.5223\n# of epochs=250      train_acc = 0.6441\n# of epochs=300      train_acc = 0.7686\n# of epochs=350      train_acc = 0.8469\n# of epochs=400      train_acc = 0.8979\n# of epochs=450      train_acc = 0.9302\n# of epochs=500      train_acc = 0.9492\n\n\n- Step4: 예측 & 결과분석\n- train acc\n\n((net(X).data &gt; 0.5) == y).float().mean()\n\ntensor(0.9492, device='cuda:0')\n\n\n- test acc\n- net 이 cuda에 있기 때문에 데이터도 cuda로!\n\nXX = XX.to(\"cuda:0\")\nyy = yy.to(\"cuda:0\") \n\n\n((net(XX).data&gt;0.5) == yy).float().mean()\n\ntensor(0.9626, device='cuda:0')\n\n\n\n\nD. 미니배치도 사용\n- Step1: 데이터정리\n\nX = X.to(\"cpu\")\ny = y.to(\"cpu\")\nXX = XX.to(\"cpu\")\nyy = yy.to(\"cpu\")\n\n\nds  = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size = 16, shuffle=True) \n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.Dropout(0.9),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,3):\n    net.train()\n    #---에폭시작---# \n    for Xm,ym in dl:         \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1 \n        ym_hat = net(Xm) \n        # 2 \n        loss = loss_fn(ym_hat,ym) \n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---# \n    net.eval()\n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    s = 0 \n    for Xm, ym in dl:\n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        s = s + ((net(Xm) &gt; 0.5) == ym).float().sum()\n    acc = s/12665        \n    print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=1        train_acc = 0.9860\n# of epochs=2        train_acc = 0.9931\n\n\n- Step4: 예측 & 결과분석\n- 이번에는 net을 cpu로\n\nnet.to(\"cpu\")\n\nSequential(\n  (0): Linear(in_features=784, out_features=32, bias=True)\n  (1): Dropout(p=0.9, inplace=False)\n  (2): ReLU()\n  (3): Linear(in_features=32, out_features=1, bias=True)\n  (4): Sigmoid()\n)\n\n\n- train acc\n\n((net(X) &gt; 0.5) == y).float().mean()\n\ntensor(0.9931)\n\n\n- test acc\n\n((net(XX) &gt; 0.5) == yy).float().mean()\n\ntensor(0.9967)\n\n\n- 점점 비본질적인 코드가 늘어남 \\(\\to\\) 코드가 더러워짐 \\(\\to\\) Trainer의 개념 등장"
  },
  {
    "objectID": "posts/8-2.XAI,설명가능한인공지능(ClassActivationMap).html",
    "href": "posts/8-2.XAI,설명가능한인공지능(ClassActivationMap).html",
    "title": "8-2. XAI, 설명 가능한 인공지능(Class Activation Map)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport torchvision\nimport PIL\nimport requests\nimport io\nimport matplotlib.pyplot as plt\n\n\n\n2. torch.einsum\n\nA. transpose\n- test tensor\n\ntsr = torch.arange(12).reshape(4,3)\ntsr\n\ntensor([[ 0,  1,  2],\n        [ 3,  4,  5],\n        [ 6,  7,  8],\n        [ 9, 10, 11]])\n\n\n- 행렬을 transpose 하는 방법 1\n\ntsr.t()\n\ntensor([[ 0,  3,  6,  9],\n        [ 1,  4,  7, 10],\n        [ 2,  5,  8, 11]])\n\n\n- 행렬을 transpose 하는 방법 2\n\ntorch.einsum('ij -&gt; ji', tsr)\n\ntensor([[ 0,  3,  6,  9],\n        [ 1,  4,  7, 10],\n        [ 2,  5,  8, 11]])\n\n\n\n\nB. 행렬곱\n- test tensors\n\ntsr1 = torch.arange(12).reshape(4,3).float()\ntsr2 = torch.arange(15).reshape(3,5).float()\ntsr1,tsr2\n\n(tensor([[ 0.,  1.,  2.],\n         [ 3.,  4.,  5.],\n         [ 6.,  7.,  8.],\n         [ 9., 10., 11.]]),\n tensor([[ 0.,  1.,  2.,  3.,  4.],\n         [ 5.,  6.,  7.,  8.,  9.],\n         [10., 11., 12., 13., 14.]]))\n\n\n- 행렬곱을 수행하는 방법1\n\ntsr1 @ tsr2\n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])\n\n\n- 행렬곱을 수행하는 방법2\n\ntorch.einsum('ij, jk -&gt; ik', tsr1,tsr2)\n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])\n\n\n\n\nC. img_plt vs img_pytorch\n- r,g,b 를 의미하는 tensor\n\nr = torch.zeros(16).reshape(4,4) + 1.0\ng = torch.zeros(16).reshape(4,4)\nb = torch.zeros(16).reshape(4,4)\n\n- torch를 쓰기 위해서는 이미지가 이렇게 저장되어 있어야함\n\nimg_pytorch = torch.stack([r,g,b],axis=0).reshape(1,3,4,4)\nprint(img_pytorch)\nprint(img_pytorch.shape)\n\ntensor([[[[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[0., 0., 0., 0.],\n          [0., 0., 0., 0.],\n          [0., 0., 0., 0.],\n          [0., 0., 0., 0.]],\n\n         [[0., 0., 0., 0.],\n          [0., 0., 0., 0.],\n          [0., 0., 0., 0.],\n          [0., 0., 0., 0.]]]])\ntorch.Size([1, 3, 4, 4])\n\n\n\nimg_matplotlib = torch.stack([r,g,b],axis=-1)\nprint(img_matplotlib)\nprint(img_matplotlib.shape)\nplt.imshow(img_matplotlib)\n\ntensor([[[1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.]],\n\n        [[1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.]],\n\n        [[1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.]],\n\n        [[1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.]]])\ntorch.Size([4, 4, 3])\n\n\n\n\n\n\n\n\n\n\n# 잘못된코드\nplt.imshow(img_pytorch.squeeze().reshape(4,4,3))\n\n\n\n\n\n\n\n\n\n# 올바른코드1\nplt.imshow(torch.einsum('cij -&gt; ijc', img_pytorch.squeeze()))\n\n\n\n\n\n\n\n\n\n# 올바른코드2\nplt.imshow(img_pytorch.squeeze().permute(1,2,0))\n\n\n\n\n\n\n\n\n\n\n\n3. 이미지 자료 처리\n\nA. 데이터\n- 데이터 다운로드\n\ntorchvision.__version__\n\n'0.20.1'\n\n\n\ntrain_dataset = torchvision.datasets.OxfordIIITPet(\n    root='./data', \n    split='trainval',\n    download=True,\n    target_types='binary-category'\n)\ntest_dataset = torchvision.datasets.OxfordIIITPet(\n    root='./data', \n    split='test',\n    download=True,\n    target_types='binary-category'\n)\n\n- 고양이는 0, 강아지는 1\n\ntrain_dataset[0][0]\n\n\n\n\n\n\n\n\n\ntrain_dataset[0][1]\n\n0\n\n\n\n\nB. 이미지 변환\n- x_pil 을 tensor로 바꾸어 보자\n\nx_pil = train_dataset[0][0]\nx_pil\n\n\n\n\n\n\n\n\n\nto_tensor = torchvision.transforms.ToTensor() # PIL를 텐서로 만드는 함수를 리턴\nx_tensor=to_tensor(x_pil)\nprint(x_tensor.shape)\nx_tensor\n\ntorch.Size([3, 500, 394])\n\n\ntensor([[[0.1451, 0.1373, 0.1412,  ..., 0.9686, 0.9765, 0.9765],\n         [0.1373, 0.1373, 0.1451,  ..., 0.9647, 0.9725, 0.9765],\n         [0.1373, 0.1412, 0.1529,  ..., 0.9686, 0.9804, 0.9804],\n         ...,\n         [0.0196, 0.0157, 0.0157,  ..., 0.2863, 0.2471, 0.2706],\n         [0.0157, 0.0118, 0.0118,  ..., 0.2392, 0.2157, 0.2510],\n         [0.1098, 0.1098, 0.1059,  ..., 0.2314, 0.2549, 0.2980]],\n\n        [[0.0784, 0.0706, 0.0745,  ..., 0.9725, 0.9725, 0.9725],\n         [0.0706, 0.0706, 0.0784,  ..., 0.9686, 0.9686, 0.9725],\n         [0.0706, 0.0745, 0.0863,  ..., 0.9647, 0.9765, 0.9765],\n         ...,\n         [0.0235, 0.0196, 0.0196,  ..., 0.4627, 0.4039, 0.4314],\n         [0.0118, 0.0078, 0.0078,  ..., 0.3882, 0.3843, 0.4235],\n         [0.1059, 0.1059, 0.1059,  ..., 0.3686, 0.4157, 0.4588]],\n\n        [[0.0471, 0.0392, 0.0431,  ..., 0.9922, 0.9922, 0.9922],\n         [0.0392, 0.0392, 0.0471,  ..., 0.9843, 0.9882, 0.9922],\n         [0.0392, 0.0431, 0.0549,  ..., 0.9843, 0.9961, 0.9961],\n         ...,\n         [0.0941, 0.0902, 0.0902,  ..., 0.9608, 0.9216, 0.8784],\n         [0.0745, 0.0706, 0.0706,  ..., 0.9255, 0.9373, 0.8980],\n         [0.1373, 0.1373, 0.1373,  ..., 0.8392, 0.9098, 0.8745]]])\n\n\n\nplt.imshow(to_tensor(x_pil) .permute(1,2,0))\n\n\n\n\n\n\n\n\n- 궁극적으로는 train_dataset의 모든 이미지를 (3680,3,???,???)로 정리하여 X라고 하고 싶음. \\(\\to\\) 이걸 하기 위해서는 이미지 크기를 통일시켜야함. \\(\\to\\) 이미지크기를 통일시키는 방법을 알아보자.\n\nto_tensor(train_dataset[0][0]).shape\n\ntorch.Size([3, 500, 394])\n\n\n\nto_tensor(train_dataset[1][0]).shape\n\ntorch.Size([3, 313, 450])\n\n\n- 512,512로 이미지 조정\n\nresize = torchvision.transforms.Resize((512,512)) # 512,512로 이미지를 조정해주는 함수가 리턴\n\n\nto_tensor(resize(train_dataset[0][0])).shape\n\ntorch.Size([3, 512, 512])\n\n\n\nplt.imshow(to_tensor(resize(train_dataset[0][0])).permute(1,2,0))\n\n\n\n\n\n\n\n\n- 크기가 8인 이미지들의 배치를 만들기\n\nXm = torch.stack([to_tensor(resize(train_dataset[n][0])) for n in range(8)],axis=0)\nXm.shape\n\ntorch.Size([8, 3, 512, 512])\n\n\n\n\n5. AP Layer\n- 채널별로 평균을 구하는 Layer\n\nap = torch.nn.AdaptiveAvgPool2d(output_size=1)\n\n\nX = torch.arange(1*3*4*4).reshape(1,3,4,4).float()\nX\n\ntensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]],\n\n         [[16., 17., 18., 19.],\n          [20., 21., 22., 23.],\n          [24., 25., 26., 27.],\n          [28., 29., 30., 31.]],\n\n         [[32., 33., 34., 35.],\n          [36., 37., 38., 39.],\n          [40., 41., 42., 43.],\n          [44., 45., 46., 47.]]]])\n\n\n\nap(X) # 채널별평균\n\ntensor([[[[ 7.5000]],\n\n         [[23.5000]],\n\n         [[39.5000]]]])\n\n\n\n\nB.AP, Linear의 교환\n\nr = X[:,0,:,:]\ng = X[:,1,:,:]\nb = X[:,2,:,:]\n\n\nap(r)*0.1 + ap(g)*0.2 + ap(b)*0.3\n\ntensor([[[17.3000]]])\n\n\n\nap(r*0.1 + g*0.2 + b*0.3)\n\ntensor([[[17.3000]]])\n\n\n- 위의 두 계산결과를 torch.nn.AdaptiveAvgPool2d, torch.nn.Linear, 그리고 torch.nn.Flatten()을 조합하여 구현해보자.\n\n# ap(r)*0.1 + ap(g)*0.2 + ap(b)*0.3\nap = torch.nn.AdaptiveAvgPool2d(output_size=1)\nflattn = torch.nn.Flatten()\nlinr = torch.nn.Linear(3,1,bias=False)\nlinr.weight.data = torch.tensor([[ 0.1,  0.2, 0.3]])\n#---#\nprint(X.shape)\nprint(ap(X).shape) # ap(r), ap(g), ap(b) 의 값이 들어있음.\nprint(flattn(ap(X)).shape) # [ap(r), ap(g), ap(b)] 형태로\nprint(linr(flattn(ap(X))).shape) # ap(r)*0.1 + ap(g)*0.2 + ap(b)*0.3\n\ntorch.Size([1, 3, 4, 4])\ntorch.Size([1, 3, 1, 1])\ntorch.Size([1, 3])\ntorch.Size([1, 1])\n\n\n\n#ap(r*0.1 + g*0.2 + b*0.3)\nap = torch.nn.AdaptiveAvgPool2d(output_size=1)\nflattn = torch.nn.Flatten()\nlinr = torch.nn.Linear(3,1,bias=False)\nlinr.weight.data = torch.tensor([[ 0.1,  0.2, 0.3]])\n#---#\ndef _linr(X):\n    return torch.einsum('ocij, kc -&gt; okij', X, linr.weight.data)\n#---#\nprint(X.shape) # \nprint(_linr(X).shape) # r*0.1 + g*0.2 + b*0.3 \nprint(ap(_linr(X)).shape) # ap(r*0.1 + g*0.2 + b*0.3 )\nprint(flattn(ap(_linr(X))).shape)\n\ntorch.Size([1, 3, 4, 4])\ntorch.Size([1, 1, 4, 4])\ntorch.Size([1, 1, 1, 1])\ntorch.Size([1, 1])\n\n\n\n\n\n5. CAM(Ahou et al. 2016)의 구현\nref: https://arxiv.org/abs/1512.04150\n- 이 강의노트는 위의 논문의 내용을 재구성하였음.\n\nA. 0단계 – (X,y), (XX,yy)\n\ntrain_dataset = torchvision.datasets.OxfordIIITPet(\n    root='./data', \n    split='trainval',\n    download=True,\n    target_types='binary-category',\n)\ntest_dataset = torchvision.datasets.OxfordIIITPet(\n    root='./data', \n    split='test',\n    download=True,\n    target_types='binary-category',\n)\n\n\ncompose = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((512,512)),\n    torchvision.transforms.ToTensor()\n])\n\n\nX = torch.stack([compose(train_dataset[i][0]) for i in range(3680)],axis=0)\nXX = torch.stack([compose(test_dataset[i][0]) for i in range(3669)],axis=0)\ny = torch.tensor([train_dataset[i][1] for i in range(3680)]).reshape(-1,1).float()\nyy = torch.tensor([test_dataset[i][1] for i in range(3669)]).reshape(-1,1).float()\n\n\n\nB. 1단계 - 이미지 분류 잘하는 네트워크 선택 후 학습\ntorch.manual_seed(43052) #–Step1 ds_train = torch.utils.data.TensorDataset(X,y) dl_train = torch.utils.data.DataLoader(ds_train, batch_size=32, shuffle=True) ds_test = torch.utils.data.TensorDataset(XX,yy) dl_test = torch.utils.data.DataLoader(ds_test, batch_size=32) #–Step2 resnet18 = torchvision.models.resnet18(pretrained=True) resnet18.fc = torch.nn.Linear(512,1) loss_fn = torch.nn.BCEWithLogitsLoss() optimizr = torch.optim.Adam(resnet18.parameters(), lr=1e-5) #–Step3 resnet18.to(“cuda:0”) for epoc in range(3): resnet18.train() for Xm,ym in dl_train: Xm = Xm.to(“cuda:0”) ym = ym.to(“cuda:0”) #1 netout = resnet18(Xm) #2 loss = loss_fn(netout,ym) #3 loss.backward() #4 optimizr.step() optimizr.zero_grad() #—# resnet18.eval() s = 0 for Xm,ym in dl_train: Xm = Xm.to(“cuda:0”) ym = ym.to(“cuda:0”) s = s + ((resnet18(Xm).data &gt; 0) == ym).sum().item() acc = s/3680 print(f”train_acc = {acc:.4f}“) #–Step4 resnet18.eval() s = 0 for Xm,ym in dl_test: Xm = Xm.to(”cuda:0”) ym = ym.to(“cuda:0”) s = s + ((resnet18(Xm).data &gt; 0) == ym).sum().item() acc = s/3669 print(f”test_acc = {acc:.4f}“)\n\n\nC. 2단계 - Linear 와 AP의 순서를 바꿈\n- resnet18을 재구성하여 net을 만들자\n\nresnet18._forward_impl??\n\n\nSignature: resnet18._forward_impl(x: torch.Tensor) -&gt; torch.Tensor\nDocstring: &lt;no docstring&gt;\nSource:   \n    def _forward_impl(self, x: Tensor) -&gt; Tensor:\n        # See note [TorchScript super()]\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\nFile:      ~/anaconda3/envs/test/lib/python3.12/site-packages/torchvision/models/resnet.py\nType:      method\n\n\n\n\nstem = torch.nn.Sequential(\n    torch.nn.Sequential(\n        resnet18.conv1,\n        resnet18.bn1,\n        resnet18.relu,\n        resnet18.maxpool\n    ),\n    resnet18.layer1,\n    resnet18.layer2,\n    resnet18.layer3,\n    resnet18.layer4\n)\nhead = torch.nn.Sequential(\n    resnet18.avgpool,\n    torch.nn.Flatten(),\n    resnet18.fc\n)\nnet = torch.nn.Sequential(\n    stem,\n    head\n)\n\n- 아직은 resnet18과 똑같은 기능, 인덱스로 접근 가능!\n- 1개의 observation을 고정\n\nx = X[[0]].to(\"cuda:0\")\n\n- 이렇게 해도 될듯\n\ntorch.stack([X[0]],axis=0).shape\n\ntorch.Size([1, 3, 512, 512])\n\n\n\nnet(x), resnet18(x)\n\n(tensor([[-5.5534]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-5.5534]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;))\n\n\n- 위와 같은 값 -5.5534이 나오는 과정을 추적하여 보자.\n\n# 계산방식1: 원래계산방식\nap = head[0]\nflattn = head[1]\nlinr = head[2]\n#---#\nprint(f\"{x.shape} -- x\")\nprint(f\"{stem(x).shape} -- stem(x)\")\nprint(f\"{ap(stem(x)).shape} -- ap(stem(x))\")\nprint(f\"{flattn(ap(stem(x))).shape} -- flattn(ap(stem(x)))\")\nprint(f\"{linr(flattn(ap(stem(x)))).shape} -- linr(flattn(ap(stem(x))))\")\n\ntorch.Size([1, 3, 512, 512]) -- x\ntorch.Size([1, 512, 16, 16]) -- stem(x)\ntorch.Size([1, 512, 1, 1]) -- ap(stem(x))\ntorch.Size([1, 512]) -- flattn(ap(stem(x)))\ntorch.Size([1, 1]) -- linr(flattn(ap(stem(x))))\n\n\n현재 네트워크 \\[\\underset{(1,3,512,512)}{\\boldsymbol x} \\overset{stem}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{ap}{\\to} \\underset{(1,512,1,1)}{{\\boldsymbol \\sharp}}\\overset{flattn}{\\to} \\underset{(1,512)}{{\\boldsymbol \\sharp}}\\overset{linr}{\\to} \\underset{(1,1)}{logit}\\right) = [[-5.5613]]\\]\n바꾸고 싶은 네트워크 \\[\\underset{(1,3,224,224)}{\\boldsymbol x} \\overset{stem}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{\\_linr}{\\to} \\underset{(1,1,16,16)}{{\\boldsymbol \\sharp}}\\overset{ap}{\\to} \\underset{(1,1,1,1)}{{\\boldsymbol \\sharp}}\\overset{flattn}{\\to} \\underset{(1,1)}{logit}\\right) = [[-5.5613]]\\]\n\n# 계산방식2\nap = head[0]\nflattn = head[1]\nlinr = head[2]\ndef _linr(xtilde):\n    return torch.einsum('ocij, kc -&gt; okij', xtilde, linr.weight.data) + linr.bias.data\n#---#\nprint(f\"{x.shape} -- x\")\nprint(f\"{stem(x).shape} -- stem(x)\")\nprint(f\"{_linr(stem(x)).shape} -- _linr(stem(x))\")\nprint(f\"{ap(_linr(stem(x))).shape} -- ap(_linr(stem(x)))\")\nprint(f\"{flattn(ap(_linr(stem(x)))).shape} -- flattn(ap(_linr(stem(x))))\")\n\ntorch.Size([1, 3, 512, 512]) -- x\ntorch.Size([1, 512, 16, 16]) -- stem(x)\ntorch.Size([1, 1, 16, 16]) -- _linr(stem(x))\ntorch.Size([1, 1, 1, 1]) -- ap(_linr(stem(x)))\ntorch.Size([1, 1]) -- flattn(ap(_linr(stem(x))))\n\n\n\nlinr(flattn(ap(stem(x)))), flattn(ap(_linr(stem(x))))\n\n(tensor([[-5.5534]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-5.5534]], device='cuda:0', grad_fn=&lt;ViewBackward0&gt;))\n\n\n- 멈추고 생각해보기…!!\n- 원래 계산방식을 적용\n\nlinr(flattn(ap(stem(x))))\n\ntensor([[-5.5534]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)\n\n\n- 바뀐 계산방식을 적용\n\nflattn(ap(_linr(stem(x))))\n\ntensor([[-5.5534]], device='cuda:0', grad_fn=&lt;ViewBackward0&gt;)\n\n\n- 바뀐 계산방식을 좀더 파고 들어서 분석해보자.\n\n_linr(stem(x)).long()\n\ntensor([[[[  0,   0,   0,   0,   0,   0,   0,   0,  -1,  -2,  -2,  -2,   0,   0,\n             0,   0],\n          [  0,   0,   0,   0,   0,   0,   0,  -1,   0,  -2,  -3,  -4,  -1,   0,\n             0,   0],\n          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  -3,  -5,  -4,  -2,\n             0,   0],\n          [  0,   0,   0,   0,   0,   0,   0,   0,  -1,  -4,  -9, -12, -12,  -8,\n            -2,   0],\n          [  0,   0,   0,   0,   0,   0,  -1,  -5, -11, -16, -20, -24, -22, -14,\n            -4,   0],\n          [ -1,  -1,   0,   0,   0,   0,  -5, -16, -28, -35, -40, -42, -37, -23,\n            -7,   0],\n          [ -1,  -1,   0,   0,   0,   0, -10, -28, -47, -56, -56, -52, -42, -25,\n            -7,   0],\n          [  0,  -1,   0,   0,   0,   0, -11, -29, -49, -57, -54, -47, -34, -19,\n            -4,   1],\n          [  0,   0,   0,   0,   0,   0,  -8, -21, -36, -42, -38, -29, -18,  -8,\n            -1,   0],\n          [  0,   0,  -1,  -1,   0,   0,  -3,  -9, -16, -19, -16, -11,  -4,   0,\n             0,   0],\n          [  0,   0,  -2,  -2,   0,   0,  -1,  -3,  -6,  -6,  -5,  -2,   0,   0,\n             1,   1],\n          [  0,   0,  -2,  -1,   0,   0,  -1,  -3,  -4,  -3,  -1,   0,   0,   0,\n             1,   1],\n          [  0,   0,  -1,   0,   0,   0,   0,  -2,  -2,  -1,   0,   0,   0,   0,\n             1,   1],\n          [  0,   0,   0,   0,   0,   0,   0,  -1,  -1,   0,   0,   0,   0,   1,\n             2,   1],\n          [ -1,  -1,  -1,  -1,   0,   0,   0,  -1,   0,   0,   0,   1,   1,   2,\n             2,   2],\n          [  0,  -1,  -1,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,\n             1,   1]]]], device='cuda:0')\n\n\n\n여러가지 값들이 있지만 (16*16=256개의 값들) 아무튼 이 값들의 평균은 -5.5613 임. (이 값이 작을수록 이 그림은 고양이라는 의미임)\n그런데 살펴보니까 대부분의 위치에서 -에 가까운 값을가지고, 특정위치에서만 엄청 작은 값이 존재하여 -5.5613 이라는 평균값이 나오는 것임.\n결국 이 특정위치에 존재하는 엄청 작은 값들이 x가 고양이라고 판단하는 근거가 된다.\n\n바꾸고 싶은 네트워크 – why라는 이름을 적용하여 \\[\\underset{(1,3,224,224)}{\\boldsymbol x} \\overset{stem}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{\\_linr}{\\to} \\underset{(1,1,16,16)}{\\bf why}\\overset{ap}{\\to} \\underset{(1,1,1,1)}{{\\boldsymbol \\sharp}}\\overset{flattn}{\\to} \\underset{(1,1)}{logit}\\right) = [[-5.5613]]\\]\n\nwhy = _linr(stem(x)) \n\n\n\nD. 3단계 -WHY 시각화\n- 시각화1 - why와 img를 겹쳐서 그려보자\n\nplt.imshow(why.squeeze().cpu().detach(),cmap=\"bwr\")\nplt.colorbar()\n\n\n\n\n\n\n\n\n\nplt.imshow(x.cpu().detach().squeeze().permute(1,2,0))\nwhy_resized = torch.nn.functional.interpolate(\n    why,\n    size=(512,512),\n    mode=\"bilinear\",\n)\nplt.imshow(why_resized.squeeze().cpu().detach(),cmap=\"bwr\",alpha=0.5)\nplt.colorbar()\n\n\n\n\n\n\n\n\n- 시각화2 - colormap을 magma로 적용\n\nx = X[[0]].to(\"cuda:0\")\nif net(x) &gt; 0: \n    pred = \"dog\"\n    why = _linr(stem(x)) \nelse: \n    pred = \"cat\" \n    why = - _linr(stem(x)) \nplt.imshow(x.cpu().detach().squeeze().permute(1,2,0))\nwhy_resized = torch.nn.functional.interpolate(\n    why,\n    size=(512,512),\n    mode=\"bilinear\",\n)\nplt.imshow(why_resized.squeeze().cpu().detach(),cmap=\"magma\",alpha=0.5)\nplt.title(f\"prediction = {pred}\");\n\n\n\n\n\n\n\n\n- 시각화3 - 하니를 시각화\n\nurl = 'https://github.com/guebin/DL2025/blob/main/imgs/hani1.jpeg?raw=true'\nhani_pil = PIL.Image.open(\n    io.BytesIO(requests.get(url).content)\n)\n\n\nx = compose(hani_pil).reshape(1,3,512,512).to(\"cuda:0\")\nif net(x) &gt; 0: \n    pred = \"dog\"\n    why = _linr(stem(x)) \nelse: \n    pred = \"cat\" \n    why = - _linr(stem(x)) \nplt.imshow(x.cpu().detach().squeeze().permute(1,2,0))\nwhy_resized = torch.nn.functional.interpolate(\n    why,\n    size=(512,512),\n    mode=\"bilinear\",\n)\nplt.imshow(why_resized.squeeze().cpu().detach(),cmap=\"magma\",alpha=0.5)\nplt.title(f\"prediction = {pred}\");\n\n\n\n\n\n\n\n\n- 시각화4 - XX의 이미지를 시각화해보자\n\nfig, ax = plt.subplots(5,5)\n#---#\nk = 0\nfor i in range(5):\n    for j in range(5):\n        x = XX[[k]].to(\"cuda:0\")\n        if net(x) &gt; 0: \n            pred = \"dog\"\n            why = _linr(stem(x)) \n        else: \n            pred = \"cat\" \n            why = - _linr(stem(x)) \n        plt.imshow(x.cpu().detach().squeeze().permute(1,2,0))\n        why_resized = torch.nn.functional.interpolate(\n            why,\n            size=(512,512),\n            mode=\"bilinear\",\n        )\n        ax[i][j].imshow(x.squeeze().permute(1,2,0).cpu())\n        ax[i][j].imshow(why_resized.squeeze().cpu().detach(),cmap=\"magma\",alpha=0.5)\n        ax[i][j].set_title(f\"prediction = {pred}\");\n        ax[i][j].set_xticks([])\n        ax[i][j].set_yticks([])\n        k = k+50\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(5,5)\n#---#\nk = 1 \nfor i in range(5):\n    for j in range(5):\n        x = XX[[k]].to(\"cuda:0\")\n        if net(x) &gt; 0: \n            pred = \"dog\"\n            why = _linr(stem(x)) \n        else: \n            pred = \"cat\" \n            why = - _linr(stem(x)) \n        plt.imshow(x.cpu().detach().squeeze().permute(1,2,0))\n        why_resized = torch.nn.functional.interpolate(\n            why,\n            size=(512,512),\n            mode=\"bilinear\",\n        )\n        ax[i][j].imshow(x.squeeze().permute(1,2,0).cpu())\n        ax[i][j].imshow(why_resized.squeeze().cpu().detach(),cmap=\"magma\",alpha=0.5)\n        ax[i][j].set_title(f\"prediction = {pred}\");\n        ax[i][j].set_xticks([])\n        ax[i][j].set_yticks([])\n        k = k+50\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(5,5)\n#---#\nk = 2\nfor i in range(5):\n    for j in range(5):\n        x = XX[[k]].to(\"cuda:0\")\n        if net(x) &gt; 0: \n            pred = \"dog\"\n            why = _linr(stem(x)) \n        else: \n            pred = \"cat\" \n            why = - _linr(stem(x)) \n        plt.imshow(x.cpu().detach().squeeze().permute(1,2,0))\n        why_resized = torch.nn.functional.interpolate(\n            why,\n            size=(512,512),\n            mode=\"bilinear\",\n        )\n        ax[i][j].imshow(x.squeeze().permute(1,2,0).cpu())\n        ax[i][j].imshow(why_resized.squeeze().cpu().detach(),cmap=\"magma\",alpha=0.5)\n        ax[i][j].set_title(f\"prediction = {pred}\");\n        ax[i][j].set_xticks([])\n        ax[i][j].set_yticks([])\n        k = k+50\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(5,5)\n#---#\nk = 3\nfor i in range(5):\n    for j in range(5):\n        x = XX[[k]].to(\"cuda:0\")\n        if net(x) &gt; 0: \n            pred = \"dog\"\n            why = _linr(stem(x)) \n        else: \n            pred = \"cat\" \n            why = - _linr(stem(x)) \n        plt.imshow(x.cpu().detach().squeeze().permute(1,2,0))\n        why_resized = torch.nn.functional.interpolate(\n            why,\n            size=(512,512),\n            mode=\"bilinear\",\n        )\n        ax[i][j].imshow(x.squeeze().permute(1,2,0).cpu())\n        ax[i][j].imshow(why_resized.squeeze().cpu().detach(),cmap=\"magma\",alpha=0.5)\n        ax[i][j].set_title(f\"prediction = {pred}\");\n        ax[i][j].set_xticks([])\n        ax[i][j].set_yticks([])\n        k = k+50\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n6. CAM의 한계\n- 구조적 제약이 있음\n\nhead-part가 ap와 linr로만 구성되어야 가능\n그렇지 않은 네트워크는 임의로 재구성하여 head-part를 ap와 linr로많 구성해야함(CAM을 적용하기 위한 구조로 만들기 위해)\n\n- 이후로 등장한 grad-cam은 구조의 제약 없이 거의 모든 CNN에 적용 가능"
  },
  {
    "objectID": "posts/4-2.신경망(꺽인그래프한계,시벤코정리,MNIST).html",
    "href": "posts/4-2.신경망(꺽인그래프한계,시벤코정리,MNIST).html",
    "title": "4-2. 신경망(꺽인 그래프의 한계, 시벤코 정리, MNIST)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. 꺽인 그래프의 한계\n- 지난시간에 배운 기술은 sig를 취하기 전이 꺽은 선인 형태만 가능하다. 표현력이 부족하다.\n- 하지만 그렇게 나쁘지많은 또 않다\n\nA. Step은 표현 불가능하지 않을까?\n- 이상하게 만든 취업합격률 곡선\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(-1,1)\nu = 0*x-3\nu[x&lt;-0.2] = (15*x+6)[x&lt;-0.2]\nu[(-0.2&lt;x)&(x&lt;0.4)] = (0*x-1)[(-0.2&lt;x)&(x&lt;0.4)]\nsig = torch.nn.Sigmoid()\nv = π = sig(u)\ny = torch.bernoulli(v)\n\n\nplt.plot(x,y,'.',alpha=0.03, label=\"observed\")\nplt.plot(x,v,'--', label=\"unobserved\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU())\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03, label=\"observed\")\nplt.plot(x,v, label=\"true\")\nplt.plot(x,net(x).data,'--', label=\"estimated\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nB. 곡선은 표현 가능한가?\n- 2024년 수능 미적30번 문제에 나온 곡선\n\\[y_i = e^{-x_i} \\times  |\\cos(5x_i)| \\times \\sin(5x) + \\epsilon_i, \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\]\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\nplt.plot(x,y,label=\"observed\",alpha=0.5)\nplt.plot(x,fx,label=\"true\")\n\n\n\n\n\n\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048), # 꺽이지않은 1024개의 직선\n    torch.nn.ReLU(), # 꺽인(렐루된) 1024개의 직선 \n    torch.nn.Linear(2048,1), # 합쳐진 하나의 꺽인 직선 \n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n## \nfor epoc in range(1000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,label=\"observed\",alpha=0.5)\nplt.plot(x,fx,label=\"true\")\nplt.plot(x,net(x).data,'--',label=\"estimated\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n\n3. 시벤코 정리\n\nA. 시벤코 정리의 소개\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n모든 보렐 가측함수 (Borel measurable function)\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다. 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 신경망이 원하는 정확도로 근사시킨다는 의미이다. 예를들면 아래와 같은 문제를 해결할 수 있다.\n\n\\({\\bf X}_{n\\times 2}\\)는 토익점수, GPA 이고 \\({\\bf y}_{n\\times 1}\\)는 취업여부일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 신경망은 항상 찾을 수 있다.\n\\({\\bf X}_{n \\times p}\\)는 주택이미지, 지역정보, 주택면적, 주택에 대한 설명 이고 \\({\\bf y}_{n\\times 1}\\)는 주택가격일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 신경망은 항상 찾을 수 있다.\n\n즉 하나의 은닉층을 가진 신경망의 표현력은 거의 무한대라 볼 수 있다.\n\n\n보렐가측함수에 대한 정의는 측도론에 대한 이해가 있어야 가능함. 측도론에 대한 내용이 궁금하다면 https://guebin.github.io/SS2024/ 을 공부해보세요\n\n\n\nB. 시벤코정리가 가능한 이유\n- 준비\n\nx = torch.linspace(-10,10,200).reshape(-1,1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(in_features=2,out_features=1)\n)\nl1,a1,l2 = net\n\n\nnet\n\nSequential(\n  (0): Linear(in_features=1, out_features=2, bias=True)\n  (1): Sigmoid()\n  (2): Linear(in_features=2, out_features=1, bias=True)\n)\n\n\n- 생각1 : 2개의 시그모이드를 우연히 잘 조합하면 하나의 계단함수를 만들 수 있다\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+10.00,+10.00])\n\n\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\n\n\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x)[:,[0]].data,label=r\"$-5x+10$\")\nax[0].plot(x,l1(x)[:,[1]].data,label=r\"$5x+10$\")\nax[0].set_title('$l_1(x)$')\nax[0].legend()\nax[1].plot(x,a1(l1(x))[:,[0]].data,label=r\"$v_1=sig(-5x+10)$\")\nax[1].plot(x,a1(l1(x))[:,[1]].data,label=r\"$v_2=sig(5x+10)$\")\nax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[1].legend()\nax[2].plot(x,l2(a1(l1(x))).data,color='C2',label=r\"$v_1+v_2-1$\")\nax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$')\nax[2].legend()\n\n\n\n\n\n\n\n\n- 생각2 : 계단함수의 모양이 꼭 생각 1과 같을 필요는 없다. 중심은 이동가능하고, 높이도 조절가능하다.\n- 예시1\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+0.00,+20.00])\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C0'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C0'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C0'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n\n\n\n\n\n\n\n- 예시2\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+20.00,+00.00])\nl2.weight.data = torch.tensor([[2.50,2.50]])\nl2.bias.data = torch.tensor([-2.50])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C1'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C1'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C1'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n\n\n\n\n\n\n\n- 생각3 : out_features=4로 하고 가중치를 적당히 하면 \\((l_2\\circ a_1 \\circ l_1)(x)\\)의 결과로 생각2의 예시1,2를 조합한 형태도 가능할 것 같다. 즉 4개의 시그모이드를 잘 조합하면 2단계 계단함수를 만들 수 있다.\n\nl1 = torch.nn.Linear(in_features=1,out_features=4)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=4,out_features=1)\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00],[-5.00],[5.00]])\nl1.bias.data = torch.tensor([0.00, 20.00, 20.00, 0])\nl2.weight.data = torch.tensor([[1.00,  1.00, 2.50,  2.50]])\nl2.bias.data = torch.tensor([-1.0-2.5])\n\n\nplt.plot(l2(a1(l1(x))).data,'--')\nplt.title(r\"$(l_2 \\circ a_1 \\circ l_1)(x)$\")\n\nText(0.5, 1.0, '$(l_2 \\\\circ a_1 \\\\circ l_1)(x)$')\n\n\n\n\n\n\n\n\n\n- 일단 2단계 계단함수라고 부르기\n- 생각4 : 2m개의 시그모이드를 우연히 잘 조합하면 m단계 계단함수를 만들 수 있다\n- 정리1 : 2개의 시그모이드를 우연히 잘 결합하면 아래외같은 ‘1단계-계단함수’ h를 만들 수 있음\n\ndef h(x):\n    sig = torch.nn.Sigmoid()\n    v1 = -sig(200*(x-0.5))\n    v2 = sig(200*(x+0.5))\n    return v1+v2 \n\n\nplt.plot(x,h(x))\nplt.title(\"$h(x)$\")\n\nText(0.5, 1.0, '$h(x)$')\n\n\n\n\n\n\n\n\n\n- 정리2: 위와 같은 함수 \\(h\\)를 이용한 아래의 네트워크를 고려하자. 이는 “m단계-계단함수”를 만든다.\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n그리고 위의 네트워크와 동일한 효과를 주는 아래의 네트워크가 항상 존재\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,2m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n- 생각5 그런데 어지간한 함수형태는 구불구불한 “m단계-계단함수”로 다 근사할 수 있지 않을까?\n아래의 네트워크에서 (1) ?? 를 충분히 키우고 (2) 적절하게 학습만 잘 된다면\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n위의 네트워크는 거의 무한한 표현력을 가진다. –&gt; 이런식으로 증명가능\n\n\n\nC. \\(h\\)의 위력\n- 소망: 아래와 같이 net을 설계해서, 그 위력을 체감해보고 싶은데..\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,??),\n    torch.nn.H(),\n    torch.nn.Linear(??,1)\n)\n- \\(h(x)\\)를 생성하는 클래스를 만들어보자.\n\nclass H(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,x):\n        def h(x):\n            sig = torch.nn.Sigmoid()\n            v1 = -sig(200*(x-0.5))\n            v2 = sig(200*(x+0.5))\n            return v1+v2 \n        out = h(x)\n        return out \n\n\nh = H()\n\n- h를 이용해보자\n- 예제1 : 스펙의 역설\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    H(),\n    torch.nn.Linear(2048,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,prob)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n- 예제2 : 수능곡선\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(x,fx)\n\n\n\n\n\n\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    H(),\n    torch.nn.Linear(2048,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(x,fx)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n\n\nD.의문점\n- 그냥 활성함수 h로 쓰면 되는거 아닌가? 왜 relu를 쓰지?\n- 왜 딥러닝이 2010년 이후에 떴지?\n- 은닉층이 깊을 수록 좋은거 아닌가?\n\n\n5. MNIST 해결\n\n\nA. 예비학습 - plt.imshow()\n- plt.imshow(...,camp='gray') 에서 ...이 shape가 (??,??)이면 흑백이미지를 출력\n\nimg = torch.tensor([[255,100],\n                    [255,0]])\nplt.imshow(img,cmap=\"gray\")\n\n\n\n\n\n\n\n\n- plt.imshow(...) 에서 ...의 shape이 (??,??,3)이면 칼라이미지를 출력\n\nr = torch.tensor([[255,0],\n                  [255,0]])\ng = torch.tensor([[0,255],\n                  [0,0]])\nb = torch.tensor([[0,0],\n                  [0,255]])\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n- plt.imshow(...) 에서 ...의 자료형이 int인지 float인지에 따라서 인식이 다름\n\nr = torch.tensor([[1,0],\n                  [1,0]])\ng = torch.tensor([[0,1],\n                  [0,0]])\nb = torch.tensor([[0,0],\n                  [0,1]])\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\nr = torch.tensor([[255,0],\n                  [255,0]])/255\ng = torch.tensor([[0,255],\n                  [0,0]])/255\nb = torch.tensor([[0,0],\n                  [0,255]])/255\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n- 자료형이 float임\n\nimg\n\ntensor([[[1., 0., 0.],\n         [0., 1., 0.]],\n\n        [[1., 0., 0.],\n         [0., 0., 1.]]])\n\n\n\nB. 데이터\n- 데이터 정리코드\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX3 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==3])\nX7 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==7])\nX = torch.concat([X3,X7],axis=0)\ny = torch.tensor([0.0]*len(X3) + [1.0]*len(X7))\n\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:03&lt;00:00, 3058648.55it/s]\n\n\nExtracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n\n\n100%|█████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00&lt;00:00, 147469.10it/s]\n\n\nExtracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n\n\n100%|████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:01&lt;00:00, 1479955.21it/s]\n\n\nExtracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n\n\n100%|██████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00&lt;00:00, 3940945.13it/s]\n\n\nExtracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\n\n\n\nplt.plot(y,'.')\n\n\n\n\n\n\n\n\n\nplt.imshow(X[0][0], cmap='gray')\n\n\n\n\n\n\n\n\n\nplt.imshow(X[-2].reshape(28,28),cmap='gray')\n\n\n\n\n\n\n\n\n- 우리는 \\({\\bf X}: (n,1,28,28)\\) 에서 \\({\\bf y}: (n,1)\\)으로 가는 맵핑을 배우고 싶음. \\(\\to\\) 이런건 배운적이 없는데?.. \\(\\to\\) 그렇다면 \\({\\bf X}:(n,784) \\to {\\bf y}:(n,1)\\) 으로 가는 맵핑을 학습하자.\n\n#X[0].reshape(-1)\n\n\nX = torch.stack([img.reshape(-1) for img in X])\ny = y.reshape(-1,1)\n\n\nX.shape,y.shape\n\n(torch.Size([12396, 784]), torch.Size([12396, 1]))\n\n\n\n\n\nC. 학습\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y,'.')\nplt.plot(net(X).data,'.',alpha=0.2)\n\n\n\n\n\n\n\n\n\n((y == (net(X).data &gt; 0.5))*1.0).mean()\n\ntensor(0.9901)"
  },
  {
    "objectID": "posts/6-2.신경망(다항분류,FashionMNIST).html",
    "href": "posts/6-2.신경망(다항분류,FashionMNIST).html",
    "title": "6-2. 신경망(다항분류, Fashion MNIST)",
    "section": "",
    "text": "import torch\nimport torchvision\nimport matplotlib.pyplot as plt\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)"
  },
  {
    "objectID": "posts/6-2.신경망(다항분류,FashionMNIST).html#c.-실습-3개의-클래스를-구분",
    "href": "posts/6-2.신경망(다항분류,FashionMNIST).html#c.-실습-3개의-클래스를-구분",
    "title": "6-2. 신경망(다항분류, Fashion MNIST)",
    "section": "C. 실습: 3개의 클래스를 구분",
    "text": "C. 실습: 3개의 클래스를 구분\n- 데이터준비\n\n#train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\nX1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\nX2 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==2])\nX = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)\ny = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2)).reshape(-1,1).float()\n\n\ny = torch.nn.functional.one_hot(y.reshape(-1).long()).float()\ny\n\ntensor([[1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        ...,\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.]])\n\n\n- 적합\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,3),\n)\nloss_fn = torch.nn.CrossEntropyLoss() # 의미상 CEWithLogitsLoss\noptimizr = torch.optim.Adam(net.parameters())\nfor epoc in range(1,31):\n    #1\n    netout = net(X) # netout: (n,3) \n    #2\n    loss = loss_fn(netout,y) \n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n(netout.argmax(axis=1) == y.argmax(axis=1)).float().mean()\n\ntensor(0.9685)\n\n\n\ntorch.exp(netout)\n\ntensor([[35.0634,  0.2371,  0.1590],\n        [35.9059,  0.2793,  0.1412],\n        [ 4.8449,  0.4623,  0.4364],\n        ...,\n        [ 1.1820,  0.2359,  3.2423],\n        [ 0.3119,  0.1862, 15.4971],\n        [ 0.4304,  0.4113,  5.2896]], grad_fn=&lt;ExpBackward0&gt;)\n\n\n\nD. 결론\n- 파이토치버전 // 코딩용\n\n\n\n분류\nnetout의 의미\n손실함수\n\n\n\n\n이항분류\nprob\nBCELoss\n\n\n이항분류\nlogit\nBCEWithLogitsLoss\n\n\n다항분류\nprobs\nNA\n\n\n다항분류\nlogits\nCrossEntropyLoss\n\n\n\n\nCrossEntropyLoss 이거 이름이 완전 마음에 안들어요.. CEWithLogitsLoss 라고 하는게 더 좋을 것 같습니다.\n\n- 일반적개념 // 이론용\n\n\n\n분류\n오차항의가정\n마지막활성화함수\n손실함수\n\n\n\n\n이항분류\n이항분포\nsigmoid[1]\nBinary Cross Entropy\n\n\n다항분류\n다항분포\nsoftmax[2]\nCross Entropy\n\n\n\n- 참고 (sigmoid, softmax 계산과정비교)\n\n\\(prob = \\text{sig}(logit) =\\frac{\\exp(logit)}{1+\\exp(logit)}\\)\n\\(probs= \\text{softmax}\\left(\\begin{bmatrix} logit_1 \\\\ logit_2 \\\\ logit_3\\end{bmatrix}\\right) =\\begin{bmatrix} \\frac{\\exp(logit_1)}{\\exp(logit_1)+\\exp(logit_2)+\\exp(logit_3)} \\\\\n\\frac{\\exp(logit_2)}{\\exp(logit_1)+\\exp(logit_2)+\\exp(logit_3)} \\\\\n\\frac{\\exp(logit_3)}{\\exp(logit_1)+\\exp(logit_2)+\\exp(logit_3)} \\end{bmatrix}\\)\n\n\n\n3. FashionMNIST\n\nA. 데이터\nhttps://arxiv.org/abs/1708.07747 (Xiao, Rasul, and Vollgraf 2017)\n[1] prob=sig(logit)\n[2] probs=soft(logits)\n\n#train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\n#test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX = torch.stack([to_tensor(img) for img, lbl in train_dataset])\ny = torch.tensor([lbl for img, lbl in train_dataset])\ny = torch.nn.functional.one_hot(y).float()\nXX = torch.stack([to_tensor(img) for img, lbl in test_dataset])\nyy = torch.tensor([lbl for img, lbl in test_dataset])\nyy = torch.nn.functional.one_hot(yy).float()\n\n\ntorchvision.datasets.FashionMNIST.classes\n\n['T-shirt/top',\n 'Trouser',\n 'Pullover',\n 'Dress',\n 'Coat',\n 'Sandal',\n 'Shirt',\n 'Sneaker',\n 'Bag',\n 'Ankle boot']\n\n\n\nobs_idx = 301\nplt.imshow(X[obs_idx,0,:,:],cmap=\"gray\")\nplt.title(torchvision.datasets.FashionMNIST.classes[y[obs_idx,:].argmax().item()]);\n\n\n\n\n\n\n\n\n\n\nB. 간단한 신경망\n\nds_train = torch.utils.data.TensorDataset(X,y)\ndl_train = torch.utils.data.DataLoader(ds_train,batch_size=256,shuffle=True)\nds_test = torch.utils.data.TensorDataset(XX,yy)\ndl_test = torch.utils.data.DataLoader(ds_test,batch_size=256)\n\n- Step2: 학습에 필요한 준비 (모델링)\n- 직접 만들기\n\nclass Flatten(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, inp):\n        out = inp.reshape(-1,784)\n        return out\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    Flatten(),#torch.nn.Flatten(),\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n- torch 기능 사용\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n- Step3: 적합\n\nfor epoc in range(1,31):\n    net.train()\n    #---에폭시작---#\n    for Xm,ym in dl_train:        \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1\n        netout = net(Xm)\n        # 2 \n        loss = loss_fn(netout,ym)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc % 5 == 0:\n        net.eval()\n        s =0\n        for Xm,ym in dl_train:        \n            Xm = Xm.to(\"cuda:0\")\n            ym = ym.to(\"cuda:0\")        \n            logits = net(Xm).data \n            s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\n        acc = s / len(X)\n        print(f\"# of epochs = {epoc},train_acc = {acc:.4f}\") \n\n# of epochs = 5,train_acc = 0.8588\n# of epochs = 10,train_acc = 0.8659\n# of epochs = 15,train_acc = 0.8779\n# of epochs = 20,train_acc = 0.8831\n# of epochs = 25,train_acc = 0.8856\n# of epochs = 30,train_acc = 0.8876\n\n\n- Step4: 적합결과 시각화 및 분석\n\nnet.eval()\ns =0\nfor Xm,ym in dl_test:        \n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")        \n    logits = net(Xm).data \n    s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\nacc = s / len(XX)\nprint(f\"test_acc = {acc:.4f}\") \n\ntest_acc = 0.8638\n\n\n\n\nC. 약간 더 복잡한 신경망\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\nfor epoc in range(1,31):\n    net.train()\n    #---에폭시작---#\n    for Xm,ym in dl_train:        \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1\n        netout = net(Xm)\n        # 2 \n        loss = loss_fn(netout,ym)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc % 5 == 0:\n        net.eval()\n        s =0\n        for Xm,ym in dl_train:        \n            Xm = Xm.to(\"cuda:0\")\n            ym = ym.to(\"cuda:0\")        \n            logits = net(Xm).data \n            s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\n        acc = s / len(X)\n        print(f\"# of epochs = {epoc},train_acc = {acc:.4f}\") \n\n# of epochs = 5,train_acc = 0.8843\n# of epochs = 10,train_acc = 0.9020\n# of epochs = 15,train_acc = 0.9176\n# of epochs = 20,train_acc = 0.9265\n# of epochs = 25,train_acc = 0.9345\n# of epochs = 30,train_acc = 0.9388\n\n\n\nnet.eval()\ns =0\nfor Xm,ym in dl_test:        \n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")        \n    logits = net(Xm).data \n    s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\nacc = s / len(XX)\nprint(f\"test_acc = {acc:.4f}\") \n\ntest_acc = 0.8892\n\n\n\n\nD. 발악..?\n- 노드를 엄청 많이…\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,4096),\n    torch.nn.Dropout(0.5),\n    torch.nn.ReLU(),\n    torch.nn.Linear(4096,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\nfor epoc in range(1,31):\n    net.train()\n    #---에폭시작---#\n    for Xm,ym in dl_train:        \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1\n        netout = net(Xm)\n        # 2 \n        loss = loss_fn(netout,ym)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc % 5 == 0:\n        net.eval()\n        s =0\n        for Xm,ym in dl_train:        \n            Xm = Xm.to(\"cuda:0\")\n            ym = ym.to(\"cuda:0\")        \n            logits = net(Xm).data \n            s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\n        acc = s / len(X)\n        print(f\"# of epochs = {epoc},train_acc = {acc:.4f}\") \n\n# of epochs = 5,train_acc = 0.8870\n# of epochs = 10,train_acc = 0.9024\n# of epochs = 15,train_acc = 0.9116\n# of epochs = 20,train_acc = 0.9214\n# of epochs = 25,train_acc = 0.9302\n# of epochs = 30,train_acc = 0.9307\n\n\n\nnet.eval()\ns =0\nfor Xm,ym in dl_test:        \n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")        \n    logits = net(Xm).data \n    s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\nacc = s / len(XX)\nprint(f\"test_acc = {acc:.4f}\") \n\ntest_acc = 0.8913\n\n\n- 레이어를 많이..\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,256),\n    torch.nn.ReLU(), \n    torch.nn.Linear(256,256),\n    torch.nn.ReLU(),    \n    torch.nn.Linear(256,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\nfor epoc in range(1,31):\n    net.train()\n    #---에폭시작---#\n    for Xm,ym in dl_train:        \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1\n        netout = net(Xm)\n        # 2 \n        loss = loss_fn(netout,ym)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc % 5 == 0:\n        net.eval()\n        s =0\n        for Xm,ym in dl_train:        \n            Xm = Xm.to(\"cuda:0\")\n            ym = ym.to(\"cuda:0\")        \n            logits = net(Xm).data \n            s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\n        acc = s / len(X)\n        print(f\"# of epochs = {epoc},train_acc = {acc:.4f}\") \n\n# of epochs = 5,train_acc = 0.8881\n# of epochs = 10,train_acc = 0.9154\n# of epochs = 15,train_acc = 0.9240\n# of epochs = 20,train_acc = 0.9303\n# of epochs = 25,train_acc = 0.9511\n# of epochs = 30,train_acc = 0.9547\n\n\n\nnet.eval()\ns =0\nfor Xm,ym in dl_test:        \n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")        \n    logits = net(Xm).data \n    s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\nacc = s / len(XX)\nprint(f\"test_acc = {acc:.4f}\") \n\ntest_acc = 0.8907\n\n\n- test_acc 를 90% 넘기는게 힘들다..\n\n\nF. 합성곱신경망\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1 ,out_channels=64,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),\n    torch.nn.Conv2d(in_channels=64 ,out_channels=64,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),    \n    torch.nn.Flatten(),\n    torch.nn.Linear(1024,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\nfor epoc in range(1,31):\n    net.train()\n    #---에폭시작---#\n    for Xm,ym in dl_train:        \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1\n        netout = net(Xm)\n        # 2 \n        loss = loss_fn(netout,ym)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc % 5 == 0:\n        net.eval()\n        s =0\n        for Xm,ym in dl_train:        \n            Xm = Xm.to(\"cuda:0\")\n            ym = ym.to(\"cuda:0\")        \n            logits = net(Xm).data \n            s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\n        acc = s / len(X)\n        print(f\"# of epochs = {epoc},train_acc = {acc:.4f}\") \n\n# of epochs = 5,train_acc = 0.9067\n# of epochs = 10,train_acc = 0.9322\n# of epochs = 15,train_acc = 0.9420\n# of epochs = 20,train_acc = 0.9579\n# of epochs = 25,train_acc = 0.9653\n# of epochs = 30,train_acc = 0.9772\n\n\n\nnet.eval()\ns =0\nfor Xm,ym in dl_test:        \n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")        \n    logits = net(Xm).data \n    s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\nacc = s / len(XX)\nprint(f\"test_acc = {acc:.4f}\") \n\ntest_acc = 0.9166"
  },
  {
    "objectID": "posts/1-2.회귀(회귀모형,손실함수,파이토치를이용한추정).html",
    "href": "posts/1-2.회귀(회귀모형,손실함수,파이토치를이용한추정).html",
    "title": "1-2, 2-1. 회귀(회귀모형, 손실함수, 파이토치를 이용한 추정)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport matplotlib.pyplot as plt \n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. 회귀모형\n\nA. 아이스 아메리카노 (가짜자료)\n- 카페주인 이상민씨는 온도와 아이스 아메리카노 판매량이 관계가 있다는 것을 확인하기 위해 하래의 100개의 데이터를 모았다.\n\ntemp = [-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632]\n\n\nsales= [-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340]\n\n- temp는 평균기온, sales는 아이스 아메리카노 판매량\n- 그래프를 그려보자\n\nplt.plot(temp,sales,'o')\n\n\n\n\n\n\n\n\n- 오늘 평균 기온이 0.5도이면 아이스 아메리카노가 얼마나 팔릴까?\n\n\nB. 자료를 만든 방법\n- 방법1 : \\(y_i= w_0+w_1 x_i +\\epsilon_i = 2.5 + 4x_i +\\epsilon_i, \\quad i=1,2,\\dots,n\\)\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps\n\n- sort()를 하면 인덱스 항이 생겨서 필요없으므로 _에 저장\n\nx[:5], y[:5]\n\n(tensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792]),\n tensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516]))\n\n\n- 방법2: \\({\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\)\n\n\\({\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)\n\n\nX = torch.stack([torch.ones(100),x],axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\nx = X[:,[1]]\n\n\nX[:5,:], y[:5,:]\n\n(tensor([[ 1.0000, -2.4821],\n         [ 1.0000, -2.3621],\n         [ 1.0000, -1.9973],\n         [ 1.0000, -1.6239],\n         [ 1.0000, -1.4792]]),\n tensor([[-8.5420],\n         [-6.5767],\n         [-5.9496],\n         [-4.4794],\n         [-4.2516]]))\n\n\n- true 와 관측값(observed data) 동시에 시각화\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\")\nplt.plot(x,2.5+4*x,'--',label=r\"true: $(x_i, 4x_i+2.5)$ // $y=4x+2.5$ \")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nC. 회귀분석\n- 관측한 자료 \\((x_i,y_i)\\) 이 선형성을 가지고 있을 때 이를 파악하여 새로운 \\(x\\)가 주어졌을 때 \\(\\hat{y}\\)(예측값)을 구할 수 있는 적당한 추세선을 찾는 것\n- 좀 더 정확하게 말하면 \\((x_1,y_1) \\dots (x_n,y_n)\\) 으로\n\\(\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\) 를 최대한 \\(\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}\\)와 비슷하게 찾는 것.\n\ngiven data : \\(\\big\\{(x_i,y_i) \\big\\}_{i=1}^{n}\\)\nparameter: \\({\\bf W}=\\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}\\)\nestimated parameter: \\({\\bf \\hat{W}}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\)\n\n- 추세선을 그리는 행위 = \\((w_0,w_1)\\)을 선택하는일\n\n\n\n4. 손실함수\n- \\((\\hat{w}_0,\\hat{w}_1)=(-5,10)\\)을 선택하여 선을 그려보고 적당한지 판단해보자\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\") \nWhat = torch.tensor([[-5.0],[10.0]])\nplt.plot(x,X@What,'--',label=r\"estimated line: $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 기울기와 절편 모두 너무 다르다\n- \\((\\hat{w}_0,\\hat{w}_1)=(2.5,3.5)\\)을 선택하여 선을 그려보고 적당한지 판단해보자\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\") \nWhat = torch.tensor([[2.5],[3.5]])\nplt.plot(x,X@What,'--',label=r\"estimated line: $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 기울기가 살짝 다른 듯 하다\n- \\((\\hat{w}_0,\\hat{w}_1)=(2.3,3.5)\\)을 선택하여 선을 그려보고 적당한지 판단해보자\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\") \nWhat = torch.tensor([[2.3],[3.5]])\nplt.plot(x,X@What,'--',label=r\"estimated: $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- \\((\\hat{w}_0,\\hat{w}_1)=(2.5,3.5)\\)를 했을 때와 \\((2.3,3,5)\\) 로 했을 때 중 어떤 것이 더 적당한가?\n\nA. loss 개념\n- (2.5,3.5) 가 더 적당해야할 것 같긴 한데 육안으로 판단 어려움\n- 이를 수식화하기 위해서 : loss의 개념 사용\n\n\\(loss = \\sum_{i=1}^{n}(y_i- \\hat{y}_i)^2 = \\sum_{i=1}^{n}\\big(y_i - (\\hat{w}_0+\\hat{w}_1x_i)\\big)^2\\)\n\n\\(=({\\bf y}-\\hat{\\bf y})^\\top({\\bf y}-\\hat{\\bf y})=({\\bf y}-{\\bf X}\\hat{\\bf W})^\\top({\\bf y}-{\\bf X}\\hat{\\bf W})\\)\n\n\nB. loss의 특징\n\n\\(y_i \\approx \\hat{y}_i\\) 일수록 loss 값이 작음\n\\(y_i \\approx \\hat{y}_i\\) 이 되도록 \\((\\hat{w}_0, \\hat{w}_1)\\)을 잘 찍으면 loss 값이 작음\n주황색 점선이 “적당할수록” loss 값이 작음\n\n\n\nC. loss 사용\n- 방법1 : \\(\\sum_{i=1}^{n}(y_i- \\hat{y}_i)^2\\)\n\nWhat = torch.tensor([[2.5],[3.5]])\nprint(f\"loss: {torch.sum((y - X@What)**2)}\")\n\nWhat = torch.tensor([[2.3],[3.5]])\nprint(f\"loss: {torch.sum((y - X@What)**2)}\")\n\nloss: 55.074012756347656\nloss: 59.3805046081543\n\n\n- 방법2 : \\(({\\bf y}-\\hat{\\bf y})^\\top({\\bf y}-\\hat{\\bf y})\\)\n\nWhat = torch.tensor([[2.5],[3.5]])\nprint(f\"loss: {(y - X@What).T @ (y - X@What)}\")\n\nWhat = torch.tensor([[2.3],[3.5]])\nprint(f\"loss: {(y - X@What).T @ (y - X@What)}\")\n\nloss: tensor([[55.0740]])\nloss: tensor([[59.3805]])\n\n\n\n\n\n5. 파이토치를 이용한 반복추정\n- 추정 전략 : 손실함수 + 경사하강법 * 1단계 : 아무 점선 긋기 * 2단계 : 1단계의 점선보다 loss값이 작은 하나의 직선으로 변경 * 3단계 : 1,2단계 반복\n\nA. 1단계 - 최초 점선\n- What 아무렇게나 설정\n\nWhat = torch.tensor([[-5.0],[10.0]])\nWhat\n\ntensor([[-5.],\n        [10.]])\n\n\n\nyhat = X@What\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\n\n\n\n\n\n\n\n\n\n\nB. 2단계 - update\n- ‘적당한 정도’ : loss 값이 작을수록 적당함\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat)\n\n\n\n\n\n\n\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875)\n\n\n- 현재 loss(=8587.6875)를 줄여야함\n\n최종적으로loss를 최소로 하는 \\((\\hat{w}_0,\\hat{w}_1)\\)을 구해야함\n함수의 최대값, 최소값을 컴퓨터로 찾는것 : ‘최적화’\n최적화의 방법 : 경사하강법\n\n- 경사하강법 (1차원)\n\n임의의 점을 찍음\n그 점에서 순간기울기를 구함 (접선) &lt;– 미분\n순간기울기(=미분계수)의 부호와 반대방향으로 점을 이동\n\n\n기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절 \\(\\to\\) \\(\\alpha\\)를 도입\n최종수식 :\\(\\hat{w} \\leftarrow \\hat{w} - \\alpha \\times \\frac{\\partial}{\\partial w}loss(w)\\)\n\n- 경사하강법 (2차원)\n\n\n임의의 점을 찍음\n그 점에서 순간기울기를 구함 (접평면) &lt;– 편미분\n순간기울기(=미분계수)의 부호와 반대방향으로 각각 점을 이동\n\n\n기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절 \\(\\to\\) \\(\\alpha\\)를 도입\n\n- 경사하강법 : loss를 줄이도록 \\(\\hat{W}\\)를 개선하는 방법\n\n수정값 = 원래값 - \\(\\alpha\\) \\(\\times\\) 기울어진 크기(=미분계수)\n\n미분계수와 반대방향으로 이동해야하기 때문에 마이너스 부호 사용\n\n\\(\\alpha\\)는 전체적인 보폭 크기 결정, 클수록 한번에 update에서 움직임이 큼\n\n- 우리가 구하고 싶은 것\n\n\\(\\hat{W}^{LSE}=\\underset{\\hat{W}}argmin ~ loss(\\hat{W})\\)\n\n- 요약\n\nx,X,W,y // X = [1 x], W = [w0, w1] (회귀분석에서는 W=β)\n회귀모형: y=X@W+ϵ = X@β+ϵ\ntrue: E(y)=X@W\nobserved: (x,y)\nestimated W = What = [w0hat, w1hat]’ &lt;– 아무값이나넣음\nestimated y = yhat = X@What = X@β̂\nloss = yhat이랑 y랑 얼마나 비슷한지 = sum((y-yhat)^2)\n(x,y) 보고 최적의 선분을 그리는것 = loss를 가장 작게 만드는 What = [w0hat, w1hat] 를 찾는것\n전략\n\n\n아무 What나 찍는다\n\n\n그거보다 더 나은 What을 찾는다.\n\n\n1-2를 반복한다.\n\n\n전략2가 어려운데, 이를 수행하는 방법이 경사하강법\n경사하강법 알고리즘: 더나은What = 원래What - \\(\\alpha\\)*미분값\n수식 \\[\\hat{\\bf W} \\leftarrow \\hat{\\bf W} - \\alpha \\times \\left.\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\right|_{{\\bf W}=\\hat{\\bf W}}\\]\n\n- 미분값 계산법 1) \\(\\to\\) 정확하지도 않고 번거로운 방법..\n\ndef l(w0,w1):\n    yhat = w0 + w1*x\n    return torch.sum((y-yhat)**2)\n\n\nl(-5,10)\n\ntensor(8587.6875)\n\n\n\nh=0.001\nprint((l(-5+h,10) - l(-5,10))/h)\nprint((l(-5,10+h) - l(-5,10))/h)\n\ntensor(-1341.7968)\ntensor(1190.4297)\n\n\n\nnew = What - 0.001 * torch.tensor([[-1341.7968],[1190.4297]])\nnew\n\ntensor([[-3.6582],\n        [ 8.8096]])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What,'-') # 원래What: 주황색\nplt.plot(x,X@new,'-') # 더나은What: 초록색\n\n\n\n\n\n\n\n\n- 수식\n\n편미분\n\\(\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\)\n\\(\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\)\n편미분 값을 이용\n\\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W}):= \\begin{bmatrix} \\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1}\\end{bmatrix}loss({\\bf W}) =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss({\\bf W}) \\\\ \\frac{\\partial}{\\partial w_1}loss({\\bf W})\\end{bmatrix}  =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1)\\end{bmatrix}\\]\n\n- 미분값 계산법 2) \\(\\to\\) 이것도 어려움…\n\nloss = (y - XWhat)'(y -  XWhat)\n= (y'- What'X')(y - XWhat)\n= y'y - y'XWhat - What'X'y + What'X'XWhat\nloss를 What으로 미분\nloss' = -X'y - X'y + 2X'XWhat \\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})= -2{\\bf X}^\\top {\\bf y} + 2{\\bf X}^\\top {\\bf X}{\\bf W}\\]\n\n\n-2*X.T@y + 2*X.T@X@What\n\ntensor([[-1342.2524],\n        [ 1188.9302]])\n\n\n- 미분값 계산법 3) (★)\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n- loss를 꼬리표의 근원인 What으로 미분\n\nloss.backward() \n\n- What 에 미분값이 저장\n\nWhat.grad\n\ntensor([[-1342.2524],\n        [ 1188.9305]])\n\n\n- 미분 전\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n None)\n\n\n\nloss.backward()\n\n- 미분 후\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-1342.2524],\n         [ 1188.9305]]))\n\n\n- 1회 업데이트 과정\n\nalpha=0.001\nprint(f\"{What.data} -- 수정전\")\nprint(f\"{-alpha*What.grad} -- 수정하는폭\")\nprint(f\"{What.data-alpha*What.grad} -- 수정후\")\nprint(f\"{torch.tensor([[2.5],[4]])} -- 참값\")\n\ntensor([[-5.],\n        [10.]]) -- 수정전\ntensor([[ 1.3423],\n        [-1.1889]]) -- 수정하는폭\ntensor([[-3.6577],\n        [ 8.8111]]) -- 수정후\ntensor([[2.5000],\n        [4.0000]]) -- 참값\n\n\n\nWbefore = What.data\nWafter = What.data - alpha * What.grad\nplt.plot(x,y,'o',label=r'observed data')\nplt.plot(x,X@Wbefore,'--', label=r\"$\\hat{\\bf y}_{before}={\\bf X}@\\hat{\\bf W}_{before}$\")\nplt.plot(x,X@Wafter,'--', label=r\"$\\hat{\\bf y}_{after}={\\bf X}@\\hat{\\bf W}_{after}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nC. 3단계 - iteration\n- What.grad = None을 꼭 해줘야함\n\nloss.backward() 의 역할\n\nWhat.grad \\(\\leftarrow\\) What.grad + What에서의미분값\n\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 최초의 직선을 만드는 값\nfor epoc in range(30):\n    yhat = X@What \n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    What.grad = None \n\n\nplt.plot(x,y,'o',label=r\"observed: $(x_i,y_i)$\")\nplt.plot(x,X@What.data,'--o', label=r\"estimated: $(x_i,\\hat{y}_i)$ -- after 30 iterations (=epochs)\", alpha=0.4 )\nplt.legend()"
  },
  {
    "objectID": "posts/1-1.torch(파이토치기본).html",
    "href": "posts/1-1.torch(파이토치기본).html",
    "title": "1-1. torch(파이토치 기본)",
    "section": "",
    "text": "1.import\n\nimport torch\n\n\n\n2.기초 지식\n- 선형대수학\n\n벡터와 행렬\n행렬의 곱셉\n트랜스포즈\n\n- 기초통계학(수리통계)\n\n정규분포, 이항분포\n모수, 추정\n\\(X_i \\overset{i.i.d.}{\\sim} N(0,1)\\)\n\n- 회귀분석\n\n독립변수(\\(y\\)), 설명변수(\\(X\\))\n\\({\\boldsymbol y} = {\\bf X}{\\boldsymbol \\beta} + {\\boldsymbol \\epsilon}\\)\n\n- 파이썬\n\n파이썬 기본문법\n넘파이, 판다스\n전반적인 클래스 지식 (__init__, self, …)\n상속\n\n\n\n3. torch\n\nA.벡터\n\ntorch.tensor([1,2,3])\n\ntensor([1, 2, 3])\n\n\n- 벡터끼리 덧셈\n\ntorch.tensor([1,2,3]) + torch.tensor([3,3,3])\n\ntensor([4, 5, 6])\n\n\n- 브로드캐스팅 가능 -&gt; 위에와 똑같은 기능\n\ntorch.tensor([1,2,3])+2\n\ntensor([3, 4, 5])\n\n\n\ntorch.tensor([1,2,3])+torch.tensor([2])\n\ntensor([3, 4, 5])\n\n\n\ntorch.tensor([1,2,3])+torch.tensor(2)\n\ntensor([3, 4, 5])\n\n\n\n\n\nB. 벡터와 매트릭스\n- 3x2 matrix\n\ntorch.tensor([[1,2],[3,4],[5,6]])\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- 3X1 matrix 는 3X1 열벡터(column vector)와 같음\n\ntorch.tensor([[1],[2],[3]]) \n\ntensor([[1],\n        [2],\n        [3]])\n\n\n- 1X2 matrix 는 1X2 행벡터(row vector)와 같음\n\ntorch.tensor([[1,2]]) \n\ntensor([[1, 2]])\n\n\n\nc. matrix 덧셈\n- 브로드캐스팅(숫자하나)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) - 1\n\ntensor([[0, 1],\n        [2, 3],\n        [4, 5]])\n\n\n- 아래와 같은 의미임\n\ntorch.tensor([[1,2],[3,4],[5,6]]) - torch.tensor([[1,1],[1,1],[1,1]])\n\ntensor([[0, 1],\n        [2, 3],\n        [4, 5]])\n\n\n- 브로드캐스팅(열)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-3],[-5]])\n\ntensor([[0, 1],\n        [0, 1],\n        [0, 1]])\n\n\n- 아래와 같은 의미임\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-1],[-3,-3],[-5,-5]])\n\ntensor([[0, 1],\n        [0, 1],\n        [0, 1]])\n\n\n- 브로드캐스팅(행)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-2]])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\n- 아래와 같은 의미임\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-2],[-1,-2],[-1,-2]])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\n잘못된 브로드캐스팅\n- 열로 브로드캐스팅 하려면 3X1 행렬이어야하지만 여기는 1X3 행렬\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-3,-5]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[20], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-3,-5]])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\n- 행으로 브로드캐스팅 하려면 1X2 행렬이어야하지만 여기는 2X1 행렬\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-2]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[21], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-2]])\n\nRuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0\n\n\n\n그냥 벡터를 넣으면 이상하게 행으로만 브로드캐스팅 됨\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-2])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\n- 열로는 안됨..\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-3,-5])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[23], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-3,-5])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\n\n\nD. 행렬곱\n정상적 행렬곱\n- (3X2) @ (2X1) = (3X1)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1],[2]])\n\ntensor([[ 5],\n        [11],\n        [17]])\n\n\n- (1X3) @ (3X2) = (1X2)\n\ntorch.tensor([[1,2,3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\ntensor([[22, 28]])\n\n\n잘못된 행렬곱\n- (3X2) @ (1X2) = (???)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1,2]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[26], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1,2]])\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 1x2)\n\n\n\n- (3X1) @ (3X2) = (???)\n\ntorch.tensor([[1],[2],[3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[27], line 1\n----&gt; 1 torch.tensor([[1],[2],[3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x1 and 3x2)\n\n\n\n이상하게 되는 것\n- (3X2) @ 행벡터(1X2)-&gt;(2X1)행렬로 바꿔주는듯 = (3X1) 행렬이 아닌 (1X3)행벡터로 나옴\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([1,2])\n\ntensor([ 5, 11, 17])\n\n\n- 행벡터(1X3) @ (3X2) = (1X2)\n\ntorch.tensor([1,2,3]) @ torch.tensor([[1,2],[3,4],[5,6]])\n\ntensor([22, 28])\n\n\n\n\nE. Transpose\n- 정방행렬 전치\n\ntorch.tensor([[1,2],[3,4]]).T \n\ntensor([[1, 3],\n        [2, 4]])\n\n\n- (NX1) 행렬 전치\n\ntorch.tensor([[1],[3]]).T \n\ntensor([[1, 3]])\n\n\n- (1XN) 행렬 전치\n\ntorch.tensor([[1,2]]).T \n\ntensor([[1],\n        [2]])\n\n\n\n\nF. reshape\n- 일반적인 사용\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,3)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n- Transpose와는 다르게 순서대로 reshape 해줌\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6,1)\n\ntensor([[1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\n- 차원 줄이기도 가능\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6)\n\ntensor([1, 2, 3, 4, 5, 6])\n\n\n- -1로 설정한 부분은 자동으로 지정됨\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,-1)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\n- -1만 넣으면 행벡터로 만들어버림\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1)\n\ntensor([1, 2, 3, 4, 5, 6])\n\n\n\ntorch.tensor([[[1,2],[2,30]],[[1,2],[3,3]]]).reshape(-1)\n\ntensor([ 1,  2,  2, 30,  1,  2,  3,  3])\n\n\n\n\nG. concat, stack (★★★)\n- concat\n\naxis=0 인 경우 0번째 차원을 기준으로 합쳐짐\naxis=1 인 경우 1번째 차원을 기준으로 합쳐짐\n\n\na = torch.tensor([[1],[3],[5]])\nb = torch.tensor([[2],[4],[6]])\ntorch.concat([a,b],axis=0)\n\ntensor([[1],\n        [3],\n        [5],\n        [2],\n        [4],\n        [6]])\n\n\n\na = torch.tensor([[1],[3],[5]])\nb = torch.tensor([[2],[4],[6]])\ntorch.concat([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- stack\n\naxis=0 : 0번째 차원을 추가\naxis=1 : 1번째 차원을 추가\n\n\na = torch.tensor([1,3,5])\nb = torch.tensor([2,4,6])\ntorch.stack([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DL2025",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMay 5, 2025\n\n\n9-1. 생성모형(Generative Adversarial Network(GAN))\n\n\n이상민 \n\n\n\n\nMay 4, 2025\n\n\n8-2. XAI, 설명 가능한 인공지능(Class Activation Map)\n\n\n이상민 \n\n\n\n\nMay 3, 2025\n\n\n8-1. 합성곱신경망(MNIST, CIFAR10, XAI란?)\n\n\n이상민 \n\n\n\n\nMay 2, 2025\n\n\n7-2. 합성곱신경망(CNN 핵심 레이어, CNN의 학습원리, FashionMNIST)\n\n\n이상민 \n\n\n\n\nMay 1, 2025\n\n\n7-1. 합성곱신경망(CNN 장점, CNN 핵심 레이어)\n\n\n이상민 \n\n\n\n\nApr 30, 2025\n\n\n6-2. 신경망(다항분류, Fashion MNIST)\n\n\n이상민 \n\n\n\n\nApr 29, 2025\n\n\n6-1. 신경망(데이터분석 코딩패턴)\n\n\n이상민 \n\n\n\n\nApr 28, 2025\n\n\n5-2. 신경망(신경망의 표현, GPU사용법, 확률적경사하강법)\n\n\n이상민 \n\n\n\n\nApr 27, 2025\n\n\n5-1. 신경망(예측, 시벤코정리의 이면, 드랍아웃)\n\n\n이상민 \n\n\n\n\nApr 26, 2025\n\n\n4-2. 신경망(꺽인 그래프의 한계, 시벤코 정리, MNIST)\n\n\n이상민 \n\n\n\n\nApr 25, 2025\n\n\n4-1. 신경망(로지스틱의 한계 극복)\n\n\n이상민 \n\n\n\n\nApr 24, 2025\n\n\n3-2. 로지스틱(sig, BCELoss, Adam)\n\n\n이상민 \n\n\n\n\nMar 28, 2025\n\n\n3-1. 회귀,로지스틱(파이토치식 코딩패턴 2, 로지스틱 모형)\n\n\n이상민 \n\n\n\n\nMar 27, 2025\n\n\n2-2. 회귀(파라메터 학습과정, MSE, 파이토치식 코딩패턴1)\n\n\n이상민 \n\n\n\n\nMar 26, 2025\n\n\n1-2, 2-1. 회귀(회귀모형, 손실함수, 파이토치를 이용한 추정)\n\n\n이상민 \n\n\n\n\nMar 25, 2025\n\n\n1-1. torch(파이토치 기본)\n\n\n이상민 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/3-1.회귀,로지스틱(파이토치식코딩패턴2,로지스틱모형).html",
    "href": "posts/3-1.회귀,로지스틱(파이토치식코딩패턴2,로지스틱모형).html",
    "title": "3-1. 회귀,로지스틱(파이토치식 코딩패턴 2, 로지스틱 모형)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport matplotlib.pyplot as plt \n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. 파이토치식 코딩패턴 2\n- 복습\n\n모델링 : X \\(\\to\\) y 가는 패턴(추세선)을 찾는 것\n관측자료 (x,y) – with error\n추세선(underlying) – (x,yhat=X@W) without error\n모델링: 에러가포함된 자료에서 error-free 한 structure를 찾는것\n모델링의 철칙: error-free 한 structure를 찾으려고 노력해야지.. error를 따라가려고 노력하면 X\n오차: error-free한 스트럭쳐(모델)이랑 실제관측데이터의 갭이 있는데, 이 갭을 설명해주는 역할\n\n- 데이터 만들기\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\nX = torch.stack([torch.ones(100),x],axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\nx = X[:,[1]]\n\n\nA. bias의 사용\n- net에서 bias를 사용\n\nin_features=2 \\(\\to\\) in_features=1\nbias=False \\(\\to\\) bias=True\nX(1벡터 포함) \\(\\to\\) x사용\n\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=1,\n    out_features=1,\n    bias=True\n) # net(x) = x@net.weight.T + net.bias \nnet.bias.data = torch.tensor([-5.0])\nnet.weight.data = torch.tensor([[10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(x)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.bias.data, net.weight.data\n\n(tensor([2.4290]), tensor([[4.0144]]))\n\n\n\n\n\nB. 잘못된 코드(비효율적)\n- bias 디폴트로 True\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과 시각화\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');\n\n\n\n\n\n\n\n\n- 나쁘지 않다?\n\n절편의 회귀계수(가중치)를 두 개로 나눠서 추정해서..합이 2.5가 되긴 함 \\(\\to\\) 비효율적\n\n\nnet.weight, net.bias\n\n(Parameter containing:\n tensor([[-1.2161,  4.0080]], requires_grad=True),\n Parameter containing:\n tensor([3.6610], requires_grad=True))\n\n\n\n\n3. 로지스틱 모형\n\nA. \\(\\hat{y} = ??\\)\n- \\(X\\) 를 가지고 \\(y\\)를 맞추는 아래와 같은 문제!\n\nx = torch.tensor([-6,-5,-4,-3,-2,-1, 0, 1, 2, 3, 4, 5, 6.0]).reshape(-1,1)\ny = torch.tensor([ 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1]).reshape(-1,1)\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n- 아래와 같이 모형화\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x)/(1+torch.exp(x)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nB. \\(\\hat{\\bf y} = \\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))}\\)\n- 산점도가 꼭 아래와 같은 방식이 아니라면?\n\n\\(x\\)가 증가할수록 \\(y\\)가 0이 된다면?\n0 근처에서 변화가 일어나지 않고 2 긑처에서 변화가 일어난다면?\n변화가 좀더 급하거나 환만하게 일어난다면?\n\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(5*x+3)/(1+torch.exp(5*x+3)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n#plt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x)/(1+torch.exp(x)),'o--', label = \"underlying type1 (without error)\", color=\"C1\")\nplt.plot(x,torch.exp(5*x)/(1+torch.exp(5*x)),'o--', label = \"underlying type2 (without error)\", color=\"C2\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 회귀 vs 로지스틱\n\n\\({\\bf X} \\to {\\bf y}\\) 에 대한 패턴이\n\\(\\text{linr}({\\bf X}) \\approx {\\bf y}\\) 이라면 회귀!\n\\({\\bf X} \\to {\\bf y}\\) 에 대한 패턴이\n\\(\\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))} \\approx {\\bf y}\\)이라면 로지스틱!\n\n\n\nC. 로지스틱 모형\n- \\(x\\)가 커질수록 \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 \\(\\leftarrow\\) 외워야함!!\n\n\\(y_i \\sim {\\cal B}(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)} = \\frac{1}{1+\\exp(-w_0-w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\n- 회귀모형과 로지스틱 모형의 비교\n\n회귀모형: \\(y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)\\)[1]\n로지스틱: \\(y_i \\sim {\\cal B}\\big(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\big)\\)\n\n- 우리가 예측하고 싶은것\n\n회귀모형: 정규분포의 평균을 예측하고 싶음. 즉 \\(w_0+w_1x_i\\)를 예측하고 싶음. 예측값으로는 \\(\\hat{w}_0 + \\hat{w}_1x_i\\)를 사용!\n로지스틱: 베르누이의 평균을 예측하고 싶음. 즉 \\(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)를 예측하고 싶음. 예측값으로는 \\(\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}\\)를 사용!"
  },
  {
    "objectID": "posts/2-2.회귀(파라메터학습과정,MSE,파이토치식코딩패턴).html",
    "href": "posts/2-2.회귀(파라메터학습과정,MSE,파이토치식코딩패턴).html",
    "title": "2-2. 회귀(파라메터 학습과정, MSE, 파이토치식 코딩패턴1)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt \n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. 파라메터 학습과정\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\nX = torch.stack([torch.ones(100),x],axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\nx = X[:,[1]]\n\n\nA. 학습과정 print\n\nWhat = torch.tensor([[-5.0],[10.0]], requires_grad=True)\nalpha = 0.001\nprint(f\"시작값 = {What.data.reshape(-1)}\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - alpha * What.grad\n    print(f'loss = {loss:.2f} \\n업데이트폭 = {-alpha * What.grad.reshape(-1)} \\n업데이트결과: {What.data.reshape(-1)}')\n    What.grad = None\n\n시작값 = tensor([-5., 10.])\nloss = 8587.69 \n업데이트폭 = tensor([ 1.3423, -1.1889]) \n업데이트결과: tensor([-3.6577,  8.8111])\nloss = 5675.21 \n업데이트폭 = tensor([ 1.1029, -0.9499]) \n업데이트결과: tensor([-2.5548,  7.8612])\nloss = 3755.64 \n업데이트폭 = tensor([ 0.9056, -0.7596]) \n업데이트결과: tensor([-1.6492,  7.1016])\nloss = 2489.58 \n업데이트폭 = tensor([ 0.7431, -0.6081]) \n업데이트결과: tensor([-0.9061,  6.4935])\nloss = 1654.04 \n업데이트폭 = tensor([ 0.6094, -0.4872]) \n업데이트결과: tensor([-0.2967,  6.0063])\nloss = 1102.32 \n업데이트폭 = tensor([ 0.4995, -0.3907]) \n업데이트결과: tensor([0.2028, 5.6156])\nloss = 737.84 \n업데이트폭 = tensor([ 0.4091, -0.3136]) \n업데이트결과: tensor([0.6119, 5.3020])\nloss = 496.97 \n업데이트폭 = tensor([ 0.3350, -0.2519]) \n업데이트결과: tensor([0.9469, 5.0501])\nloss = 337.71 \n업데이트폭 = tensor([ 0.2742, -0.2025]) \n업데이트결과: tensor([1.2211, 4.8477])\nloss = 232.40 \n업데이트폭 = tensor([ 0.2243, -0.1629]) \n업데이트결과: tensor([1.4454, 4.6848])\nloss = 162.73 \n업데이트폭 = tensor([ 0.1834, -0.1311]) \n업데이트결과: tensor([1.6288, 4.5537])\nloss = 116.63 \n업데이트폭 = tensor([ 0.1500, -0.1056]) \n업데이트결과: tensor([1.7787, 4.4480])\nloss = 86.13 \n업데이트폭 = tensor([ 0.1226, -0.0851]) \n업데이트결과: tensor([1.9013, 4.3629])\nloss = 65.93 \n업데이트폭 = tensor([ 0.1001, -0.0687]) \n업데이트결과: tensor([2.0014, 4.2942])\nloss = 52.57 \n업데이트폭 = tensor([ 0.0818, -0.0554]) \n업데이트결과: tensor([2.0832, 4.2388])\nloss = 43.72 \n업데이트폭 = tensor([ 0.0668, -0.0447]) \n업데이트결과: tensor([2.1500, 4.1941])\nloss = 37.86 \n업데이트폭 = tensor([ 0.0545, -0.0361]) \n업데이트결과: tensor([2.2045, 4.1579])\nloss = 33.97 \n업데이트폭 = tensor([ 0.0445, -0.0292]) \n업데이트결과: tensor([2.2490, 4.1287])\nloss = 31.40 \n업데이트폭 = tensor([ 0.0363, -0.0236]) \n업데이트결과: tensor([2.2853, 4.1051])\nloss = 29.70 \n업데이트폭 = tensor([ 0.0296, -0.0191]) \n업데이트결과: tensor([2.3150, 4.0860])\nloss = 28.57 \n업데이트폭 = tensor([ 0.0242, -0.0155]) \n업데이트결과: tensor([2.3392, 4.0705])\nloss = 27.83 \n업데이트폭 = tensor([ 0.0197, -0.0125]) \n업데이트결과: tensor([2.3589, 4.0580])\nloss = 27.33 \n업데이트폭 = tensor([ 0.0161, -0.0101]) \n업데이트결과: tensor([2.3750, 4.0479])\nloss = 27.00 \n업데이트폭 = tensor([ 0.0131, -0.0082]) \n업데이트결과: tensor([2.3881, 4.0396])\nloss = 26.79 \n업데이트폭 = tensor([ 0.0107, -0.0067]) \n업데이트결과: tensor([2.3988, 4.0330])\nloss = 26.64 \n업데이트폭 = tensor([ 0.0087, -0.0054]) \n업데이트결과: tensor([2.4075, 4.0276])\nloss = 26.55 \n업데이트폭 = tensor([ 0.0071, -0.0044]) \n업데이트결과: tensor([2.4146, 4.0232])\nloss = 26.48 \n업데이트폭 = tensor([ 0.0058, -0.0035]) \n업데이트결과: tensor([2.4204, 4.0197])\nloss = 26.44 \n업데이트폭 = tensor([ 0.0047, -0.0029]) \n업데이트결과: tensor([2.4251, 4.0168])\nloss = 26.41 \n업데이트폭 = tensor([ 0.0038, -0.0023]) \n업데이트결과: tensor([2.4290, 4.0144])\n\n\n\n\nB. yhat의 관점에서 시각화\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nplt.plot(x,y,'o',label = \"observed\")\nfig = plt.gcf()\nax = fig.gca()\nax.plot(x,X@What.data,'--',color=\"C1\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - alpha * What.grad\n    ax.plot(x,X@What.data,'--',color=\"C1\",alpha=0.1)\n    What.grad = None\n\n\n\n\n\n\n\n\n\n\nC. loss의 관점에서 시각화\n\ndef plot_loss():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax.azim = 30  ## 3d plot의 view 조절 \n    ax.dist = 8   ## 3d plot의 view 조절 \n    ax.elev = 5   ## 3d plot의 view 조절 \n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    plt.close(fig)  # 자동 출력 방지\n    return fig\n\n\ndef l(w0hat,w1hat):\n    yhat = w0hat + w1hat*x\n    return torch.sum((y-yhat)**2)\n\n\nfig = plot_loss()\nax = fig.gca()\nax.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\nax.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue', label=r\"initial $\\hat{\\bf W}=[-5, 10]'$\")\nax.legend()\nfig\n\n/tmp/ipykernel_144216/2229765328.py:13: MatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n\n\nD. 애니메이션\n\nfrom matplotlib import animation\n\n\nplt.rcParams['figure.figsize'] = (7.5,2.5)\nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n\ndef show_animation(alpha=0.001):\n    ## 1. 히스토리 기록을 위한 list 초기화\n    loss_history = [] \n    yhat_history = [] \n    What_history = [] \n\n    ## 2. 학습 + 학습과정기록\n    What= torch.tensor([[-5.0],[10.0]],requires_grad=True)\n    What_history.append(What.data.tolist())\n    for epoc in range(30): \n        yhat=X@What ; yhat_history.append(yhat.data.tolist())\n        loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n        loss.backward() \n        What.data = What.data - alpha * What.grad; What_history.append(What.data.tolist())\n        What.grad = None    \n\n    ## 3. 시각화 \n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n    #### ax1: yhat의 관점에서.. \n    ax1.plot(x,y,'o',label=r\"$(x_i,y_i)$\")\n    line, = ax1.plot(x,yhat_history[0],label=r\"$(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    #### ax2: loss의 관점에서.. \n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax2.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax2.azim = 30  ## 3d plot의 view 조절 \n    ax2.dist = 8   ## 3d plot의 view 조절 \n    ax2.elev = 5   ## 3d plot의 view 조절 \n    ax2.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax2.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax2.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax2.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    ax2.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\n    ax2.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue')\n    ax2.legend()\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(What_history)[epoc,0],np.array(What_history)[epoc,1],loss_history[epoc],color='grey')\n        fig.suptitle(f\"alpha = {alpha} / epoch = {epoc}\")\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\nani = show_animation(alpha=0.001)\nani\n\n/tmp/ipykernel_144216/464110397.py:36: MatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nE. 학습률(\\(\\alpha\\)) 다양하게\n- \\(\\alpha\\)가 너무 작아서 비효율적\n\nshow_animation(alpha=0.0001)\n\n/tmp/ipykernel_144216/464110397.py:36: MatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- \\(\\alpha\\) 가 크다고 무조건 좋은것도 아님\n\nshow_animation(alpha=0.0083)\n\n/tmp/ipykernel_144216/464110397.py:36: MatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 수렴을 안할수도 있음\n\nshow_animation(alpha=0.0085)\n\n/tmp/ipykernel_144216/464110397.py:36: MatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- \\(\\alpha\\) 를 너무 크게함\n\nshow_animation(alpha=0.01)\n\n/tmp/ipykernel_144216/464110397.py:36: MatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nplt.rcdefaults()\nplt.rcParams['figure.figsize'] = 4.5,3.0 \n\n\n\n\n3. SSE \\(\\to\\) MSE\n- 학습률 선택하는 것이 중요\n- 손실함수를 SSE로 설정하면 학습률 선택에서 비효율적\n- \\(\\to\\) MSE !!!\n손실함수가 SSE일 때 코드\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    loss = torch.sum((y-yhat)**2)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.001 * What.grad\n    What.grad = None\n\n\nWhat.data\n\ntensor([[2.4290],\n        [4.0144]])\n\n\n손실함수가  MSE일 때 코드\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    loss = torch.sum((y-yhat)**2)/100 # torch.mean((y-yhat)**2)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n\nWhat.data\n\ntensor([[2.4290],\n        [4.0144]])\n\n\n\n\n4. 파이토치식 코딩패턴 1\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\nX = torch.stack([torch.ones(100),x],axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\nx = X[:,[1]]\n\n\nA. 기본 패턴 (★)\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    loss = torch.sum((y-yhat)**2)/100\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');\n\n\n\n\n\n\n\n\n\n\nB. Step2 loss값 계산 \\(\\to\\) loss_fn 이용\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    #loss = torch.sum((y-yhat)**2)/100\n    loss = loss_fn(yhat,y) # 여기서는 큰 상관없지만 습관적으로 yhat을 먼저넣는 연습을 하자!!\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');\n\n\n\n\n\n\n\n\n\n\nC. Step3 yhat 계산 \\(\\to\\) net 이용\n- 원래 방식\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nyhat= X@What\nyhat[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n# yhat = net(X) \nnet = torch.nn.Linear(\n    in_features=2, # X:(n,2) --&gt; 2 \n    out_features=1, # yhat:(n,1) --&gt; 1 \n    bias=False \n)\n\n- .T(전치를 꼭 해서 넣어줘야함)\n\nnet.weight.data = torch.tensor([[-5.0], [10.0]]).T\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n- 아래 값이 모두 같은 것을 알 수 있음\n\nnet(X)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(X@What)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(X@net.weight.T)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n- loss_fn, net 사용 코드\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat\n    # yhat = X@What \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    net.weight.data = net.weight.data - 0.1 * net.weight.grad\n    net.weight.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');\n\n\n\n\n\n\n\n\n\n\nD. Step4 update \\(\\to\\) optimizer 이용\n- 기존의 방식\n\n## -- 준비과정 -- ## \n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n\n\n## -- 1에폭진행 -- ## \n# step1: \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nprint(net.weight.data)\nnet.weight.grad = None\n\ntensor([[-5., 10.]])\ntensor([[-3.6577,  8.8111]])\n\n\n\n## -- 2에폭진행 -- ## \n# step1: 2에폭진행\nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nprint(net.weight.data)\nnet.weight.grad = None\n\ntensor([[-3.6577,  8.8111]])\ntensor([[-2.5548,  7.8612]])\n\n\n- optimizer 이용한 코드\n\n## -- 준비과정 -- ## \n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비\noptimizr = torch.optim.SGD(net.parameters(),lr=0.1) #이게 추가됨\n\n\n## -- 1에폭진행 -- ## \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\n#net.weight.data = net.weight.data - 0.1 * net.weight.grad\noptimizr.step()\nprint(net.weight.data)\n#net.weight.grad = None\noptimizr.zero_grad()\n\ntensor([[-5., 10.]])\ntensor([[-3.6577,  8.8111]])\n\n\n\n## -- 2에폭진행 -- ## \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\n#net.weight.data = net.weight.data - 0.1 * net.weight.grad\noptimizr.step()\nprint(net.weight.data)\n#net.weight.grad = None\noptimizr.zero_grad()\n\ntensor([[-3.6577,  8.8111]])\ntensor([[-2.5548,  7.8612]])\n\n\n- 최종 loss_fn, net, optimizer 사용 코드\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/3-2.로지스틱(sig,BCELoss,Adam).html",
    "href": "posts/3-2.로지스틱(sig,BCELoss,Adam).html",
    "title": "3-2. 로지스틱(sig, BCELoss, Adam)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport matplotlib.pyplot as plt \nimport numpy as np\nimport pandas as pd\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. 로지스틱 -sig(linr(x))\n\nA. 희귀모형과 로지스틱\n- 모형의 비교\n\n회귀모형: \\(y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)\\)[1]\n로지스틱: \\(y_i \\sim {\\cal B}\\big(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\big)\\)\n\n- 우리가 예측하고 싶은것\n\n회귀모형: 정규분포의 평균을 예측하고 싶음. 즉 \\(w_0+w_1x_i\\)를 예측하고 싶음. 예측값으로는 \\(\\hat{w}_0 + \\hat{w}_1x_i\\)를 사용!\n로지스틱: 베르누이의 평균을 예측하고 싶음. 즉 \\(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)를 예측하고 싶음. 예측값으로는 \\(\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}\\)를 사용!\n\n\n\nB. 데이터 - 스펙과 취업\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0,w1 = -1, 5\nprob = torch.exp(w0+w1*x) / (1+torch.exp(w0+w1*x)) \ny = torch.bernoulli(prob)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'.',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nC. Step1 : net 설계 (모델링)\n- 최초의 곡선\n\n임의의 \\(\\hat{w_0}, \\hat{w_1}\\) 설정\n초기값 \\(\\hat{w_0}=-0.8\\), \\(\\hat{w_1}=-0.3\\)\n실제값 \\(\\hat{w_0}=-1\\), \\(\\hat{w_1}=5\\)\n\n- 방법1 : l1, sigmoid\n\nl1 = torch.nn.Linear(1,1)\nl1(x)\n\ntensor([[ 0.6311],\n        [ 0.6304],\n        [ 0.6297],\n        ...,\n        [-0.6902],\n        [-0.6909],\n        [-0.6916]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n\n\ndef sigmoid(x):\n    return torch.exp(x)/(1+torch.exp(x))\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,sigmoid(l1(x)).data,'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 방법2 : l1, a1\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n\n\na1 = torch.nn.Sigmoid()\n\n- 직접 만든 함수함수와 결과 같음\n\nsigmoid(l1(x)), a1(l1(x))\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;DivBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;))\n\n\n- 방법3 : l1, a1 \\(\\to\\) net\n\n현재 구조\n\n\\[{\\bf x} \\overset{l_1}{\\to} {\\bf u} \\overset{a_1}{\\to} {\\bf v} = \\hat{\\bf y}\\]\n\n함수 \\(l_1, a_1\\) 의 합성을 하나로 묶기\n\n\\[(a_1\\circ l_1)({\\bf x}) := net({\\bf x})\\] - 한번에 이런 기능을 해주는 \\(net\\) 만들기\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\na1 = torch.nn.Sigmoid()\n\n\nnet = torch.nn.Sequential(l1,a1)\n\n- 셋 다 같은 결과\n\nnet(x), a1(l1(x)), sigmoid(l1(x))\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;DivBackward0&gt;))\n\n\n- net 구조 살펴보기\n\nnet[0], net[1]\n\n(Linear(in_features=1, out_features=1, bias=True), Sigmoid())\n\n\n\nl1 is net[0]\n\nTrue\n\n\n\na1 is net[1]\n\nTrue\n\n\n- 방법4 : net을 바로 만들기\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.3]])\nnet[0].bias.data = torch.tensor([-0.8])\nyhat = net(x)\n\n\nnet(x)\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\n\nD. Step 1~4\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n\nfor epoc in range(4900):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 5000 epochs')\n\nText(0.5, 1.0, 'after 5000 epochs')\n\n\n\n\n\n\n\n\n\n\n\n\n3. 학습과정 시각화, 문제인식\n\nA. 시각화를 위한 준비\n\ndef plot_loss(loss_fn, ax=None, Wstar=[-1,5]):\n    w0hat,w1hat =torch.meshgrid(torch.arange(-10,3,0.1),torch.arange(-1,10,0.1),indexing='ij')\n    w0hat = w0hat.reshape(-1)\n    w1hat = w1hat.reshape(-1)\n    def l(w0hat,w1hat):\n        yhat = torch.exp(w0hat+w1hat*x)/(1+torch.exp(w0hat+w1hat*x))\n        return loss_fn(yhat,y) \n    loss = list(map(l,w0hat,w1hat))\n    #---#\n    if ax is None: \n        fig = plt.figure()\n        ax = fig.add_subplot(1,1,1,projection='3d')\n    ax.scatter(w0hat,w1hat,loss,s=0.001) \n    ax.scatter(w0hat[::20],w1hat[::20],loss[::20],s=0.1,color='C0') \n    w0star,w1star = np.array(Wstar).reshape(-1)\n    ax.scatter(w0star,w1star,l(w0star,w1star),s=200,marker='*',color='red',label=f\"W=[{w0star:.1f},{w1star:.1f}]\")\n    #---#\n    ax.elev = 15\n    #ax.dist = -20\n    ax.azim = 75    \n    ax.legend()\n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-10,-5,0])  # x축 틱 간격 설정\n    ax.set_yticks([-10,0,10])  # y축 틱 간격 설정\n\n\ndef _learn_and_record(net, loss_fn, optimizr):\n    yhat_history = [] \n    loss_history = []\n    What_history = []\n    Whatgrad_history = []\n    What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n    for epoc in range(100): \n        ## step1 \n        yhat = net(x)\n        ## step2 \n        loss = loss_fn(yhat,y)\n        ## step3\n        loss.backward() \n        ## step4 \n        optimizr.step()\n        ## record \n        if epoc % 5 ==0: \n            yhat_history.append(yhat.reshape(-1).data.tolist())\n            loss_history.append(loss.item())\n            What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n            Whatgrad_history.append([net[0].bias.grad.item(), net[0].weight.grad.item()])\n        optimizr.zero_grad() \n        \n    return yhat_history, loss_history, What_history, Whatgrad_history\n    \ndef show_animation(net, loss_fn, optimizr):\n    yhat_history,loss_history,What_history,Whatgrad_history = _learn_and_record(net,loss_fn,optimizr)\n    \n    fig = plt.figure(figsize=(10,5))\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n    ## ax1: 왼쪽그림 \n    ax1.scatter(x,y,alpha=0.01)\n    ax1.scatter(x[0],y[0],color='C0',label=r\"observed data = $(x_i,y_i)$\")\n    ax1.plot(x,prob,'--',label=r\"prob (true) = $(x_i,\\frac{exp(-1+5x_i)}{1+exp(-1+5x_i)})$\")    \n    line, = ax1.plot(x,yhat_history[0],'--',label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    ## ax2: 오른쪽그림 \n    plot_loss(loss_fn,ax2)\n    ax2.scatter(np.array(What_history)[0,0],np.array(What_history)[0,1],loss_history[0],color='blue',s=200,marker='*')    \n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        w0hat = np.array(What_history)[epoc,0]\n        w1hat = np.array(What_history)[epoc,1]\n        w0hatgrad = np.array(Whatgrad_history)[epoc,0]\n        w1hatgrad = np.array(Whatgrad_history)[epoc,1]\n        ax2.scatter(w0hat,w1hat,loss_history[epoc],color='grey')\n        ax2.set_title(f\"What.grad=[{w0hatgrad:.4f},{w1hatgrad:.4f}]\",y=0.8)\n        fig.suptitle(f\"epoch={epoc*5} // What=[{w0hat:.2f},{w1hat:.2f}] // Loss={loss_fn.__class__.__name__} // Opt={optimizr.__class__.__name__}\")\n        return line\n    ani = animation.FuncAnimation(fig, animate, frames=20)    \n    plt.close()\n    return ani\n\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n\nloss_fn = torch.nn.MSELoss()\nplot_loss(loss_fn)\n\n\n\n\n\n\n\n\n\ntorch.manual_seed(42)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nB. 좋은 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n\n\nC. 가능성 있는 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n\n\nD. 최악의 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n\n\n\n4. 손실함수의 개선\n\nA. BCE Loss를 사용해서 학습\n- BCE Loss\n\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\)\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    #loss = torch.mean((y-yhat)**2) # loss_fn(yhat,y)\n    loss = -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat))\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n- BEC Loss 불러와서 쓰기\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) # yhat부터 써야함\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n\n\nB. Loss Function 시각화\n- MSE Loss\n\nplot_loss(torch.nn.MSELoss())\n\n\n\n\n\n\n\n\n- BCE Loss\n\nplot_loss(torch.nn.BCELoss())\n\n\n\n\n\n\n\n\n\nfig = plt.figure()\nax1 = fig.add_subplot(1,2,1,projection='3d')\nax2 = fig.add_subplot(1,2,2,projection='3d')\nplot_loss(torch.nn.MSELoss(),ax1)\nplot_loss(torch.nn.BCELoss(),ax2)\n\n\n\n\n\n\n\n\n\n\nC. 좋은 초기값 비교\n- MSE Loss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCE Loss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nD. 가능성 있는 초기값\n- MSE Loss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n- BCE Loss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n\n\nE. 최악의 초기값\n- MSE Loss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n- BCE Loss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n\n\n\n5. 옵티마이저 개선\n\nA. 좋은 초기값\n- MSE Loss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8470])\nnet[0].weight.data = torch.tensor([[-0.3467]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- MSE Loss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nB. 가능성 있는 초기값\n- MSE Loss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n- MSE Loss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n\n\nC. 최악의 초기값\n- MSE Loss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n- MSE Loss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n\n6. 로지스틱의 한계\n\nA. 기사\n\n스펙이 너무 높아도 취업이 안됨\n\n\n\nB. 가짜데이터 (스펙의 역설)\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\ndf\n\n\n\n\n\n\n\n\nx\nprob\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nC. 로지스틱 적합\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---# \nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data, '--', label= r\"prob (estimated) = $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nD. 로지스틱 한계극복 아이디어\n- sigmoid를 넣기 전의 상태가 직선이 아니라 꺽이는 직선이어야 함\n\na = torch.nn.Sigmoid()\n\n\nfig,ax = plt.subplots(4,2,figsize=(8,8))\nu1 = torch.tensor([-6,-4,-2,0,2,4,6])\nu2 = torch.tensor([6,4,2,0,-2,-4,-6])\nu3 = torch.tensor([-6,-2,2,6,2,-2,-6])\nu4 = torch.tensor([-6,-2,2,6,4,2,0])\nax[0,0].plot(u1,'--o',color='C0',label = r\"$u_1$\")\nax[0,0].legend()\nax[0,1].plot(a(u1),'--o',color='C0',label = r\"$a(u_1)=\\frac{exp(u_1)}{exp(u_1)+1}$\")\nax[0,1].legend()\nax[1,0].plot(u2,'--o',color='C1',label = r\"$u_2$\")\nax[1,0].legend()\nax[1,1].plot(a(u2),'--o',color='C1',label = r\"$a(u_2)=\\frac{exp(u_2)}{exp(u_2)+1}$\")\nax[1,1].legend()\nax[2,0].plot(u3,'--o',color='C2', label = r\"$u_3$\")\nax[2,0].legend()\nax[2,1].plot(a(u3),'--o',color='C2', label = r\"$a(u_3)=\\frac{exp(u_3)}{exp(u_3)+1}$\")\nax[2,1].legend()\nax[3,0].plot(u4,'--o',color='C3', label = r\"$u_4$\")\nax[3,0].legend()\nax[3,1].plot(a(u4),'--o',color='C3', label = r\"$a(u_4)=\\frac{exp(u_4)}{exp(u_4)+1}$\")\nax[3,1].legend()"
  },
  {
    "objectID": "posts/5-2.신경망(신경망의표현,GPU사용법,확률적경사하강법).html",
    "href": "posts/5-2.신경망(신경망의표현,GPU사용법,확률적경사하강법).html",
    "title": "5-2. 신경망(신경망의 표현, GPU사용법, 확률적경사하강법)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport matplotlib.pyplot as plt\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. 신경망의 표현\n- 신경망의 표현: \\({\\bf X} \\to \\hat{\\bf y}\\) 로 가는 과정을 그림으로 표현\n\nA. 로지스틱\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\bf y}}\\]\n- 모든 observation과 가중치를 명시한 버전\n(표현1)\n\n\n단점: 똑같은 그림의 반복이 너무 많음\n\n- observation 반복을 생략한 버전들\n(표현2) 모든 \\(i\\)에 대하여 아래의 그림을 반복한다고 하면 (표현1)과 같다.\n\n(표현3) 그런데 (표현2)에서 아래와 같이 \\(x_i\\), \\(y_i\\) 대신에 간단히 \\(x\\), \\(y\\)로 쓰는 경우도 많음\n\n- 1을 생략한 버전들\n(표현4) bais=False 대신에 bias=True를 주면 1을 생략할 수 있음\n\n(표현4의 수정) \\(\\hat{w}_1\\)대신에 \\(\\hat{w}\\)를 쓰는 것이 더 자연스러움\n\n(표현5) 선형변환의 결과는 아래와 같이 \\(u\\)로 표현하기도 한다.\n\n\n다이어그램은 그리는 사람의 취향에 따라 그리는 방법이 조금씩 다릅니다. 즉 교재마다 달라요.\n\n\n\nB. 스펙의역설\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\bf y}}\\]\n참고: 코드로 표현\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Sigmoid()\n)\n- 이해를 위해서 예젠에 다루었던 아래의 상황을 고려하자.\n\n(강의노트의 표현)\n\n(좀 더 일반화된 표현) 상황을 일반화하면 아래와 같다.\n\n* Layer의 개념: \\({\\bf X}\\)에서 \\(\\hat{\\boldsymbol y}\\)로 가는 과정은 “선형변환+비선형변환”이 반복되는 구조이다. “선형변환+비선형변환”을 하나의 세트로 보면 아래와 같이 표현할 수 있다.\n\n\\(\\underset{(n,1)}{\\bf X}  \\overset{l_1}{\\to} \\left( \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\right) \\overset{l_2}{\\to} \\left(\\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}\\right), \\quad  \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{net({\\bf X})}=\\underset{(n,1)}{\\hat{\\bf y}}\\)\n\n이것을 다이어그램으로 표현한다면 아래와 같다.\n(선형+비선형을 하나의 Layer로 묶은 표현)\n\nLayer를 세는 방법\n\n제 방식: 학습가능한 파라메터가 몇층으로 있는지… &lt;– 이것만 기억하세여\n일부 교재 설명: 입력층은 계산하지 않음, activation layer는 계산하지 않음. &lt;– 무시하세요.. 이러면 헷갈립니다..\n위의 예제의 경우 number of layer = 2 이다.\n\nHidden Layer의 수를 세는 방법\n\n제 방식: Hidden Layer의 수 = Layer의 수 -1 &lt;– 이걸 기억하세여..\n\n일부 교재 설명: Layer의 수 = Hidden Layer의 수 + 출력층의 수 = Hidden Layer의 수 + 1 &lt;– 기억하지 마세여\n위의 예제의 경우 number of hidden layer = 1 이다.\n\n\nImportant\n무조건 학습가능한 파라메터가 몇겹으로 있는지만 판단하세요. 딴거 아무것도 생각하지마세여\n## 예시1 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n)\n## 예시2 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid(),\n)\n## 예시3 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n) \n## 예시4 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n) \n## 예시5 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층    \n) \n## 예시6 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층  \n    torch.nn.Sigmoid()\n) \n\n\nImportant\n문헌에 따라서 레이어를 세는 개념이 제가 설명한 방식과 다른경우가 있습니다. 제가 설명한 방식보다 1씩 더해서 셉니다. 즉 아래의 경우 레이어를 3개로 카운트합니다.\n## 예시1 -- 문헌에 따라 3층으로 세는 경우가 있음 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n)\n예를 들어 여기에서는 위의 경우 레이어는 3개라고 설명하고 있습니다. 이러한 카운팅은 “무시”하세요. 제가 설명한 방식이 맞아요. 이 링크 잘못(?) 나와있는 이유는 아래와 같습니다.\n- 진짜 예전에 MLP를 소개할 초창기에서는 위의 경우 Layer를 3개로 셌음. (Rosenblatt et al. 1962)\n- 그런데 요즘은 그렇게 안셈.. (그리고 애초에 MLP라는 용어도 잘 안쓰죠..)\n참고로 히든레이어의 수는 예전방식이나 지금방식이나 동일하게 카운트하므로 히든레이어만 세면 혼돈이 없습니다.\n\n* node의 개념: \\(u\\to v\\)로 가는 쌍을 간단히 노드라는 개념을 이용하여 나타낼 수 있음.\n(노드의 개념이 포함된 그림)\n\n여기에서 node의 숫자 = feature의 숫자와 같이 이해할 수 있다. 즉 아래와 같이 이해할 수 있다.\n(“number of nodes = number of features”로 이해한 그림)\n\n\n다이어그램의 표현방식은 교재마다 달라서 모든 예시를 달달 외울 필요는 없습니다. 다만 임의의 다이어그램을 보고 대응하는 네트워크를 pytorch로 구현하는 능력은 매우 중요합니다.\n\n\n\nC. MNIST\n\\[\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n(다이어그램표현)\n\n\nLayer0,1,2 대신에 Input Layer, Hidden Layer, Output Layer로 표현함\n\n- 위의 다이어그램에 대응하는 코드\n- 가중치의 합은 784X32\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=28*28*1,out_features=32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid() \n)\n\n\n\n3. CPU vs GPU\n- 파이토치에서 GPU를 쓰는 방법을 알아보자. (사실 지금까지 우리는 CPU만 쓰고 있었음)\n\nA. GPU 사용방법\n- cpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_cpu = torch.tensor([0.0,0.1,0.2]).reshape(-1,1) \ny_cpu = torch.tensor([0.0,0.2,0.4]).reshape(-1,1) \nnet_cpu = torch.nn.Linear(1,1) \n\n\nnet_cpu(x_cpu)\n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nx_cpu\n\ntensor([[0.0000],\n        [0.1000],\n        [0.2000]])\n\n\n\n!nvidia-smi\n\nSat May  3 17:40:43 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:81:00.0 Off |                   On |\n| N/A   60C    P0              67W / 275W |                  N/A |     N/A      Default |\n|                                         |                      |              Enabled |\n+-----------------------------------------+----------------------+----------------------+\n\n+---------------------------------------------------------------------------------------+\n| MIG devices:                                                                          |\n+------------------+--------------------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |\n|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |\n|                  |                                |        ECC|                       |\n|==================+================================+===========+=======================|\n|  0    0   0   0  |               6MiB / 81050MiB  | 98      0 |  7   0    5    1    1 |\n|                  |               3MiB / 131072MiB |           |                       |\n+------------------+--------------------------------+-----------+-----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n\n\n- GPU로 올리기\n\ntorch.manual_seed(43052)\nx_gpu = x_cpu.to(\"cuda:0\")\ny_gpu = y_cpu.to(\"cuda:0\")\nnet_gpu = torch.nn.Linear(1,1).to(\"cuda:0\") \n\n\n!nvidia-smi\n\nSat May  3 17:41:54 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:81:00.0 Off |                   On |\n| N/A   60C    P0              70W / 275W |                  N/A |     N/A      Default |\n|                                         |                      |              Enabled |\n+-----------------------------------------+----------------------+----------------------+\n\n+---------------------------------------------------------------------------------------+\n| MIG devices:                                                                          |\n+------------------+--------------------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |\n|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |\n|                  |                                |        ECC|                       |\n|==================+================================+===========+=======================|\n|  0    0   0   0  |             395MiB / 81050MiB  | 98      0 |  7   0    5    1    1 |\n|                  |               5MiB / 131072MiB |           |                       |\n+------------------+--------------------------------+-----------+-----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n\n\n- GPU에 메모리 올리면 GPU메모리가 점유됨\n- cpu 혹은 gpu 연산이 가능한 메모리에 저장된 값들을 확인\n\nx_cpu, y_cpu, net_cpu.weight, net_cpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]]),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]]),\n Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n\nx_gpu, y_gpu, net_gpu.weight, net_gpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]], device='cuda:0'),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]], device='cuda:0'),\n Parameter containing:\n tensor([[-0.3467]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.8470], device='cuda:0', requires_grad=True))\n\n\n- gpu는 gpu끼리 연산가능하고 cpu는 cpu끼리 연산가능함\n(예시1)\n\nnet_cpu(x_cpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시2)\n\nnet_gpu(x_gpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시3)\n\n#net_cpu(x_gpu) \n\n(예시4)\n\n#net_gpu(x_cpu)\n\n(예시5)\n\ntorch.mean((y_cpu-net_cpu(x_cpu))**2)\n\ntensor(1.2068, grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시6)\n\ntorch.mean((y_gpu-net_gpu(x_gpu))**2)\n\ntensor(1.2068, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시7)\n\n#torch.mean((y_gpu-net_cpu(x_cpu))**2)\n\n(예시8)\n\n#torch.mean((y_cpu-net_gpu(x_gpu))**2)\n\n\n\nB. 시간측정(예비학습)\n\nimport time \n\n\nt1 = time.time()\n\n\nt2 = time.time()\n\n\nt2-t1\n\n3.919365882873535\n\n\n\n\nC. CPU vs GPU (500 nodes)\n- CPU (500 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.8856925964355469\n\n\n- GPU (500 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.821221113204956\n\n\n\n\nD. CPU vs GPU (200,000 nodes)\n- CPU(200,000)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n90.73985743522644\n\n\n- GPU (200,000)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.9625039100646973\n\n\n- 왜 이런 차이가 나는가?\n- 연산을 하는 주체는 코어인데 CPU는 수는 적지만 일을 잘하는 코어들을 가지고 있고 GPU는 일은 못하지만 다수의 코어를 가지고 있기 때문\n\n\nE. 주의점\n- tensor 일 경우\n\nx = torch.tensor([1,2,3])\nx.to(\"cuda:0\"), x\n\n(tensor([1, 2, 3], device='cuda:0'), tensor([1, 2, 3]))\n\n\n- net일 경우\n\nnet = torch.nn.Linear(1,1).to(\"cuda:0\")\nnet.weight, net.bias\n\n(Parameter containing:\n tensor([[-0.0084]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.6216], device='cuda:0', requires_grad=True))\n\n\n\n\n\n4. 확률적 경사하강법\n\nA. 의문\n- GPU 비쌈\n- 우리가 분석하는 데이터\n\nx = torch.linspace(-10,10,100000).reshape(-1,1)\neps = torch.randn(100000).reshape(-1,1)\ny = x*2 + eps \n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n- 데이터의 크기가 커지면 x.to(\"cuda:0\"), y.to(\"cuda:0\") 쓰면 문제 발생 \\(\\to\\) 이런식이면 GPU를 이용하여 아무런 분석도 못할것 같음??\n- 아이디어: 데이터를 100개중에 1개 꼴로만 쓰면 어떨까?\n\nplt.plot(x[::100],y[::100],'o',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n- 이것만 가지고도 적합해도 충분히 정확할 것 같다\n\n\nB. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?\n- 데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?\n- 아래의 알고리즘을 생각해보자.\n\n데이터를 반으로 나눈다.\n짝수obs의 x,y 그리고 net의 모든 파라메터를 GPU에 올린다.\nyhat, loss, grad, update 수행\n짝수obs의 x,y를 GPU메모리에서 내린다. 그리고 홀수obs의 x,y를 GPU메모리에 올린다.\nyhat, loss, grad, update 수행\n홀수obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수obs의 x,y를 GPU메모리에 올린다.\n반복\n\n\n이러면 되는거아니야???? —&gt; 맞아요\n\n\n\nC. 경사하강법, 확률적경사하강법, 미니배치 경사하강법\n10개의 샘플이 있다고 가정. \\(\\{(x_i,y_i)\\}_{i=1}^{10}\\)\n# ver1 – 모든 샘플을 이용하여 slope 계산\n(epoch 1) \\(loss=\\sum_{i=1}^{10}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2 \\to slope  \\to update\\)\n(epoch 2) \\(loss=\\sum_{i=1}^{10}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2 \\to slope  \\to update\\)\n…\n\n우리가 항상 이렇게 했죠!\n\n# ver2 – 하나의 샘플만을 이용하여 slope 계산\n(epoch 1)\n\n\\(loss=(y_1-\\hat{w}_0-\\hat{w}_1x_1)^2 \\to slope \\to update\\)\n\\(loss=(y_2-\\hat{w}_0-\\hat{w}_1x_2)^2 \\to slope \\to update\\)\n…\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n(epoch 2)\n\n\\(loss=(y_1-\\hat{w}_0-\\hat{w}_1x_1)^2  \\to slope  \\to  update\\)\n\\(loss=(y_2-\\hat{w}_0-\\hat{w}_1x_2)^2  \\to slope  \\to  update\\)\n…\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n…\n# ver3 – \\(m (\\leq n)\\) 개의 샘플을 이용하여 slope 계산\n\\(m=3\\)이라고 하자.\n(epoch 1)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n(epoch 2)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n…\n\n\nD. 용어의 정리\n옛날\n- ver1(모든): gradient descent, batch gradient descent\n- ver2(하나만): stochastic gradient descent\n- ver3(몇개만): mini-batch gradient descent, mini-batch stochastic gradient descent\n요즘\n- ver1(모든): gradient descent\n- ver2(하나만): stochastic gradient descent with batch size = 1\n- ver3(몇개만): stochastic gradient descent - https://www.deeplearningbook.org/contents/optimization.html, 알고리즘 8-1 참고.\n\n\nE. Dataset(ds), DataLoader(dl)\n\n취지는 알겠으나, C의 과정을 실제 구현하려면 진짜 어려움.. (입코딩과 손코딩의 차이) –&gt; 이걸 해결하기 위해서 파이토치에서는 DataLoader라는 오브젝트를 준비했음!\n\n- 데이터\n\nx=torch.tensor(range(10)).float().reshape(-1,1)\ny=torch.tensor([1.0]*5+[0.0]*5).reshape(-1,1)\ntorch.concat([x,y],axis=1)\n\ntensor([[0., 1.],\n        [1., 1.],\n        [2., 1.],\n        [3., 1.],\n        [4., 1.],\n        [5., 0.],\n        [6., 0.],\n        [7., 0.],\n        [8., 0.],\n        [9., 0.]])\n\n\n- ds오브젝트\n\nds = torch.utils.data.TensorDataset(x,y)\nds\n\n&lt;torch.utils.data.dataset.TensorDataset at 0x7f1ae80a6c20&gt;\n\n\n\nds.tensors \n# 생긴건 ds.tensors = (x,y) 임\n\n(tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]),\n tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]]))\n\n\n\nds[0],(x,y)[0] # (x,y) 튜플자체는 아님.. 인덱싱이 다르게 동작\n\n((tensor([0.]), tensor([1.])),\n tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]))\n\n\n- dl 오브젝트\n\ndl = torch.utils.data.DataLoader(ds, batch_size=3)\n\n\nfor x_mbatch,y_mbatch in dl:\n    print(f\"x_mini_batch:{x_mbatch.tolist()} \\t y_mini_batch:{y_mbatch.tolist()}\")\n\nx_mini_batch:[[0.0], [1.0], [2.0]]   y_mini_batch:[[1.0], [1.0], [1.0]]\nx_mini_batch:[[3.0], [4.0], [5.0]]   y_mini_batch:[[1.0], [1.0], [0.0]]\nx_mini_batch:[[6.0], [7.0], [8.0]]   y_mini_batch:[[0.0], [0.0], [0.0]]\nx_mini_batch:[[9.0]]     y_mini_batch:[[0.0]]\n\n\n- 마지막 관측치는 왜 단독 업데이트?? \\(\\to\\) shuffle=True 같은 옵션 존재\n\ndl = torch.utils.data.DataLoader(ds,batch_size=3,shuffle=True)\nfor x_mbatch,y_mbatch in dl:\n    print(f\"x_mini_batch:{x_mbatch.tolist()} \\t y_mini_batch:{y_mbatch.tolist()}\")\n\nx_mini_batch:[[9.0], [0.0], [8.0]]   y_mini_batch:[[0.0], [1.0], [0.0]]\nx_mini_batch:[[7.0], [5.0], [6.0]]   y_mini_batch:[[0.0], [0.0], [0.0]]\nx_mini_batch:[[3.0], [4.0], [1.0]]   y_mini_batch:[[1.0], [1.0], [1.0]]\nx_mini_batch:[[2.0]]     y_mini_batch:[[1.0]]\n\n\n\n\nF. 성능 체크\n- 목표 : 확률적 경사하강법과 그냥 경사하강법의 성늘을 ’동일 반복횟수’로 비교해보자\n- MNIST자료를 그냥 경사하강법으로 적합해보자\n\nimport torchvision\n\n\n#train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n#to_tensor = torchvision.transforms.ToTensor()\nX0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\nX1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\nX = torch.concat([X0,X1],axis=0).reshape(-1,784)\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n\nfor epoc in range(700):\n    # step1 \n    yhat = net(X)\n    # step2 \n    loss = loss_fn(yhat,y)\n    # step3     \n    loss.backward()\n    # step4 \n    optimizr.step()\n    optimizr.zero_grad()    \n\n\n((yhat &gt; 0.5) ==  y).float().mean()\n\ntensor(0.9953)\n\n\n- MNIST자료를 확률적 경사하강법으로 적합해보자. – 미니배치 쓰는 학습\n\n# train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n# to_tensor = torchvision.transforms.ToTensor()\n# X0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\n# X1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\n# X = torch.concat([X0,X1],axis=0).reshape(-1,784)\n# y = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n\n\nlen(X)/2048\n\n6.18408203125\n\n\n- (mini) batchsize 가 2048 이라면 한 epoch당 7회 update\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n\nfor epoc in range(100): \n    for xm,ym in dl:        \n        # step1 \n        ym_hat = net(xm)\n        # step2 \n        loss = loss_fn(ym_hat,ym)\n        # step3     \n        loss.backward()\n        # step4 \n        optimizr.step()\n        optimizr.zero_grad()\n\n\n((net(X) &gt; 0.5) ==  y).float().mean()\n\ntensor(0.9931)\n\n\n- 성능의 큰 차이가 없음"
  },
  {
    "objectID": "posts/8-1.합성곱신경망(MNIST,CIFAR10,XAI란?).html",
    "href": "posts/8-1.합성곱신경망(MNIST,CIFAR10,XAI란?).html",
    "title": "8-1. 합성곱신경망(MNIST, CIFAR10, XAI란?)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport torchvision\nimport matplotlib.pyplot as plt\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n# CNN \n# net = 2d --&gt; 1d\n# 1d: (linr(선형변환) -&gt; relu(비선형변환))\n# 2d: (conv(선형번환) -&gt; relu(비선형변환) -&gt; mp(비선형변환)) \n\n- conv \\(\\to\\) conv \\(\\to\\) … (비효율 하나로 퉁칠수 있는거 존재 : linr와 유사)\n\n\n2. MNIST\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=False,transform=torchvision.transforms.ToTensor())\ntest_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=False,transform=torchvision.transforms.ToTensor())\nX,y = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=6000,shuffle=True)))\nXX,yy = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=1000,shuffle=True)))\n\n- pytorch는 자동으로 원핫인코딩 해줌..\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,32,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),\n    torch.nn.Conv2d(32,32,kernel_size=3),\n    torch.nn.ReLU(),\n    torch.nn.Flatten(),\n    #---#\n    torch.nn.Linear(3200,10)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nnet.to(\"cuda:0\")\nX = X.to(\"cuda:0\")\ny = y.to(\"cuda:0\")\nXX = XX.to(\"cuda:0\")\nyy = yy.to(\"cuda:0\")\n#---#\nfor epoc in range(100):\n    #1\n    netout = net(X)\n    #2\n    loss = loss_fn(netout,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 배치사이즈 만들어서 해보기\n\n(net(X).argmax(axis=1) == y).float().mean()\n\ntensor(0.9798, device='cuda:0')\n\n\n\n(net(XX).argmax(axis=1) == yy).float().mean()\n\ntensor(0.9590, device='cuda:0')\n\n\n\ntorch.cuda.empty_cache()\n\n\n\n3. CIFAR10\n\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True,transform=torchvision.transforms.ToTensor())\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,transform=torchvision.transforms.ToTensor())\nX,y = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=10000,shuffle=True)))\nXX,yy = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=2000,shuffle=True)))\n\nDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n\n\n100%|███████████████████████████████████████████████████████████████| 170498071/170498071 [00:13&lt;00:00, 12433990.20it/s]\n\n\nExtracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n\n\n\nX[0].shape\n\ntorch.Size([3, 32, 32])\n\n\n\nplt.imshow(torch.einsum('chw -&gt; hwc', X[0]))\n\n\n\n\n\n\n\n\n\nA. 직접설계\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(3,32,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),\n    torch.nn.Conv2d(32,32,kernel_size=3),\n    torch.nn.ReLU(),\n    torch.nn.Flatten(),\n    #---#\n    torch.nn.Linear(4608,10)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nnet.to(\"cuda:0\")\nX = X.to(\"cuda:0\")\ny = y.to(\"cuda:0\")\nXX = XX.to(\"cuda:0\")\nyy = yy.to(\"cuda:0\")\n#---#\nfor epoc in range(500):\n    #1\n    netout = net(X)\n    #2\n    loss = loss_fn(netout,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n(net(X).argmax(axis=1) == y).float().mean()\n\ntensor(0.6786, device='cuda:0')\n\n\n\n(net(XX).argmax(axis=1) == yy).float().mean()\n\ntensor(0.6035, device='cuda:0')\n\n\n- 표현력 자체에 문제가 있어보임(언더피팅)\n\ntorch.cuda.empty_cache()\n\n\n\nB. 알렉스넷\n\n\nimg = torch.zeros(1,3*224*224).reshape(1,3,224,224)\nimg.shape\n\ntorch.Size([1, 3, 224, 224])\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(3,96,kernel_size=(11,11),stride=4),\n    torch.nn.ReLU(),    \n    torch.nn.MaxPool2d((3,3),stride=2), # default stride는 3\n    torch.nn.Conv2d(96,256,kernel_size=(5,5),padding=2),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((3,3),stride=2), # default stride는 3\n    torch.nn.Conv2d(256,384,kernel_size=(3,3),padding=1),\n    torch.nn.ReLU(),\n    torch.nn.Conv2d(384,384,kernel_size=(3,3),padding=1),\n    torch.nn.ReLU(),    \n    torch.nn.Conv2d(384,256,kernel_size=(3,3),padding=1),\n    torch.nn.ReLU(),    \n    torch.nn.MaxPool2d((3,3),stride=2),\n    torch.nn.Flatten(),\n    torch.nn.Linear(6400,4096),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.5),\n    torch.nn.Linear(4096,4096),        \n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.5),    \n    torch.nn.Linear(4096,1000),\n)\n\n\n\nC. 알렉스넷으로 ImageNet 적합\n\nnet[-1] = torch.nn.Linear(4096,10)\n\n\nimg = torch.randn(1,3,32,32)\n\n- 실패… 이미지 사이즈가 맞지 않음\n- 224, 224에서만 쓸 수 있음..\n\n#net(img)\n\n\nnet[:5](img).shape\n\ntorch.Size([1, 256, 2, 2])\n\n\n\nnet[5]\n\nMaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n\n\n\n\nD. renset18\n\nnet = torchvision.models.resnet18()\n#net \n\n\nnet.fc = torch.nn.Linear(512,10)\n\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nnet.to(\"cuda:0\")\nX = X.to(\"cuda:0\")\ny = y.to(\"cuda:0\")\nXX = XX.to(\"cuda:0\")\nyy = yy.to(\"cuda:0\")\n#---#\nfor epoc in range(500):\n    #1\n    netout = net(X)\n    #2\n    loss = loss_fn(netout,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.eval()\nprint((net(X).argmax(axis=1) == y).float().mean())\nprint((net(XX).argmax(axis=1) == yy).float().mean())\n\ntensor(1., device='cuda:0')\ntensor(0.6100, device='cuda:0')\n\n\n- 오버피팅이 있어보이긴 하지만 표현력 자체는 올라감\n\ntorch.cuda.empty_cache()\n\n\n\nE. resnet18, pretrained = True\n- 아이디어 : 하나를 잘하는 모델은 다른 것도 잘하지 않을까? -&gt; transger learning\n- 가중치까지 가져옴\n\nnet = torchvision.models.resnet18(pretrained=True) # 아키텍처 + 학습된 가중치까지 \nnet.fc = torch.nn.Linear(512,10)\n\n/root/anaconda3/envs/pypy/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/root/anaconda3/envs/pypy/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|███████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:00&lt;00:00, 109MB/s]\n\n\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nnet.to(\"cuda:0\")\nX = X.to(\"cuda:0\")\ny = y.to(\"cuda:0\")\nXX = XX.to(\"cuda:0\")\nyy = yy.to(\"cuda:0\")\n#---#\nfor epoc in range(500):\n    #1\n    netout = net(X)\n    #2\n    loss = loss_fn(netout,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.eval()\nprint((net(X).argmax(axis=1) == y).float().mean())\nprint((net(XX).argmax(axis=1) == yy).float().mean())\n\ntensor(1., device='cuda:0')\ntensor(0.7945, device='cuda:0')\n\n\n- 잘함 (오버피팅은 여전히 있음)\n\ntorch.cuda.empty_cache()\n\n\n\n\n4. XAI란?\nhttps://brunch.co.kr/@hvnpoet/140"
  },
  {
    "objectID": "posts/7-1.합성곱신경망(CNN장점, CNN핵심레이어).html",
    "href": "posts/7-1.합성곱신경망(CNN장점, CNN핵심레이어).html",
    "title": "7-1. 합성곱신경망(CNN 장점, CNN 핵심 레이어)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport torchvision\nimport matplotlib.pyplot as plt\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. CNN 장점\n\nA. 성능이 좋음\n\ntrain_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=False)\ntest_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=False)\ntrain_dataset = torch.utils.data.Subset(train_dataset, range(5000))\ntest_dataset = torch.utils.data.Subset(test_dataset, range(1000))\nto_tensor = torchvision.transforms.ToTensor()\nX = torch.stack([to_tensor(img) for img, lbl in train_dataset]).to(\"cuda:0\")\ny = torch.tensor([lbl for img, lbl in train_dataset])\ny = torch.nn.functional.one_hot(y).float().to(\"cuda:0\")\nXX = torch.stack([to_tensor(img) for img, lbl in test_dataset]).to(\"cuda:0\")\nyy = torch.tensor([lbl for img, lbl in test_dataset])\nyy = torch.nn.functional.one_hot(yy).float().to(\"cuda:0\")\n\n- 발악수준으로 설계한 신경망\n\ntorch.manual_seed(0)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,2048),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2048,10)\n).to(\"cuda\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(1,500):\n    #1\n    logits = net(X)\n    #2\n    loss = loss_fn(logits, y) \n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 과적합의 끝판왕\n\n(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()\n\ntensor(1., device='cuda:0')\n\n\n\n(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()\n\ntensor(0.8530, device='cuda:0')\n\n\n- 대충대충 설계한 합성곱신경망\n\ntorch.manual_seed(0)\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,2),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(2),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2704,10),\n).to(\"cuda\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(1,500):\n    #1\n    logits = net(X)\n    #2\n    loss = loss_fn(logits, y) \n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()\n\ntensor(0.9666, device='cuda:0')\n\n\n\n(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()\n\ntensor(0.8710, device='cuda:0')\n\n\n\n\nB. 파라메터가 적음\n\nnet1 = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,2048),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2048,10)\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,2),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(2),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2704,10),\n)\n\n\nnet1_params = list(net1.parameters())\nprint(net1_params[0].shape)\nprint(net1_params[1].shape)\nprint(net1_params[2].shape)\nprint(net1_params[3].shape)\n\ntorch.Size([2048, 784])\ntorch.Size([2048])\ntorch.Size([10, 2048])\ntorch.Size([10])\n\n\n\n2048*784 + 2048 + 2048*10 +10\n\n1628170\n\n\n\nnet2_params = list(net2.parameters())\nprint(net2_params[0].shape)\nprint(net2_params[1].shape)\nprint(net2_params[2].shape)\nprint(net2_params[3].shape)\n\ntorch.Size([16, 1, 2, 2])\ntorch.Size([16])\ntorch.Size([10, 2704])\ntorch.Size([10])\n\n\n\n16*1*2*2 + 16 + 10*2704 + 10 \n\n27130\n\n\n- net1 의 1.6퍼밖에 안됨..\n\n27130/1628170\n\n0.01666287918337766\n\n\n\n\nC. 유명함\n- 딥러닝이 있게함\n\n\n\n3. CNN 핵심 레이어\n\nA. torch.nn.ReLU\n- (예시1) 연산방법 : 음수를 0으로\n\nimg = torch.randn(1,1,4,4) # (4,4) 흑백이미지 한장\nrelu = torch.nn.ReLU()\n\n\nimg\n\ntensor([[[[ 1.4381,  0.2449, -0.6420,  2.6874],\n          [ 0.7790,  1.0558,  0.7939,  0.1099],\n          [ 0.3492,  1.7610,  1.6032,  2.4212],\n          [ 0.5416, -0.2153, -1.2772,  0.6885]]]])\n\n\n\nrelu(img)\n\ntensor([[[[1.4381, 0.2449, 0.0000, 2.6874],\n          [0.7790, 1.0558, 0.7939, 0.1099],\n          [0.3492, 1.7610, 1.6032, 2.4212],\n          [0.5416, 0.0000, 0.0000, 0.6885]]]])\n\n\n\n\nB. torch.nn.MaxPool2d\n- (예시1) 연산방법, kernel_size 의 의미\n\nimg = torch.rand(1,1,4,4)\nmp = torch.nn.MaxPool2d(kernel_size=2)\n\n\nimg\n\ntensor([[[[0.8921, 0.4222, 0.5778, 0.2707],\n          [0.6921, 0.5627, 0.5356, 0.1048],\n          [0.5356, 0.7699, 0.9047, 0.5911],\n          [0.3617, 0.5345, 0.1218, 0.4772]]]])\n\n\n\nmp(img)\n\ntensor([[[[0.8921, 0.5778],\n          [0.7699, 0.9047]]]])\n\n\n- (예시2) 이미지 크기와 딱 맞지않는 커널일 경우?\n\nimg = torch.rand(1,1,5,5)\nmp = torch.nn.MaxPool2d(kernel_size=3)\n\n\nimg\n\ntensor([[[[0.9560, 0.4947, 0.1591, 0.2606, 0.9130],\n          [0.0603, 0.1255, 0.6520, 0.2504, 0.8759],\n          [0.7544, 0.5927, 0.5319, 0.2390, 0.2883],\n          [0.9470, 0.8519, 0.3501, 0.0725, 0.3881],\n          [0.7203, 0.0753, 0.8360, 0.1287, 0.9515]]]])\n\n\n\nmp(img)\n\ntensor([[[[0.9560]]]])\n\n\n- (예시3) 정사각형이 아닌 커널\n\nimg = torch.rand(1,1,4,4)\nmp = torch.nn.MaxPool2d(kernel_size=(4,2))\n\n\nimg\n\ntensor([[[[0.4283, 0.9998, 0.3532, 0.3085],\n          [0.3278, 0.8575, 0.3331, 0.9769],\n          [0.0239, 0.2457, 0.8468, 0.8224],\n          [0.9593, 0.1292, 0.5930, 0.3652]]]])\n\n\n\nmp(img)\n\ntensor([[[[0.9998, 0.9769]]]])\n\n\n\n\nC. torch.nn.Conv2d\n-(예시1) 연산방법, stride=2\n\nimg = torch.rand(1,1,4,4)\nconv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=2)\n\n\nimg\n\ntensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n          [0.1166, 0.8762, 0.9373, 0.8573],\n          [0.5778, 0.8702, 0.9686, 0.5854],\n          [0.1373, 0.3530, 0.0529, 0.0139]]]])\n\n\n\nconv(img)\n\ntensor([[[[ 0.1106, -0.1898],\n          [ 0.0529, -0.0976]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n- 과정\n\nconv.weight.data, conv.bias.data\n\n(tensor([[[[-0.0218,  0.2400],\n           [-0.4914,  0.3394]]]]),\n tensor([-0.1958]))\n\n\n\n(img[:,  :,  :2,  :2] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([0.1106]),\n tensor([[[[ 0.1106, -0.1898],\n           [ 0.0529, -0.0976]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:,  :,  :2,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([-0.1898]),\n tensor([[[[ 0.1106, -0.1898],\n           [ 0.0529, -0.0976]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:,  :,  2:,  :2] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([0.0529]),\n tensor([[[[ 0.1106, -0.1898],\n           [ 0.0529, -0.0976]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:,  :,  2:,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([-0.0976]),\n tensor([[[[ 0.1106, -0.1898],\n           [ 0.0529, -0.0976]]]], grad_fn=&lt;ConvolutionBackward0&gt;))"
  },
  {
    "objectID": "posts/4-1.신경망(로지스틱의한계극복).html",
    "href": "posts/4-1.신경망(로지스틱의한계극복).html",
    "title": "4-1. 신경망(로지스틱의 한계 극복)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport matplotlib.pyplot as plt \nimport pandas as pd\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. 꺽인 직선을 만드는 방법\n- 로지스틱의 한계를 극복하기 위해서는 시그모이드를 취하기 전 꺽인 그래프 모양을 만들어야함\n- 아래와 같은 벡터 \\(x\\)가정\n\nx = torch.linspace(-1,1,1001).reshape(-1,1)\nx\n\ntensor([[-1.0000],\n        [-0.9980],\n        [-0.9960],\n        ...,\n        [ 0.9960],\n        [ 0.9980],\n        [ 1.0000]])\n\n\n- 목표: 아래와 같은 벡터 \\({\\bf y}\\)를 만들어보자.\n\\[{\\bf y} = [y_1,y_2,\\dots,y_{n}]^\\top, \\quad y_i = \\begin{cases} 9x_i +4.5& x_i &lt;0 \\\\ -4.5x_i + 4.5& x_i &gt;0 \\end{cases}\\]\n- 방법1 수식 그대로 구현\n\nplt.plot(x,9*x+4.5,color=\"blue\",alpha=0.1)\nplt.plot(x[x&lt;0], (9*x+4.5)[x&lt;0],color=\"blue\")\nplt.plot(x,-4.5*x+4.5,color=\"orange\",alpha=0.1)\nplt.plot(x[x&gt;0], (-4.5*x+4.5)[x&gt;0],color=\"orange\")\n\n\n\n\n\n\n\n\n\ny = x*0\ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n- 방법2 ReLU 이용\n\nrelu = torch.nn.ReLU()\n#plt.plot(x,-4.5*relu(x),color=\"red\")\n#plt.plot(x,-9*relu(-x),color=\"blue\")\ny = -4.5*relu(x) + -9*relu(-x) + 4.5\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n- ReLU 중간과정\n\nfig = plt.figure(figsize=(6, 4))\nspec = fig.add_gridspec(4, 3)\nax1 = fig.add_subplot(spec[:2,0]); ax1.set_title(r'$x$'); ax1.set_ylim(-1,1)\nax2 = fig.add_subplot(spec[2:,0]); ax2.set_title(r'$-x$'); ax2.set_ylim(-1,1)\nax3 = fig.add_subplot(spec[:2,1]); ax3.set_title(r'$relu(x)$'); ax3.set_ylim(-1,1)\nax4 = fig.add_subplot(spec[2:,1]); ax4.set_title(r'$relu(-x)$'); ax4.set_ylim(-1,1)\nax5 = fig.add_subplot(spec[1:3,2]); ax5.set_title(r'$-4.5 relu(x)-9 relu(-x)+4.5$')\n#---#\nax1.plot(x,'--',color='C0')\nax2.plot(-x,'--',color='C1')\nax3.plot(relu(x),'--',color='C0')\nax4.plot(relu(-x),'--',color='C1')\nax5.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',color='C2')\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 방법3 ReLU의 브로드캐스팅 화룡\n- 아래와 같은 아이디어로 y를 계산해도 된다.\n\nx, relu 준비\nu = [x -x]\nv = relu(u) = [relu(x), relu(-x)] = [v1 v2]\ny = -4.5*v1 + -9*v2 + 4.5\n\n\nu = torch.concat([x,-x],axis=1)\nv = relu(u)\nv1 = v[:,[0]]\nv2 = v[:,[1]]\ny = -4.5*v1 -9*v2 + 4.5 \nplt.plot(x,y)\n\n\n\n\n\n\n\n\n- 방법4 y=linr(v)\n\nx \nu = torch.concat([x,-x],axis=1)\nv = relu(u) \ny = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \nplt.plot(x,y)\n\n\n\n\n\n\n\n\n- 방법5u=linr(x)\n\nx \nu = x @ torch.tensor([[1.0, -1.0]])\nv = relu(u) \ny = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \n\n\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n- 방법6 torch.nn.Linear()를 이용\n\n# u = l1(x) # l1은 x-&gt;u인 선형변환: (n,1) -&gt; (n,2) 인 선형변환\nl1 = torch.nn.Linear(1,2,bias=False)\nl1.weight.data = torch.tensor([[1.0, -1.0]]).T \na1 = relu \nl2 = torch.nn.Linear(2,1,bias=True)\nl2.weight.data = torch.tensor([[-4.5],[-9]]).T \nl2.bias.data = torch.tensor([4.5])\n#---#\nx\nu = l1(x)\nv = a1(u) \ny = l2(v) \n\n\nplt.plot(x,y.data)\n\n\n\n\n\n\n\n\n\npwlinr = torch.nn.Sequential(l1,a1,l2)\nplt.plot(x,pwlinr(x).data)\n\n\n\n\n\n\n\n\n- 수식적 표현\n\nNote\n수식표현\n(1) \\({\\bf X}=\\begin{bmatrix} x_1 \\\\ \\dots \\\\ x_n \\end{bmatrix}\\)\n(2) \\(l_1({\\bf X})={\\bf X}{\\bf W}^{(1)}\\overset{bc}{+} {\\boldsymbol b}^{(1)}=\\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n\\end{bmatrix}\\)\n\n\\({\\bf W}^{(1)}=\\begin{bmatrix} 1 & -1 \\end{bmatrix}\\)\n\\({\\boldsymbol b}^{(1)}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}\\)\n\n(3) \\((a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big)=\\begin{bmatrix} \\text{relu}(x_1) & \\text{relu}(-x_1) \\\\ \\text{relu}(x_2) & \\text{relu}(-x_2) \\\\ \\dots & \\dots \\\\ \\text{relu}(x_n) & \\text{relu}(-x_n)\\end{bmatrix}\\)\n(4) \\((l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad=\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\\({\\bf W}^{(2)}=\\begin{bmatrix} -4.5 \\\\ -9 \\end{bmatrix}\\)\n\\(b^{(2)}=4.5\\)\n\n(5) \\(\\textup{pwlinr}({\\bf X})=(l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad =\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\n\n3. 스펙의 역설 적합\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\n\n\n\n\n\n\n\n\n- Step1에 대한 생각: 네트워크를 어떻게 만들까? = 아키텍처를 어떻게 만들까? = 모델링\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n\n\\(l_1\\): torch.nn.Linear(1,2,bias=False)\n\\(a_1\\): torch.nn.ReLU()\n\\(l_2\\): torch.nn.Linear(2,1,bias=True)\n\\(a_2\\): torch.nn.Sigmoid()\n\n- Step1-4\n\nnet[0].weight.data\n\ntensor([[ 0.5153],\n        [-0.4414]])\n\n\n\nnet[2].weight.data\n\ntensor([[-0.1371,  0.3319]])\n\n\n\nnet[0].weight.data\n\ntensor([[ 1.7773],\n        [-3.0447]])\n\n\n\nnet[2].weight.data\n\ntensor([[-0.9945, -2.7176]])\n\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2,bias=False),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2,1,bias=True),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## step1\n    yhat = net(x)\n    ## step2\n    loss = loss_fn(yhat,y)\n    ## step3\n    loss.backward()\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,yhat.data,'--')\n\n\n\n\n\n\n\n\n- 5000번 더 반복\n\nfor epoc in range(5000):\n    ## step1\n    yhat = net(x)\n    ## step2\n    loss = loss_fn(yhat,y)\n    ## step3\n    loss.backward()\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,yhat.data,'--')\n\n\n\n\n\n\n\n\n\na= (1.5,2,2)\n\n\nint(a[0])\n\n1"
  },
  {
    "objectID": "posts/5-1.신경망(예측,시벤코정리의이면,드랍아웃).html",
    "href": "posts/5-1.신경망(예측,시벤코정리의이면,드랍아웃).html",
    "title": "5-1. 신경망(예측, 시벤코정리의 이면, 드랍아웃)",
    "section": "",
    "text": "import torch\nimport matplotlib.pyplot as plt\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)"
  },
  {
    "objectID": "posts/5-1.신경망(예측,시벤코정리의이면,드랍아웃).html#d.-시벤코정리의-올바른-이해",
    "href": "posts/5-1.신경망(예측,시벤코정리의이면,드랍아웃).html#d.-시벤코정리의-올바른-이해",
    "title": "5-1. 신경망(예측, 시벤코정리의 이면, 드랍아웃)",
    "section": "D. 시벤코정리의 올바른 이해",
    "text": "D. 시벤코정리의 올바른 이해\n\nNote\n시벤코의 항변(?) (Cybenko 1989)\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(), ## &lt;-- 여기에 렐루를 써도 된다. \n    torch.nn.Linear(???,q)\n)\n모든 보렐가측함수\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다. 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 신경망이 원하는 정확도로 근사시킨다는 의미이다. 그렇지만 이러한 규칙이 네크워크가 학습하지 못했던 자료 (처음 보는 자료, unseen data) \\({\\bf XX}_{m \\times p}\\), \\({\\bf yy}_{m \\times q}\\) 에 대하여서도 올바르게 적용된다라는 보장은 없다. 시벤코는 단지 net가 가지는 표현력의 한계를 수학적으로 밝혔을 뿐이다.\n\n\n5. 드랍아웃\n\nA. 오버피팅의 해결\n- 오버피팅의 해결책: 드랍아웃\n- 데이터\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\n#plt.plot(x_all,y_all,'--o',alpha=0.5)\nx,y = x_all[:80], y_all[:80]\nxx,yy = x_all[80:], y_all[80:]\nplt.plot(x,y,'--o',color=\"C0\")\nplt.plot(xx,yy,'--o',color=\"C1\")\n\n\n\n\n\n\n\n\n- 학습\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.8),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과 시각화(잘못된 사용)\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')\n\n\n\n\n\n\n\n\n- 결과 시각화 (올바른 사용)\n\nnet.training \n\nTrue\n\n\n\nnet.eval()\n\nSequential(\n  (0): Linear(in_features=1, out_features=512, bias=True)\n  (1): ReLU()\n  (2): Dropout(p=0.8, inplace=False)\n  (3): Linear(in_features=512, out_features=1, bias=True)\n)\n\n\n\nnet.training\n\nFalse\n\n\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')\n\n\n\n\n\n\n\n\n\n\nB. 드랍아웃 레이어\n- 드랍아웃의 성질 1 : 드랍아웃의 계산 방식 이해\n\nu = torch.randn(10,2)\nd = torch.nn.Dropout(0.9)\nu\n\ntensor([[ 0.5951,  0.2245],\n        [ 0.8238,  0.5230],\n        [ 0.4772, -1.0465],\n        [-0.6826,  0.4257],\n        [ 0.5113,  0.4130],\n        [-0.3946,  0.0827],\n        [ 1.4149, -1.7569],\n        [ 0.3142, -0.9964],\n        [-0.4613,  0.3530],\n        [-0.2743, -0.5558]])\n\n\n\nd(u)\n\ntensor([[0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, -0.0000],\n        [-0.0000, 0.0000],\n        [5.1128, 4.1303],\n        [-0.0000, 0.0000],\n        [0.0000, -0.0000],\n        [0.0000, -0.0000],\n        [-0.0000, 3.5305],\n        [-0.0000, -0.0000]])\n\n\n- 90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다.\n- 남은값을 10배 키우는 이유? 출력의 평균값을 보정하기 위해서\n- 드랍아웃의 성질2: 드랍아웃을 on/off 하는 방법을 이해해보자.\n\nu = torch.randn(10,2)\nu\n\ntensor([[ 0.8395,  1.8825],\n        [-0.0415, -2.3987],\n        [-0.3658, -1.3403],\n        [-1.4066,  0.7178],\n        [-1.0465,  0.9663],\n        [-1.2350,  1.3424],\n        [-1.1903,  0.3955],\n        [ 0.4236, -0.7882],\n        [-0.4348,  0.2669],\n        [-0.9102, -0.3219]])\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Dropout(0.9)\n)\nnet\n\nSequential(\n  (0): Dropout(p=0.9, inplace=False)\n)\n\n\n\nu,net(u)\n\n(tensor([[ 0.8395,  1.8825],\n         [-0.0415, -2.3987],\n         [-0.3658, -1.3403],\n         [-1.4066,  0.7178],\n         [-1.0465,  0.9663],\n         [-1.2350,  1.3424],\n         [-1.1903,  0.3955],\n         [ 0.4236, -0.7882],\n         [-0.4348,  0.2669],\n         [-0.9102, -0.3219]]),\n tensor([[  0.0000,   0.0000],\n         [ -0.0000,  -0.0000],\n         [ -0.0000,  -0.0000],\n         [-14.0662,   0.0000],\n         [ -0.0000,   0.0000],\n         [-12.3497,   0.0000],\n         [ -0.0000,   0.0000],\n         [  4.2361,  -0.0000],\n         [ -0.0000,   0.0000],\n         [ -0.0000,  -3.2190]]))\n\n\n\nnet.training\n\nTrue\n\n\n- 드랍아웃이 안먹히고 통과\n\nnet.eval() # 드랍아웃이 무력화\n\nSequential(\n  (0): Dropout(p=0.9, inplace=False)\n)\n\n\n\nu,net(u)\n\n(tensor([[ 0.8395,  1.8825],\n         [-0.0415, -2.3987],\n         [-0.3658, -1.3403],\n         [-1.4066,  0.7178],\n         [-1.0465,  0.9663],\n         [-1.2350,  1.3424],\n         [-1.1903,  0.3955],\n         [ 0.4236, -0.7882],\n         [-0.4348,  0.2669],\n         [-0.9102, -0.3219]]),\n tensor([[ 0.8395,  1.8825],\n         [-0.0415, -2.3987],\n         [-0.3658, -1.3403],\n         [-1.4066,  0.7178],\n         [-1.0465,  0.9663],\n         [-1.2350,  1.3424],\n         [-1.1903,  0.3955],\n         [ 0.4236, -0.7882],\n         [-0.4348,  0.2669],\n         [-0.9102, -0.3219]]))\n\n\n- 드랍아웃레이어 정리\n\n계산: (1) 입력의 일부를 임의로 0으로 만드는 역할 (2) 0이 안된것들은 스칼라배하여 드랍아웃을 통과한 모든 숫자들의 총합이 대체로 일정하게 되도록 조정\non/off: 학습시에는 dropout on / 학습을 하지 않을 경우는 dropout off\n느낌: 일부러 패널티를 안고 학습하는 느낌..\n효과: 오버피팅을 억제하는 효과가 있음\n\n\n참고: 오버피팅을 잡는 방법은 드랍아웃만 있는게 아니다..\n\n\n\nC. 드랍아웃 레이어의 위치\n- ReLU,dropout의 특이한 성질: 순서 상관없음\n\\(\\text{dropout}(\\text{relu}({\\bf x}))=\\text{relu}(\\text{dropout}({\\bf x}))\\)\n\nu = torch.randn(10,2)\nr = torch.nn.ReLU()\nd = torch.nn.Dropout()\n\n\ntorch.manual_seed(0)\nd(r(u))\n\ntensor([[0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.5372],\n        [2.6658, 2.1870],\n        [0.3798, 0.0000],\n        [0.0000, 1.6593],\n        [0.9300, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000]])\n\n\n\ntorch.manual_seed(0)\nr(d(u))\n\ntensor([[0.0000, 0.0000],\n        [-0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.5372],\n        [2.6658, 2.1870],\n        [0.3798, -0.0000],\n        [0.0000, 1.6593],\n        [0.9300, 0.0000],\n        [0.0000, 0.0000],\n        [-0.0000, 0.0000]])\n\n\n- 다른 활성화함수는 성립안함\n\nu = torch.randn(10,2)\ns = torch.nn.Sigmoid()\nd = torch.nn.Dropout()\n\n\ntorch.manual_seed(0)\nd(s(u))\n\ntensor([[0.4801, 0.0000],\n        [0.0000, 1.4006],\n        [0.3487, 0.0000],\n        [0.0000, 1.2299],\n        [0.9213, 1.6180],\n        [1.1322, 0.0000],\n        [0.0000, 1.4407],\n        [0.6015, 1.4349],\n        [0.0000, 1.7626],\n        [0.0000, 0.0000]])\n\n\n\ntorch.manual_seed(0)\ns(d(u))\n\ntensor([[0.0907, 0.5000],\n        [0.5000, 0.8452],\n        [0.0427, 0.5000],\n        [0.5000, 0.7183],\n        [0.4218, 0.9472],\n        [0.6300, 0.5000],\n        [0.5000, 0.8691],\n        [0.1561, 0.8657],\n        [0.5000, 0.9822],\n        [0.5000, 0.5000]])\n\n\n- 결론: 드랍아웃은 활성화 함수 바로 뒤에 오는게 맞음. (그렇지 않다면 0을 만들 수 없는걸?) 그렇지만 ReLU의 경우 활성화 함수 직전에 취하기도 함."
  }
]