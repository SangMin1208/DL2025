[
  {
    "objectID": "posts/5-1.신경망(예측,시벤코정리의이면,드랍아웃).html",
    "href": "posts/5-1.신경망(예측,시벤코정리의이면,드랍아웃).html",
    "title": "5-1. 신경망(예측, 시벤코정리의 이면, 드랍아웃)",
    "section": "",
    "text": "import torch\nimport matplotlib.pyplot as plt\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)"
  },
  {
    "objectID": "posts/5-1.신경망(예측,시벤코정리의이면,드랍아웃).html#d.-시벤코정리의-올바른-이해",
    "href": "posts/5-1.신경망(예측,시벤코정리의이면,드랍아웃).html#d.-시벤코정리의-올바른-이해",
    "title": "5-1. 신경망(예측, 시벤코정리의 이면, 드랍아웃)",
    "section": "D. 시벤코정리의 올바른 이해",
    "text": "D. 시벤코정리의 올바른 이해\n\nNote\n시벤코의 항변(?) (Cybenko 1989)\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(), ## &lt;-- 여기에 렐루를 써도 된다. \n    torch.nn.Linear(???,q)\n)\n모든 보렐가측함수\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다. 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 신경망이 원하는 정확도로 근사시킨다는 의미이다. 그렇지만 이러한 규칙이 네크워크가 학습하지 못했던 자료 (처음 보는 자료, unseen data) \\({\\bf XX}_{m \\times p}\\), \\({\\bf yy}_{m \\times q}\\) 에 대하여서도 올바르게 적용된다라는 보장은 없다. 시벤코는 단지 net가 가지는 표현력의 한계를 수학적으로 밝혔을 뿐이다.\n\n\n5. 드랍아웃\n\nA. 오버피팅의 해결\n- 오버피팅의 해결책: 드랍아웃\n- 데이터\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\n#plt.plot(x_all,y_all,'--o',alpha=0.5)\nx,y = x_all[:80], y_all[:80]\nxx,yy = x_all[80:], y_all[80:]\nplt.plot(x,y,'--o',color=\"C0\")\nplt.plot(xx,yy,'--o',color=\"C1\")\n\n\n\n\n\n\n\n\n- 학습\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.8),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과 시각화(잘못된 사용)\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')\n\n\n\n\n\n\n\n\n- 결과 시각화 (올바른 사용)\n\nnet.training \n\nTrue\n\n\n\nnet.eval()\n\nSequential(\n  (0): Linear(in_features=1, out_features=512, bias=True)\n  (1): ReLU()\n  (2): Dropout(p=0.8, inplace=False)\n  (3): Linear(in_features=512, out_features=1, bias=True)\n)\n\n\n\nnet.training\n\nFalse\n\n\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')\n\n\n\n\n\n\n\n\n\n\nB. 드랍아웃 레이어\n- 드랍아웃의 성질 1 : 드랍아웃의 계산 방식 이해\n\nu = torch.randn(10,2)\nd = torch.nn.Dropout(0.9)\nu\n\ntensor([[ 0.5951,  0.2245],\n        [ 0.8238,  0.5230],\n        [ 0.4772, -1.0465],\n        [-0.6826,  0.4257],\n        [ 0.5113,  0.4130],\n        [-0.3946,  0.0827],\n        [ 1.4149, -1.7569],\n        [ 0.3142, -0.9964],\n        [-0.4613,  0.3530],\n        [-0.2743, -0.5558]])\n\n\n\nd(u)\n\ntensor([[0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, -0.0000],\n        [-0.0000, 0.0000],\n        [5.1128, 4.1303],\n        [-0.0000, 0.0000],\n        [0.0000, -0.0000],\n        [0.0000, -0.0000],\n        [-0.0000, 3.5305],\n        [-0.0000, -0.0000]])\n\n\n- 90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다.\n- 남은값을 10배 키우는 이유? 출력의 평균값을 보정하기 위해서\n- 드랍아웃의 성질2: 드랍아웃을 on/off 하는 방법을 이해해보자.\n\nu = torch.randn(10,2)\nu\n\ntensor([[ 0.8395,  1.8825],\n        [-0.0415, -2.3987],\n        [-0.3658, -1.3403],\n        [-1.4066,  0.7178],\n        [-1.0465,  0.9663],\n        [-1.2350,  1.3424],\n        [-1.1903,  0.3955],\n        [ 0.4236, -0.7882],\n        [-0.4348,  0.2669],\n        [-0.9102, -0.3219]])\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Dropout(0.9)\n)\nnet\n\nSequential(\n  (0): Dropout(p=0.9, inplace=False)\n)\n\n\n\nu,net(u)\n\n(tensor([[ 0.8395,  1.8825],\n         [-0.0415, -2.3987],\n         [-0.3658, -1.3403],\n         [-1.4066,  0.7178],\n         [-1.0465,  0.9663],\n         [-1.2350,  1.3424],\n         [-1.1903,  0.3955],\n         [ 0.4236, -0.7882],\n         [-0.4348,  0.2669],\n         [-0.9102, -0.3219]]),\n tensor([[  0.0000,   0.0000],\n         [ -0.0000,  -0.0000],\n         [ -0.0000,  -0.0000],\n         [-14.0662,   0.0000],\n         [ -0.0000,   0.0000],\n         [-12.3497,   0.0000],\n         [ -0.0000,   0.0000],\n         [  4.2361,  -0.0000],\n         [ -0.0000,   0.0000],\n         [ -0.0000,  -3.2190]]))\n\n\n\nnet.training\n\nTrue\n\n\n- 드랍아웃이 안먹히고 통과\n\nnet.eval() # 드랍아웃이 무력화\n\nSequential(\n  (0): Dropout(p=0.9, inplace=False)\n)\n\n\n\nu,net(u)\n\n(tensor([[ 0.8395,  1.8825],\n         [-0.0415, -2.3987],\n         [-0.3658, -1.3403],\n         [-1.4066,  0.7178],\n         [-1.0465,  0.9663],\n         [-1.2350,  1.3424],\n         [-1.1903,  0.3955],\n         [ 0.4236, -0.7882],\n         [-0.4348,  0.2669],\n         [-0.9102, -0.3219]]),\n tensor([[ 0.8395,  1.8825],\n         [-0.0415, -2.3987],\n         [-0.3658, -1.3403],\n         [-1.4066,  0.7178],\n         [-1.0465,  0.9663],\n         [-1.2350,  1.3424],\n         [-1.1903,  0.3955],\n         [ 0.4236, -0.7882],\n         [-0.4348,  0.2669],\n         [-0.9102, -0.3219]]))\n\n\n- 드랍아웃레이어 정리\n\n계산: (1) 입력의 일부를 임의로 0으로 만드는 역할 (2) 0이 안된것들은 스칼라배하여 드랍아웃을 통과한 모든 숫자들의 총합이 대체로 일정하게 되도록 조정\non/off: 학습시에는 dropout on / 학습을 하지 않을 경우는 dropout off\n느낌: 일부러 패널티를 안고 학습하는 느낌..\n효과: 오버피팅을 억제하는 효과가 있음\n\n\n참고: 오버피팅을 잡는 방법은 드랍아웃만 있는게 아니다..\n\n\n\nC. 드랍아웃 레이어의 위치\n- ReLU,dropout의 특이한 성질: 순서 상관없음\n\\(\\text{dropout}(\\text{relu}({\\bf x}))=\\text{relu}(\\text{dropout}({\\bf x}))\\)\n\nu = torch.randn(10,2)\nr = torch.nn.ReLU()\nd = torch.nn.Dropout()\n\n\ntorch.manual_seed(0)\nd(r(u))\n\ntensor([[0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.5372],\n        [2.6658, 2.1870],\n        [0.3798, 0.0000],\n        [0.0000, 1.6593],\n        [0.9300, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000]])\n\n\n\ntorch.manual_seed(0)\nr(d(u))\n\ntensor([[0.0000, 0.0000],\n        [-0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.5372],\n        [2.6658, 2.1870],\n        [0.3798, -0.0000],\n        [0.0000, 1.6593],\n        [0.9300, 0.0000],\n        [0.0000, 0.0000],\n        [-0.0000, 0.0000]])\n\n\n- 다른 활성화함수는 성립안함\n\nu = torch.randn(10,2)\ns = torch.nn.Sigmoid()\nd = torch.nn.Dropout()\n\n\ntorch.manual_seed(0)\nd(s(u))\n\ntensor([[0.4801, 0.0000],\n        [0.0000, 1.4006],\n        [0.3487, 0.0000],\n        [0.0000, 1.2299],\n        [0.9213, 1.6180],\n        [1.1322, 0.0000],\n        [0.0000, 1.4407],\n        [0.6015, 1.4349],\n        [0.0000, 1.7626],\n        [0.0000, 0.0000]])\n\n\n\ntorch.manual_seed(0)\ns(d(u))\n\ntensor([[0.0907, 0.5000],\n        [0.5000, 0.8452],\n        [0.0427, 0.5000],\n        [0.5000, 0.7183],\n        [0.4218, 0.9472],\n        [0.6300, 0.5000],\n        [0.5000, 0.8691],\n        [0.1561, 0.8657],\n        [0.5000, 0.9822],\n        [0.5000, 0.5000]])\n\n\n- 결론: 드랍아웃은 활성화 함수 바로 뒤에 오는게 맞음. (그렇지 않다면 0을 만들 수 없는걸?) 그렇지만 ReLU의 경우 활성화 함수 직전에 취하기도 함."
  },
  {
    "objectID": "posts/6-1.신경망(데이터분석코딩패턴).html",
    "href": "posts/6-1.신경망(데이터분석코딩패턴).html",
    "title": "6-1. 신경망(데이터분석 코딩패턴)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport torchvision\nimport matplotlib.pyplot as plt\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n# 복습\n# --- \n# 시벤코정리 - 다 맞출수있어 (train) \n# 오버피팅 - 그게 의미가 없을텐데 (test 에서 잘하는게 의미가 있다) \n# 드랍아웃 - 대충대충 학습하면 오히려 좋을지도 --&gt; 이게 성공함 // 랜덤포레스트?\n#----#\n# GPU 메모리 아깝다.. (비싸거든) \n# 그래서 확률적경사하강법 \n# 꼭 돈이 없어서 이 알고리즘을 만든것 같지만 그런건 아님 \n# 확률적경사하강법은 알고리즘 자체에 장점이 있음 \n# -- 장점1: 데이터를 조금씩쓰면서 update // 대충대충하는 느낌 ---&gt; 오버핏을 눌러주는 효과 // 배깅?\n# -- 장점2: global min 이 있고, local min 있을때, local min을 잘 탈출하는 효과가 있음 \n\n- 오늘할것: train/test 이 존재하는 데이터 셋팅에서 Dropout 레이어도, 미니배치, GPU쓰기\n\nA. 일반적인 train/test 셋팅\n- Step1 : 데이터 정리"
  },
  {
    "objectID": "posts/5-2.신경망(신경망의표현,GPU사용법,확률적경사하강법).html",
    "href": "posts/5-2.신경망(신경망의표현,GPU사용법,확률적경사하강법).html",
    "title": "5-2. 신경망(신경망의 표현, GPU사용법, 확률적경사하강법)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport matplotlib.pyplot as plt\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. 신경망의 표현\n- 신경망의 표현: \\({\\bf X} \\to \\hat{\\bf y}\\) 로 가는 과정을 그림으로 표현\n\nA. 로지스틱\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\bf y}}\\]\n- 모든 observation과 가중치를 명시한 버전\n(표현1)\n\n\n단점: 똑같은 그림의 반복이 너무 많음\n\n- observation 반복을 생략한 버전들\n(표현2) 모든 \\(i\\)에 대하여 아래의 그림을 반복한다고 하면 (표현1)과 같다.\n\n(표현3) 그런데 (표현2)에서 아래와 같이 \\(x_i\\), \\(y_i\\) 대신에 간단히 \\(x\\), \\(y\\)로 쓰는 경우도 많음\n\n- 1을 생략한 버전들\n(표현4) bais=False 대신에 bias=True를 주면 1을 생략할 수 있음\n\n(표현4의 수정) \\(\\hat{w}_1\\)대신에 \\(\\hat{w}\\)를 쓰는 것이 더 자연스러움\n\n(표현5) 선형변환의 결과는 아래와 같이 \\(u\\)로 표현하기도 한다.\n\n\n다이어그램은 그리는 사람의 취향에 따라 그리는 방법이 조금씩 다릅니다. 즉 교재마다 달라요.\n\n\n\nB. 스펙의역설\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\bf y}}\\]\n참고: 코드로 표현\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Sigmoid()\n)\n- 이해를 위해서 예젠에 다루었던 아래의 상황을 고려하자.\n\n(강의노트의 표현)\n\n(좀 더 일반화된 표현) 상황을 일반화하면 아래와 같다.\n\n* Layer의 개념: \\({\\bf X}\\)에서 \\(\\hat{\\boldsymbol y}\\)로 가는 과정은 “선형변환+비선형변환”이 반복되는 구조이다. “선형변환+비선형변환”을 하나의 세트로 보면 아래와 같이 표현할 수 있다.\n\n\\(\\underset{(n,1)}{\\bf X}  \\overset{l_1}{\\to} \\left( \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\right) \\overset{l_2}{\\to} \\left(\\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}\\right), \\quad  \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{net({\\bf X})}=\\underset{(n,1)}{\\hat{\\bf y}}\\)\n\n이것을 다이어그램으로 표현한다면 아래와 같다.\n(선형+비선형을 하나의 Layer로 묶은 표현)\n\nLayer를 세는 방법\n\n제 방식: 학습가능한 파라메터가 몇층으로 있는지… &lt;– 이것만 기억하세여\n일부 교재 설명: 입력층은 계산하지 않음, activation layer는 계산하지 않음. &lt;– 무시하세요.. 이러면 헷갈립니다..\n위의 예제의 경우 number of layer = 2 이다.\n\nHidden Layer의 수를 세는 방법\n\n제 방식: Hidden Layer의 수 = Layer의 수 -1 &lt;– 이걸 기억하세여..\n\n일부 교재 설명: Layer의 수 = Hidden Layer의 수 + 출력층의 수 = Hidden Layer의 수 + 1 &lt;– 기억하지 마세여\n위의 예제의 경우 number of hidden layer = 1 이다.\n\n\nImportant\n무조건 학습가능한 파라메터가 몇겹으로 있는지만 판단하세요. 딴거 아무것도 생각하지마세여\n## 예시1 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n)\n## 예시2 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid(),\n)\n## 예시3 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n) \n## 예시4 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n) \n## 예시5 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층    \n) \n## 예시6 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층  \n    torch.nn.Sigmoid()\n) \n\n\nImportant\n문헌에 따라서 레이어를 세는 개념이 제가 설명한 방식과 다른경우가 있습니다. 제가 설명한 방식보다 1씩 더해서 셉니다. 즉 아래의 경우 레이어를 3개로 카운트합니다.\n## 예시1 -- 문헌에 따라 3층으로 세는 경우가 있음 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n)\n예를 들어 여기에서는 위의 경우 레이어는 3개라고 설명하고 있습니다. 이러한 카운팅은 “무시”하세요. 제가 설명한 방식이 맞아요. 이 링크 잘못(?) 나와있는 이유는 아래와 같습니다.\n- 진짜 예전에 MLP를 소개할 초창기에서는 위의 경우 Layer를 3개로 셌음. (Rosenblatt et al. 1962)\n- 그런데 요즘은 그렇게 안셈.. (그리고 애초에 MLP라는 용어도 잘 안쓰죠..)\n참고로 히든레이어의 수는 예전방식이나 지금방식이나 동일하게 카운트하므로 히든레이어만 세면 혼돈이 없습니다.\n\n* node의 개념: \\(u\\to v\\)로 가는 쌍을 간단히 노드라는 개념을 이용하여 나타낼 수 있음.\n(노드의 개념이 포함된 그림)\n\n여기에서 node의 숫자 = feature의 숫자와 같이 이해할 수 있다. 즉 아래와 같이 이해할 수 있다.\n(“number of nodes = number of features”로 이해한 그림)\n\n\n다이어그램의 표현방식은 교재마다 달라서 모든 예시를 달달 외울 필요는 없습니다. 다만 임의의 다이어그램을 보고 대응하는 네트워크를 pytorch로 구현하는 능력은 매우 중요합니다.\n\n\n\nC. MNIST\n\\[\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n(다이어그램표현)\n\n\nLayer0,1,2 대신에 Input Layer, Hidden Layer, Output Layer로 표현함\n\n- 위의 다이어그램에 대응하는 코드\n- 가중치의 합은 784X32\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=28*28*1,out_features=32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid() \n)\n\n\n\n3. CPU vs GPU\n- 파이토치에서 GPU를 쓰는 방법을 알아보자. (사실 지금까지 우리는 CPU만 쓰고 있었음)\n\nA. GPU 사용방법\n- cpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_cpu = torch.tensor([0.0,0.1,0.2]).reshape(-1,1) \ny_cpu = torch.tensor([0.0,0.2,0.4]).reshape(-1,1) \nnet_cpu = torch.nn.Linear(1,1) \n\n\nnet_cpu(x_cpu)\n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nx_cpu\n\ntensor([[0.0000],\n        [0.1000],\n        [0.2000]])\n\n\n\n!nvidia-smi\n\nSat May  3 17:40:43 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:81:00.0 Off |                   On |\n| N/A   60C    P0              67W / 275W |                  N/A |     N/A      Default |\n|                                         |                      |              Enabled |\n+-----------------------------------------+----------------------+----------------------+\n\n+---------------------------------------------------------------------------------------+\n| MIG devices:                                                                          |\n+------------------+--------------------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |\n|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |\n|                  |                                |        ECC|                       |\n|==================+================================+===========+=======================|\n|  0    0   0   0  |               6MiB / 81050MiB  | 98      0 |  7   0    5    1    1 |\n|                  |               3MiB / 131072MiB |           |                       |\n+------------------+--------------------------------+-----------+-----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n\n\n- GPU로 올리기\n\ntorch.manual_seed(43052)\nx_gpu = x_cpu.to(\"cuda:0\")\ny_gpu = y_cpu.to(\"cuda:0\")\nnet_gpu = torch.nn.Linear(1,1).to(\"cuda:0\") \n\n\n!nvidia-smi\n\nSat May  3 17:41:54 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:81:00.0 Off |                   On |\n| N/A   60C    P0              70W / 275W |                  N/A |     N/A      Default |\n|                                         |                      |              Enabled |\n+-----------------------------------------+----------------------+----------------------+\n\n+---------------------------------------------------------------------------------------+\n| MIG devices:                                                                          |\n+------------------+--------------------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |\n|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |\n|                  |                                |        ECC|                       |\n|==================+================================+===========+=======================|\n|  0    0   0   0  |             395MiB / 81050MiB  | 98      0 |  7   0    5    1    1 |\n|                  |               5MiB / 131072MiB |           |                       |\n+------------------+--------------------------------+-----------+-----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n\n\n- GPU에 메모리 올리면 GPU메모리가 점유됨\n- cpu 혹은 gpu 연산이 가능한 메모리에 저장된 값들을 확인\n\nx_cpu, y_cpu, net_cpu.weight, net_cpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]]),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]]),\n Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n\nx_gpu, y_gpu, net_gpu.weight, net_gpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]], device='cuda:0'),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]], device='cuda:0'),\n Parameter containing:\n tensor([[-0.3467]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.8470], device='cuda:0', requires_grad=True))\n\n\n- gpu는 gpu끼리 연산가능하고 cpu는 cpu끼리 연산가능함\n(예시1)\n\nnet_cpu(x_cpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시2)\n\nnet_gpu(x_gpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시3)\n\n#net_cpu(x_gpu) \n\n(예시4)\n\n#net_gpu(x_cpu)\n\n(예시5)\n\ntorch.mean((y_cpu-net_cpu(x_cpu))**2)\n\ntensor(1.2068, grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시6)\n\ntorch.mean((y_gpu-net_gpu(x_gpu))**2)\n\ntensor(1.2068, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시7)\n\n#torch.mean((y_gpu-net_cpu(x_cpu))**2)\n\n(예시8)\n\n#torch.mean((y_cpu-net_gpu(x_gpu))**2)\n\n\n\nB. 시간측정(예비학습)\n\nimport time \n\n\nt1 = time.time()\n\n\nt2 = time.time()\n\n\nt2-t1\n\n3.919365882873535\n\n\n\n\nC. CPU vs GPU (500 nodes)\n- CPU (500 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.8856925964355469\n\n\n- GPU (500 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.821221113204956\n\n\n\n\nD. CPU vs GPU (200,000 nodes)\n- CPU(200,000)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n90.73985743522644\n\n\n- GPU (200,000)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.9625039100646973\n\n\n- 왜 이런 차이가 나는가?\n- 연산을 하는 주체는 코어인데 CPU는 수는 적지만 일을 잘하는 코어들을 가지고 있고 GPU는 일은 못하지만 다수의 코어를 가지고 있기 때문\n\n\nE. 주의점\n- tensor 일 경우\n\nx = torch.tensor([1,2,3])\nx.to(\"cuda:0\"), x\n\n(tensor([1, 2, 3], device='cuda:0'), tensor([1, 2, 3]))\n\n\n- net일 경우\n\nnet = torch.nn.Linear(1,1).to(\"cuda:0\")\nnet.weight, net.bias\n\n(Parameter containing:\n tensor([[-0.0084]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.6216], device='cuda:0', requires_grad=True))\n\n\n\n\n\n4. 확률적 경사하강법\n\nA. 의문\n- GPU 비쌈\n- 우리가 분석하는 데이터\n\nx = torch.linspace(-10,10,100000).reshape(-1,1)\neps = torch.randn(100000).reshape(-1,1)\ny = x*2 + eps \n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n- 데이터의 크기가 커지면 x.to(\"cuda:0\"), y.to(\"cuda:0\") 쓰면 문제 발생 \\(\\to\\) 이런식이면 GPU를 이용하여 아무런 분석도 못할것 같음??\n- 아이디어: 데이터를 100개중에 1개 꼴로만 쓰면 어떨까?\n\nplt.plot(x[::100],y[::100],'o',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n- 이것만 가지고도 적합해도 충분히 정확할 것 같다\n\n\nB. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?\n- 데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?\n- 아래의 알고리즘을 생각해보자.\n\n데이터를 반으로 나눈다.\n짝수obs의 x,y 그리고 net의 모든 파라메터를 GPU에 올린다.\nyhat, loss, grad, update 수행\n짝수obs의 x,y를 GPU메모리에서 내린다. 그리고 홀수obs의 x,y를 GPU메모리에 올린다.\nyhat, loss, grad, update 수행\n홀수obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수obs의 x,y를 GPU메모리에 올린다.\n반복\n\n\n이러면 되는거아니야???? —&gt; 맞아요\n\n\n\nC. 경사하강법, 확률적경사하강법, 미니배치 경사하강법\n10개의 샘플이 있다고 가정. \\(\\{(x_i,y_i)\\}_{i=1}^{10}\\)\n# ver1 – 모든 샘플을 이용하여 slope 계산\n(epoch 1) \\(loss=\\sum_{i=1}^{10}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2 \\to slope  \\to update\\)\n(epoch 2) \\(loss=\\sum_{i=1}^{10}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2 \\to slope  \\to update\\)\n…\n\n우리가 항상 이렇게 했죠!\n\n# ver2 – 하나의 샘플만을 이용하여 slope 계산\n(epoch 1)\n\n\\(loss=(y_1-\\hat{w}_0-\\hat{w}_1x_1)^2 \\to slope \\to update\\)\n\\(loss=(y_2-\\hat{w}_0-\\hat{w}_1x_2)^2 \\to slope \\to update\\)\n…\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n(epoch 2)\n\n\\(loss=(y_1-\\hat{w}_0-\\hat{w}_1x_1)^2  \\to slope  \\to  update\\)\n\\(loss=(y_2-\\hat{w}_0-\\hat{w}_1x_2)^2  \\to slope  \\to  update\\)\n…\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n…\n# ver3 – \\(m (\\leq n)\\) 개의 샘플을 이용하여 slope 계산\n\\(m=3\\)이라고 하자.\n(epoch 1)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n(epoch 2)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n…\n\n\nD. 용어의 정리\n옛날\n- ver1(모든): gradient descent, batch gradient descent\n- ver2(하나만): stochastic gradient descent\n- ver3(몇개만): mini-batch gradient descent, mini-batch stochastic gradient descent\n요즘\n- ver1(모든): gradient descent\n- ver2(하나만): stochastic gradient descent with batch size = 1\n- ver3(몇개만): stochastic gradient descent - https://www.deeplearningbook.org/contents/optimization.html, 알고리즘 8-1 참고.\n\n\nE. Dataset(ds), DataLoader(dl)\n\n취지는 알겠으나, C의 과정을 실제 구현하려면 진짜 어려움.. (입코딩과 손코딩의 차이) –&gt; 이걸 해결하기 위해서 파이토치에서는 DataLoader라는 오브젝트를 준비했음!\n\n- 데이터\n\nx=torch.tensor(range(10)).float().reshape(-1,1)\ny=torch.tensor([1.0]*5+[0.0]*5).reshape(-1,1)\ntorch.concat([x,y],axis=1)\n\ntensor([[0., 1.],\n        [1., 1.],\n        [2., 1.],\n        [3., 1.],\n        [4., 1.],\n        [5., 0.],\n        [6., 0.],\n        [7., 0.],\n        [8., 0.],\n        [9., 0.]])\n\n\n- ds오브젝트\n\nds = torch.utils.data.TensorDataset(x,y)\nds\n\n&lt;torch.utils.data.dataset.TensorDataset at 0x7f1ae80a6c20&gt;\n\n\n\nds.tensors \n# 생긴건 ds.tensors = (x,y) 임\n\n(tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]),\n tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]]))\n\n\n\nds[0],(x,y)[0] # (x,y) 튜플자체는 아님.. 인덱싱이 다르게 동작\n\n((tensor([0.]), tensor([1.])),\n tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]))\n\n\n- dl 오브젝트\n\ndl = torch.utils.data.DataLoader(ds, batch_size=3)\n\n\nfor x_mbatch,y_mbatch in dl:\n    print(f\"x_mini_batch:{x_mbatch.tolist()} \\t y_mini_batch:{y_mbatch.tolist()}\")\n\nx_mini_batch:[[0.0], [1.0], [2.0]]   y_mini_batch:[[1.0], [1.0], [1.0]]\nx_mini_batch:[[3.0], [4.0], [5.0]]   y_mini_batch:[[1.0], [1.0], [0.0]]\nx_mini_batch:[[6.0], [7.0], [8.0]]   y_mini_batch:[[0.0], [0.0], [0.0]]\nx_mini_batch:[[9.0]]     y_mini_batch:[[0.0]]\n\n\n- 마지막 관측치는 왜 단독 업데이트?? \\(\\to\\) shuffle=True 같은 옵션 존재\n\ndl = torch.utils.data.DataLoader(ds,batch_size=3,shuffle=True)\nfor x_mbatch,y_mbatch in dl:\n    print(f\"x_mini_batch:{x_mbatch.tolist()} \\t y_mini_batch:{y_mbatch.tolist()}\")\n\nx_mini_batch:[[9.0], [0.0], [8.0]]   y_mini_batch:[[0.0], [1.0], [0.0]]\nx_mini_batch:[[7.0], [5.0], [6.0]]   y_mini_batch:[[0.0], [0.0], [0.0]]\nx_mini_batch:[[3.0], [4.0], [1.0]]   y_mini_batch:[[1.0], [1.0], [1.0]]\nx_mini_batch:[[2.0]]     y_mini_batch:[[1.0]]\n\n\n\n\nF. 성능 체크\n- 목표 : 확률적 경사하강법과 그냥 경사하강법의 성늘을 ’동일 반복횟수’로 비교해보자\n- MNIST자료를 그냥 경사하강법으로 적합해보자\n\nimport torchvision\n\n\n#train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n#to_tensor = torchvision.transforms.ToTensor()\nX0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\nX1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\nX = torch.concat([X0,X1],axis=0).reshape(-1,784)\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n\nfor epoc in range(700):\n    # step1 \n    yhat = net(X)\n    # step2 \n    loss = loss_fn(yhat,y)\n    # step3     \n    loss.backward()\n    # step4 \n    optimizr.step()\n    optimizr.zero_grad()    \n\n\n((yhat &gt; 0.5) ==  y).float().mean()\n\ntensor(0.9953)\n\n\n- MNIST자료를 확률적 경사하강법으로 적합해보자. – 미니배치 쓰는 학습\n\n# train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n# to_tensor = torchvision.transforms.ToTensor()\n# X0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\n# X1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\n# X = torch.concat([X0,X1],axis=0).reshape(-1,784)\n# y = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n\n\nlen(X)/2048\n\n6.18408203125\n\n\n- (mini) batchsize 가 2048 이라면 한 epoch당 7회 update\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n\nfor epoc in range(100): \n    for xm,ym in dl:        \n        # step1 \n        ym_hat = net(xm)\n        # step2 \n        loss = loss_fn(ym_hat,ym)\n        # step3     \n        loss.backward()\n        # step4 \n        optimizr.step()\n        optimizr.zero_grad()\n\n\n((net(X) &gt; 0.5) ==  y).float().mean()\n\ntensor(0.9931)\n\n\n- 성능의 큰 차이가 없음"
  },
  {
    "objectID": "posts/1-2.회귀(회귀모형,손실함수,파이토치를이용한추정).html",
    "href": "posts/1-2.회귀(회귀모형,손실함수,파이토치를이용한추정).html",
    "title": "1-2, 2-1. 회귀(회귀모형, 손실함수, 파이토치를 이용한 추정)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport matplotlib.pyplot as plt \n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. 회귀모형\n\nA. 아이스 아메리카노 (가짜자료)\n- 카페주인 이상민씨는 온도와 아이스 아메리카노 판매량이 관계가 있다는 것을 확인하기 위해 하래의 100개의 데이터를 모았다.\n\ntemp = [-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632]\n\n\nsales= [-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340]\n\n- temp는 평균기온, sales는 아이스 아메리카노 판매량\n- 그래프를 그려보자\n\nplt.plot(temp,sales,'o')\n\n\n\n\n\n\n\n\n- 오늘 평균 기온이 0.5도이면 아이스 아메리카노가 얼마나 팔릴까?\n\n\nB. 자료를 만든 방법\n- 방법1 : \\(y_i= w_0+w_1 x_i +\\epsilon_i = 2.5 + 4x_i +\\epsilon_i, \\quad i=1,2,\\dots,n\\)\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps\n\n- sort()를 하면 인덱스 항이 생겨서 필요없으므로 _에 저장\n\nx[:5], y[:5]\n\n(tensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792]),\n tensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516]))\n\n\n- 방법2: \\({\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\)\n\n\\({\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)\n\n\nX = torch.stack([torch.ones(100),x],axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\nx = X[:,[1]]\n\n\nX[:5,:], y[:5,:]\n\n(tensor([[ 1.0000, -2.4821],\n         [ 1.0000, -2.3621],\n         [ 1.0000, -1.9973],\n         [ 1.0000, -1.6239],\n         [ 1.0000, -1.4792]]),\n tensor([[-8.5420],\n         [-6.5767],\n         [-5.9496],\n         [-4.4794],\n         [-4.2516]]))\n\n\n- true 와 관측값(observed data) 동시에 시각화\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\")\nplt.plot(x,2.5+4*x,'--',label=r\"true: $(x_i, 4x_i+2.5)$ // $y=4x+2.5$ \")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nC. 회귀분석\n- 관측한 자료 \\((x_i,y_i)\\) 이 선형성을 가지고 있을 때 이를 파악하여 새로운 \\(x\\)가 주어졌을 때 \\(\\hat{y}\\)(예측값)을 구할 수 있는 적당한 추세선을 찾는 것\n- 좀 더 정확하게 말하면 \\((x_1,y_1) \\dots (x_n,y_n)\\) 으로\n\\(\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\) 를 최대한 \\(\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}\\)와 비슷하게 찾는 것.\n\ngiven data : \\(\\big\\{(x_i,y_i) \\big\\}_{i=1}^{n}\\)\nparameter: \\({\\bf W}=\\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}\\)\nestimated parameter: \\({\\bf \\hat{W}}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\)\n\n- 추세선을 그리는 행위 = \\((w_0,w_1)\\)을 선택하는일\n\n\n\n4. 손실함수\n- \\((\\hat{w}_0,\\hat{w}_1)=(-5,10)\\)을 선택하여 선을 그려보고 적당한지 판단해보자\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\") \nWhat = torch.tensor([[-5.0],[10.0]])\nplt.plot(x,X@What,'--',label=r\"estimated line: $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 기울기와 절편 모두 너무 다르다\n- \\((\\hat{w}_0,\\hat{w}_1)=(2.5,3.5)\\)을 선택하여 선을 그려보고 적당한지 판단해보자\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\") \nWhat = torch.tensor([[2.5],[3.5]])\nplt.plot(x,X@What,'--',label=r\"estimated line: $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 기울기가 살짝 다른 듯 하다\n- \\((\\hat{w}_0,\\hat{w}_1)=(2.3,3.5)\\)을 선택하여 선을 그려보고 적당한지 판단해보자\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\") \nWhat = torch.tensor([[2.3],[3.5]])\nplt.plot(x,X@What,'--',label=r\"estimated: $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- \\((\\hat{w}_0,\\hat{w}_1)=(2.5,3.5)\\)를 했을 때와 \\((2.3,3,5)\\) 로 했을 때 중 어떤 것이 더 적당한가?\n\nA. loss 개념\n- (2.5,3.5) 가 더 적당해야할 것 같긴 한데 육안으로 판단 어려움\n- 이를 수식화하기 위해서 : loss의 개념 사용\n\n\\(loss = \\sum_{i=1}^{n}(y_i- \\hat{y}_i)^2 = \\sum_{i=1}^{n}\\big(y_i - (\\hat{w}_0+\\hat{w}_1x_i)\\big)^2\\)\n\n\\(=({\\bf y}-\\hat{\\bf y})^\\top({\\bf y}-\\hat{\\bf y})=({\\bf y}-{\\bf X}\\hat{\\bf W})^\\top({\\bf y}-{\\bf X}\\hat{\\bf W})\\)\n\n\nB. loss의 특징\n\n\\(y_i \\approx \\hat{y}_i\\) 일수록 loss 값이 작음\n\\(y_i \\approx \\hat{y}_i\\) 이 되도록 \\((\\hat{w}_0, \\hat{w}_1)\\)을 잘 찍으면 loss 값이 작음\n주황색 점선이 “적당할수록” loss 값이 작음\n\n\n\nC. loss 사용\n- 방법1 : \\(\\sum_{i=1}^{n}(y_i- \\hat{y}_i)^2\\)\n\nWhat = torch.tensor([[2.5],[3.5]])\nprint(f\"loss: {torch.sum((y - X@What)**2)}\")\n\nWhat = torch.tensor([[2.3],[3.5]])\nprint(f\"loss: {torch.sum((y - X@What)**2)}\")\n\nloss: 55.074012756347656\nloss: 59.3805046081543\n\n\n- 방법2 : \\(({\\bf y}-\\hat{\\bf y})^\\top({\\bf y}-\\hat{\\bf y})\\)\n\nWhat = torch.tensor([[2.5],[3.5]])\nprint(f\"loss: {(y - X@What).T @ (y - X@What)}\")\n\nWhat = torch.tensor([[2.3],[3.5]])\nprint(f\"loss: {(y - X@What).T @ (y - X@What)}\")\n\nloss: tensor([[55.0740]])\nloss: tensor([[59.3805]])\n\n\n\n\n\n5. 파이토치를 이용한 반복추정\n- 추정 전략 : 손실함수 + 경사하강법 * 1단계 : 아무 점선 긋기 * 2단계 : 1단계의 점선보다 loss값이 작은 하나의 직선으로 변경 * 3단계 : 1,2단계 반복\n\nA. 1단계 - 최초 점선\n- What 아무렇게나 설정\n\nWhat = torch.tensor([[-5.0],[10.0]])\nWhat\n\ntensor([[-5.],\n        [10.]])\n\n\n\nyhat = X@What\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\n\n\n\n\n\n\n\n\n\n\nB. 2단계 - update\n- ‘적당한 정도’ : loss 값이 작을수록 적당함\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat)\n\n\n\n\n\n\n\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875)\n\n\n- 현재 loss(=8587.6875)를 줄여야함\n\n최종적으로loss를 최소로 하는 \\((\\hat{w}_0,\\hat{w}_1)\\)을 구해야함\n함수의 최대값, 최소값을 컴퓨터로 찾는것 : ‘최적화’\n최적화의 방법 : 경사하강법\n\n- 경사하강법 (1차원)\n\n임의의 점을 찍음\n그 점에서 순간기울기를 구함 (접선) &lt;– 미분\n순간기울기(=미분계수)의 부호와 반대방향으로 점을 이동\n\n\n기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절 \\(\\to\\) \\(\\alpha\\)를 도입\n최종수식 :\\(\\hat{w} \\leftarrow \\hat{w} - \\alpha \\times \\frac{\\partial}{\\partial w}loss(w)\\)\n\n- 경사하강법 (2차원)\n\n\n임의의 점을 찍음\n그 점에서 순간기울기를 구함 (접평면) &lt;– 편미분\n순간기울기(=미분계수)의 부호와 반대방향으로 각각 점을 이동\n\n\n기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절 \\(\\to\\) \\(\\alpha\\)를 도입\n\n- 경사하강법 : loss를 줄이도록 \\(\\hat{W}\\)를 개선하는 방법\n\n수정값 = 원래값 - \\(\\alpha\\) \\(\\times\\) 기울어진 크기(=미분계수)\n\n미분계수와 반대방향으로 이동해야하기 때문에 마이너스 부호 사용\n\n\\(\\alpha\\)는 전체적인 보폭 크기 결정, 클수록 한번에 update에서 움직임이 큼\n\n- 우리가 구하고 싶은 것\n\n\\(\\hat{W}^{LSE}=\\underset{\\hat{W}}argmin ~ loss(\\hat{W})\\)\n\n- 요약\n\nx,X,W,y // X = [1 x], W = [w0, w1] (회귀분석에서는 W=β)\n회귀모형: y=X@W+ϵ = X@β+ϵ\ntrue: E(y)=X@W\nobserved: (x,y)\nestimated W = What = [w0hat, w1hat]’ &lt;– 아무값이나넣음\nestimated y = yhat = X@What = X@β̂\nloss = yhat이랑 y랑 얼마나 비슷한지 = sum((y-yhat)^2)\n(x,y) 보고 최적의 선분을 그리는것 = loss를 가장 작게 만드는 What = [w0hat, w1hat] 를 찾는것\n전략\n\n\n아무 What나 찍는다\n\n\n그거보다 더 나은 What을 찾는다.\n\n\n1-2를 반복한다.\n\n\n전략2가 어려운데, 이를 수행하는 방법이 경사하강법\n경사하강법 알고리즘: 더나은What = 원래What - \\(\\alpha\\)*미분값\n수식 \\[\\hat{\\bf W} \\leftarrow \\hat{\\bf W} - \\alpha \\times \\left.\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\right|_{{\\bf W}=\\hat{\\bf W}}\\]\n\n- 미분값 계산법 1) \\(\\to\\) 정확하지도 않고 번거로운 방법..\n\ndef l(w0,w1):\n    yhat = w0 + w1*x\n    return torch.sum((y-yhat)**2)\n\n\nl(-5,10)\n\ntensor(8587.6875)\n\n\n\nh=0.001\nprint((l(-5+h,10) - l(-5,10))/h)\nprint((l(-5,10+h) - l(-5,10))/h)\n\ntensor(-1341.7968)\ntensor(1190.4297)\n\n\n\nnew = What - 0.001 * torch.tensor([[-1341.7968],[1190.4297]])\nnew\n\ntensor([[-3.6582],\n        [ 8.8096]])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What,'-') # 원래What: 주황색\nplt.plot(x,X@new,'-') # 더나은What: 초록색\n\n\n\n\n\n\n\n\n- 수식\n\n편미분\n\\(\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\)\n\\(\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\)\n편미분 값을 이용\n\\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W}):= \\begin{bmatrix} \\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1}\\end{bmatrix}loss({\\bf W}) =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss({\\bf W}) \\\\ \\frac{\\partial}{\\partial w_1}loss({\\bf W})\\end{bmatrix}  =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1)\\end{bmatrix}\\]\n\n- 미분값 계산법 2) \\(\\to\\) 이것도 어려움…\n\nloss = (y - XWhat)'(y -  XWhat)\n= (y'- What'X')(y - XWhat)\n= y'y - y'XWhat - What'X'y + What'X'XWhat\nloss를 What으로 미분\nloss' = -X'y - X'y + 2X'XWhat \\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})= -2{\\bf X}^\\top {\\bf y} + 2{\\bf X}^\\top {\\bf X}{\\bf W}\\]\n\n\n-2*X.T@y + 2*X.T@X@What\n\ntensor([[-1342.2524],\n        [ 1188.9302]])\n\n\n- 미분값 계산법 3) (★)\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n- loss를 꼬리표의 근원인 What으로 미분\n\nloss.backward() \n\n- What 에 미분값이 저장\n\nWhat.grad\n\ntensor([[-1342.2524],\n        [ 1188.9305]])\n\n\n- 미분 전\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n None)\n\n\n\nloss.backward()\n\n- 미분 후\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-1342.2524],\n         [ 1188.9305]]))\n\n\n- 1회 업데이트 과정\n\nalpha=0.001\nprint(f\"{What.data} -- 수정전\")\nprint(f\"{-alpha*What.grad} -- 수정하는폭\")\nprint(f\"{What.data-alpha*What.grad} -- 수정후\")\nprint(f\"{torch.tensor([[2.5],[4]])} -- 참값\")\n\ntensor([[-5.],\n        [10.]]) -- 수정전\ntensor([[ 1.3423],\n        [-1.1889]]) -- 수정하는폭\ntensor([[-3.6577],\n        [ 8.8111]]) -- 수정후\ntensor([[2.5000],\n        [4.0000]]) -- 참값\n\n\n\nWbefore = What.data\nWafter = What.data - alpha * What.grad\nplt.plot(x,y,'o',label=r'observed data')\nplt.plot(x,X@Wbefore,'--', label=r\"$\\hat{\\bf y}_{before}={\\bf X}@\\hat{\\bf W}_{before}$\")\nplt.plot(x,X@Wafter,'--', label=r\"$\\hat{\\bf y}_{after}={\\bf X}@\\hat{\\bf W}_{after}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nC. 3단계 - iteration\n- What.grad = None을 꼭 해줘야함\n\nloss.backward() 의 역할\n\nWhat.grad \\(\\leftarrow\\) What.grad + What에서의미분값\n\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 최초의 직선을 만드는 값\nfor epoc in range(30):\n    yhat = X@What \n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    What.grad = None \n\n\nplt.plot(x,y,'o',label=r\"observed: $(x_i,y_i)$\")\nplt.plot(x,X@What.data,'--o', label=r\"estimated: $(x_i,\\hat{y}_i)$ -- after 30 iterations (=epochs)\", alpha=0.4 )\nplt.legend()"
  },
  {
    "objectID": "posts/1-1.torch(파이토치기본).html",
    "href": "posts/1-1.torch(파이토치기본).html",
    "title": "1-1. torch(파이토치 기본)",
    "section": "",
    "text": "1.import\n\nimport torch\n\n\n\n2.기초 지식\n- 선형대수학\n\n벡터와 행렬\n행렬의 곱셉\n트랜스포즈\n\n- 기초통계학(수리통계)\n\n정규분포, 이항분포\n모수, 추정\n\\(X_i \\overset{i.i.d.}{\\sim} N(0,1)\\)\n\n- 회귀분석\n\n독립변수(\\(y\\)), 설명변수(\\(X\\))\n\\({\\boldsymbol y} = {\\bf X}{\\boldsymbol \\beta} + {\\boldsymbol \\epsilon}\\)\n\n- 파이썬\n\n파이썬 기본문법\n넘파이, 판다스\n전반적인 클래스 지식 (__init__, self, …)\n상속\n\n\n\n3. torch\n\nA.벡터\n\ntorch.tensor([1,2,3])\n\ntensor([1, 2, 3])\n\n\n- 벡터끼리 덧셈\n\ntorch.tensor([1,2,3]) + torch.tensor([3,3,3])\n\ntensor([4, 5, 6])\n\n\n- 브로드캐스팅 가능 -&gt; 위에와 똑같은 기능\n\ntorch.tensor([1,2,3])+2\n\ntensor([3, 4, 5])\n\n\n\ntorch.tensor([1,2,3])+torch.tensor([2])\n\ntensor([3, 4, 5])\n\n\n\ntorch.tensor([1,2,3])+torch.tensor(2)\n\ntensor([3, 4, 5])\n\n\n\n\n\nB. 벡터와 매트릭스\n- 3x2 matrix\n\ntorch.tensor([[1,2],[3,4],[5,6]])\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- 3X1 matrix 는 3X1 열벡터(column vector)와 같음\n\ntorch.tensor([[1],[2],[3]]) \n\ntensor([[1],\n        [2],\n        [3]])\n\n\n- 1X2 matrix 는 1X2 행벡터(row vector)와 같음\n\ntorch.tensor([[1,2]]) \n\ntensor([[1, 2]])\n\n\n\nc. matrix 덧셈\n- 브로드캐스팅(숫자하나)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) - 1\n\ntensor([[0, 1],\n        [2, 3],\n        [4, 5]])\n\n\n- 아래와 같은 의미임\n\ntorch.tensor([[1,2],[3,4],[5,6]]) - torch.tensor([[1,1],[1,1],[1,1]])\n\ntensor([[0, 1],\n        [2, 3],\n        [4, 5]])\n\n\n- 브로드캐스팅(열)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-3],[-5]])\n\ntensor([[0, 1],\n        [0, 1],\n        [0, 1]])\n\n\n- 아래와 같은 의미임\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-1],[-3,-3],[-5,-5]])\n\ntensor([[0, 1],\n        [0, 1],\n        [0, 1]])\n\n\n- 브로드캐스팅(행)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-2]])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\n- 아래와 같은 의미임\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-2],[-1,-2],[-1,-2]])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\n잘못된 브로드캐스팅\n- 열로 브로드캐스팅 하려면 3X1 행렬이어야하지만 여기는 1X3 행렬\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-3,-5]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[20], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-3,-5]])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\n- 행으로 브로드캐스팅 하려면 1X2 행렬이어야하지만 여기는 2X1 행렬\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-2]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[21], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-2]])\n\nRuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0\n\n\n\n그냥 벡터를 넣으면 이상하게 행으로만 브로드캐스팅 됨\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-2])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\n- 열로는 안됨..\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-3,-5])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[23], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-3,-5])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\n\n\nD. 행렬곱\n정상적 행렬곱\n- (3X2) @ (2X1) = (3X1)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1],[2]])\n\ntensor([[ 5],\n        [11],\n        [17]])\n\n\n- (1X3) @ (3X2) = (1X2)\n\ntorch.tensor([[1,2,3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\ntensor([[22, 28]])\n\n\n잘못된 행렬곱\n- (3X2) @ (1X2) = (???)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1,2]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[26], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1,2]])\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 1x2)\n\n\n\n- (3X1) @ (3X2) = (???)\n\ntorch.tensor([[1],[2],[3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[27], line 1\n----&gt; 1 torch.tensor([[1],[2],[3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x1 and 3x2)\n\n\n\n이상하게 되는 것\n- (3X2) @ 행벡터(1X2)-&gt;(2X1)행렬로 바꿔주는듯 = (3X1) 행렬이 아닌 (1X3)행벡터로 나옴\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([1,2])\n\ntensor([ 5, 11, 17])\n\n\n- 행벡터(1X3) @ (3X2) = (1X2)\n\ntorch.tensor([1,2,3]) @ torch.tensor([[1,2],[3,4],[5,6]])\n\ntensor([22, 28])\n\n\n\n\nE. Transpose\n- 정방행렬 전치\n\ntorch.tensor([[1,2],[3,4]]).T \n\ntensor([[1, 3],\n        [2, 4]])\n\n\n- (NX1) 행렬 전치\n\ntorch.tensor([[1],[3]]).T \n\ntensor([[1, 3]])\n\n\n- (1XN) 행렬 전치\n\ntorch.tensor([[1,2]]).T \n\ntensor([[1],\n        [2]])\n\n\n\n\nF. reshape\n- 일반적인 사용\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,3)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n- Transpose와는 다르게 순서대로 reshape 해줌\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6,1)\n\ntensor([[1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\n- 차원 줄이기도 가능\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6)\n\ntensor([1, 2, 3, 4, 5, 6])\n\n\n- -1로 설정한 부분은 자동으로 지정됨\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,-1)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\n- -1만 넣으면 행벡터로 만들어버림\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1)\n\ntensor([1, 2, 3, 4, 5, 6])\n\n\n\ntorch.tensor([[[1,2],[2,30]],[[1,2],[3,3]]]).reshape(-1)\n\ntensor([ 1,  2,  2, 30,  1,  2,  3,  3])\n\n\n\n\nG. concat, stack (★★★)\n- concat\n\naxis=0 인 경우 0번째 차원을 기준으로 합쳐짐\naxis=1 인 경우 1번째 차원을 기준으로 합쳐짐\n\n\na = torch.tensor([[1],[3],[5]])\nb = torch.tensor([[2],[4],[6]])\ntorch.concat([a,b],axis=0)\n\ntensor([[1],\n        [3],\n        [5],\n        [2],\n        [4],\n        [6]])\n\n\n\na = torch.tensor([[1],[3],[5]])\nb = torch.tensor([[2],[4],[6]])\ntorch.concat([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- stack\n\naxis=0 : 0번째 차원을 추가\naxis=1 : 1번째 차원을 추가\n\n\na = torch.tensor([1,3,5])\nb = torch.tensor([2,4,6])\ntorch.stack([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DL2025",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nApr 29, 2025\n\n\n6-1. 신경망(데이터분석 코딩패턴)\n\n\n이상민 \n\n\n\n\nApr 28, 2025\n\n\n5-2. 신경망(신경망의 표현, GPU사용법, 확률적경사하강법)\n\n\n이상민 \n\n\n\n\nApr 27, 2025\n\n\n5-1. 신경망(예측, 시벤코정리의 이면, 드랍아웃)\n\n\n이상민 \n\n\n\n\nApr 26, 2025\n\n\n4-2. 신경망(꺽인 그래프의 한계, 시벤코 정리, MNIST)\n\n\n이상민 \n\n\n\n\nApr 25, 2025\n\n\n4-1. 신경망(로지스틱의 한계 극복)\n\n\n이상민 \n\n\n\n\nApr 24, 2025\n\n\n3-2. 로지스틱(sig, BCELoss, Adam)\n\n\n이상민 \n\n\n\n\nMar 28, 2025\n\n\n3-1. 회귀,로지스틱(파이토치식 코딩패턴 2, 로지스틱 모형)\n\n\n이상민 \n\n\n\n\nMar 27, 2025\n\n\n2-2. 회귀(파라메터 학습과정, MSE, 파이토치식 코딩패턴1)\n\n\n이상민 \n\n\n\n\nMar 26, 2025\n\n\n1-2, 2-1. 회귀(회귀모형, 손실함수, 파이토치를 이용한 추정)\n\n\n이상민 \n\n\n\n\nMar 25, 2025\n\n\n1-1. torch(파이토치 기본)\n\n\n이상민 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/3-1.회귀,로지스틱(파이토치식코딩패턴2,로지스틱모형).html",
    "href": "posts/3-1.회귀,로지스틱(파이토치식코딩패턴2,로지스틱모형).html",
    "title": "3-1. 회귀,로지스틱(파이토치식 코딩패턴 2, 로지스틱 모형)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport matplotlib.pyplot as plt \n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. 파이토치식 코딩패턴 2\n- 복습\n\n모델링 : X \\(\\to\\) y 가는 패턴(추세선)을 찾는 것\n관측자료 (x,y) – with error\n추세선(underlying) – (x,yhat=X@W) without error\n모델링: 에러가포함된 자료에서 error-free 한 structure를 찾는것\n모델링의 철칙: error-free 한 structure를 찾으려고 노력해야지.. error를 따라가려고 노력하면 X\n오차: error-free한 스트럭쳐(모델)이랑 실제관측데이터의 갭이 있는데, 이 갭을 설명해주는 역할\n\n- 데이터 만들기\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\nX = torch.stack([torch.ones(100),x],axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\nx = X[:,[1]]\n\n\nA. bias의 사용\n- net에서 bias를 사용\n\nin_features=2 \\(\\to\\) in_features=1\nbias=False \\(\\to\\) bias=True\nX(1벡터 포함) \\(\\to\\) x사용\n\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=1,\n    out_features=1,\n    bias=True\n) # net(x) = x@net.weight.T + net.bias \nnet.bias.data = torch.tensor([-5.0])\nnet.weight.data = torch.tensor([[10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(x)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.bias.data, net.weight.data\n\n(tensor([2.4290]), tensor([[4.0144]]))\n\n\n\n\n\nB. 잘못된 코드(비효율적)\n- bias 디폴트로 True\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과 시각화\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');\n\n\n\n\n\n\n\n\n- 나쁘지 않다?\n\n절편의 회귀계수(가중치)를 두 개로 나눠서 추정해서..합이 2.5가 되긴 함 \\(\\to\\) 비효율적\n\n\nnet.weight, net.bias\n\n(Parameter containing:\n tensor([[-1.2161,  4.0080]], requires_grad=True),\n Parameter containing:\n tensor([3.6610], requires_grad=True))\n\n\n\n\n3. 로지스틱 모형\n\nA. \\(\\hat{y} = ??\\)\n- \\(X\\) 를 가지고 \\(y\\)를 맞추는 아래와 같은 문제!\n\nx = torch.tensor([-6,-5,-4,-3,-2,-1, 0, 1, 2, 3, 4, 5, 6.0]).reshape(-1,1)\ny = torch.tensor([ 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1]).reshape(-1,1)\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n- 아래와 같이 모형화\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x)/(1+torch.exp(x)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nB. \\(\\hat{\\bf y} = \\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))}\\)\n- 산점도가 꼭 아래와 같은 방식이 아니라면?\n\n\\(x\\)가 증가할수록 \\(y\\)가 0이 된다면?\n0 근처에서 변화가 일어나지 않고 2 긑처에서 변화가 일어난다면?\n변화가 좀더 급하거나 환만하게 일어난다면?\n\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(5*x+3)/(1+torch.exp(5*x+3)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n#plt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x)/(1+torch.exp(x)),'o--', label = \"underlying type1 (without error)\", color=\"C1\")\nplt.plot(x,torch.exp(5*x)/(1+torch.exp(5*x)),'o--', label = \"underlying type2 (without error)\", color=\"C2\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 회귀 vs 로지스틱\n\n\\({\\bf X} \\to {\\bf y}\\) 에 대한 패턴이\n\\(\\text{linr}({\\bf X}) \\approx {\\bf y}\\) 이라면 회귀!\n\\({\\bf X} \\to {\\bf y}\\) 에 대한 패턴이\n\\(\\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))} \\approx {\\bf y}\\)이라면 로지스틱!\n\n\n\nC. 로지스틱 모형\n- \\(x\\)가 커질수록 \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 \\(\\leftarrow\\) 외워야함!!\n\n\\(y_i \\sim {\\cal B}(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)} = \\frac{1}{1+\\exp(-w_0-w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\n- 회귀모형과 로지스틱 모형의 비교\n\n회귀모형: \\(y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)\\)[1]\n로지스틱: \\(y_i \\sim {\\cal B}\\big(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\big)\\)\n\n- 우리가 예측하고 싶은것\n\n회귀모형: 정규분포의 평균을 예측하고 싶음. 즉 \\(w_0+w_1x_i\\)를 예측하고 싶음. 예측값으로는 \\(\\hat{w}_0 + \\hat{w}_1x_i\\)를 사용!\n로지스틱: 베르누이의 평균을 예측하고 싶음. 즉 \\(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)를 예측하고 싶음. 예측값으로는 \\(\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}\\)를 사용!"
  },
  {
    "objectID": "posts/2-2.회귀(파라메터학습과정,MSE,파이토치식코딩패턴).html",
    "href": "posts/2-2.회귀(파라메터학습과정,MSE,파이토치식코딩패턴).html",
    "title": "2-2. 회귀(파라메터 학습과정, MSE, 파이토치식 코딩패턴1)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt \n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. 파라메터 학습과정\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\nX = torch.stack([torch.ones(100),x],axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\nx = X[:,[1]]\n\n\nA. 학습과정 print\n\nWhat = torch.tensor([[-5.0],[10.0]], requires_grad=True)\nalpha = 0.001\nprint(f\"시작값 = {What.data.reshape(-1)}\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - alpha * What.grad\n    print(f'loss = {loss:.2f} \\n업데이트폭 = {-alpha * What.grad.reshape(-1)} \\n업데이트결과: {What.data.reshape(-1)}')\n    What.grad = None\n\n시작값 = tensor([-5., 10.])\nloss = 8587.69 \n업데이트폭 = tensor([ 1.3423, -1.1889]) \n업데이트결과: tensor([-3.6577,  8.8111])\nloss = 5675.21 \n업데이트폭 = tensor([ 1.1029, -0.9499]) \n업데이트결과: tensor([-2.5548,  7.8612])\nloss = 3755.64 \n업데이트폭 = tensor([ 0.9056, -0.7596]) \n업데이트결과: tensor([-1.6492,  7.1016])\nloss = 2489.58 \n업데이트폭 = tensor([ 0.7431, -0.6081]) \n업데이트결과: tensor([-0.9061,  6.4935])\nloss = 1654.04 \n업데이트폭 = tensor([ 0.6094, -0.4872]) \n업데이트결과: tensor([-0.2967,  6.0063])\nloss = 1102.32 \n업데이트폭 = tensor([ 0.4995, -0.3907]) \n업데이트결과: tensor([0.2028, 5.6156])\nloss = 737.84 \n업데이트폭 = tensor([ 0.4091, -0.3136]) \n업데이트결과: tensor([0.6119, 5.3020])\nloss = 496.97 \n업데이트폭 = tensor([ 0.3350, -0.2519]) \n업데이트결과: tensor([0.9469, 5.0501])\nloss = 337.71 \n업데이트폭 = tensor([ 0.2742, -0.2025]) \n업데이트결과: tensor([1.2211, 4.8477])\nloss = 232.40 \n업데이트폭 = tensor([ 0.2243, -0.1629]) \n업데이트결과: tensor([1.4454, 4.6848])\nloss = 162.73 \n업데이트폭 = tensor([ 0.1834, -0.1311]) \n업데이트결과: tensor([1.6288, 4.5537])\nloss = 116.63 \n업데이트폭 = tensor([ 0.1500, -0.1056]) \n업데이트결과: tensor([1.7787, 4.4480])\nloss = 86.13 \n업데이트폭 = tensor([ 0.1226, -0.0851]) \n업데이트결과: tensor([1.9013, 4.3629])\nloss = 65.93 \n업데이트폭 = tensor([ 0.1001, -0.0687]) \n업데이트결과: tensor([2.0014, 4.2942])\nloss = 52.57 \n업데이트폭 = tensor([ 0.0818, -0.0554]) \n업데이트결과: tensor([2.0832, 4.2388])\nloss = 43.72 \n업데이트폭 = tensor([ 0.0668, -0.0447]) \n업데이트결과: tensor([2.1500, 4.1941])\nloss = 37.86 \n업데이트폭 = tensor([ 0.0545, -0.0361]) \n업데이트결과: tensor([2.2045, 4.1579])\nloss = 33.97 \n업데이트폭 = tensor([ 0.0445, -0.0292]) \n업데이트결과: tensor([2.2490, 4.1287])\nloss = 31.40 \n업데이트폭 = tensor([ 0.0363, -0.0236]) \n업데이트결과: tensor([2.2853, 4.1051])\nloss = 29.70 \n업데이트폭 = tensor([ 0.0296, -0.0191]) \n업데이트결과: tensor([2.3150, 4.0860])\nloss = 28.57 \n업데이트폭 = tensor([ 0.0242, -0.0155]) \n업데이트결과: tensor([2.3392, 4.0705])\nloss = 27.83 \n업데이트폭 = tensor([ 0.0197, -0.0125]) \n업데이트결과: tensor([2.3589, 4.0580])\nloss = 27.33 \n업데이트폭 = tensor([ 0.0161, -0.0101]) \n업데이트결과: tensor([2.3750, 4.0479])\nloss = 27.00 \n업데이트폭 = tensor([ 0.0131, -0.0082]) \n업데이트결과: tensor([2.3881, 4.0396])\nloss = 26.79 \n업데이트폭 = tensor([ 0.0107, -0.0067]) \n업데이트결과: tensor([2.3988, 4.0330])\nloss = 26.64 \n업데이트폭 = tensor([ 0.0087, -0.0054]) \n업데이트결과: tensor([2.4075, 4.0276])\nloss = 26.55 \n업데이트폭 = tensor([ 0.0071, -0.0044]) \n업데이트결과: tensor([2.4146, 4.0232])\nloss = 26.48 \n업데이트폭 = tensor([ 0.0058, -0.0035]) \n업데이트결과: tensor([2.4204, 4.0197])\nloss = 26.44 \n업데이트폭 = tensor([ 0.0047, -0.0029]) \n업데이트결과: tensor([2.4251, 4.0168])\nloss = 26.41 \n업데이트폭 = tensor([ 0.0038, -0.0023]) \n업데이트결과: tensor([2.4290, 4.0144])\n\n\n\n\nB. yhat의 관점에서 시각화\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nplt.plot(x,y,'o',label = \"observed\")\nfig = plt.gcf()\nax = fig.gca()\nax.plot(x,X@What.data,'--',color=\"C1\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - alpha * What.grad\n    ax.plot(x,X@What.data,'--',color=\"C1\",alpha=0.1)\n    What.grad = None\n\n\n\n\n\n\n\n\n\n\nC. loss의 관점에서 시각화\n\ndef plot_loss():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax.azim = 30  ## 3d plot의 view 조절 \n    ax.dist = 8   ## 3d plot의 view 조절 \n    ax.elev = 5   ## 3d plot의 view 조절 \n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    plt.close(fig)  # 자동 출력 방지\n    return fig\n\n\ndef l(w0hat,w1hat):\n    yhat = w0hat + w1hat*x\n    return torch.sum((y-yhat)**2)\n\n\nfig = plot_loss()\nax = fig.gca()\nax.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\nax.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue', label=r\"initial $\\hat{\\bf W}=[-5, 10]'$\")\nax.legend()\nfig\n\n/tmp/ipykernel_144216/2229765328.py:13: MatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n\n\nD. 애니메이션\n\nfrom matplotlib import animation\n\n\nplt.rcParams['figure.figsize'] = (7.5,2.5)\nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n\ndef show_animation(alpha=0.001):\n    ## 1. 히스토리 기록을 위한 list 초기화\n    loss_history = [] \n    yhat_history = [] \n    What_history = [] \n\n    ## 2. 학습 + 학습과정기록\n    What= torch.tensor([[-5.0],[10.0]],requires_grad=True)\n    What_history.append(What.data.tolist())\n    for epoc in range(30): \n        yhat=X@What ; yhat_history.append(yhat.data.tolist())\n        loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n        loss.backward() \n        What.data = What.data - alpha * What.grad; What_history.append(What.data.tolist())\n        What.grad = None    \n\n    ## 3. 시각화 \n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n    #### ax1: yhat의 관점에서.. \n    ax1.plot(x,y,'o',label=r\"$(x_i,y_i)$\")\n    line, = ax1.plot(x,yhat_history[0],label=r\"$(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    #### ax2: loss의 관점에서.. \n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax2.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax2.azim = 30  ## 3d plot의 view 조절 \n    ax2.dist = 8   ## 3d plot의 view 조절 \n    ax2.elev = 5   ## 3d plot의 view 조절 \n    ax2.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax2.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax2.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax2.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    ax2.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\n    ax2.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue')\n    ax2.legend()\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(What_history)[epoc,0],np.array(What_history)[epoc,1],loss_history[epoc],color='grey')\n        fig.suptitle(f\"alpha = {alpha} / epoch = {epoc}\")\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\nani = show_animation(alpha=0.001)\nani\n\n/tmp/ipykernel_144216/464110397.py:36: MatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nE. 학습률(\\(\\alpha\\)) 다양하게\n- \\(\\alpha\\)가 너무 작아서 비효율적\n\nshow_animation(alpha=0.0001)\n\n/tmp/ipykernel_144216/464110397.py:36: MatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- \\(\\alpha\\) 가 크다고 무조건 좋은것도 아님\n\nshow_animation(alpha=0.0083)\n\n/tmp/ipykernel_144216/464110397.py:36: MatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 수렴을 안할수도 있음\n\nshow_animation(alpha=0.0085)\n\n/tmp/ipykernel_144216/464110397.py:36: MatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- \\(\\alpha\\) 를 너무 크게함\n\nshow_animation(alpha=0.01)\n\n/tmp/ipykernel_144216/464110397.py:36: MatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nplt.rcdefaults()\nplt.rcParams['figure.figsize'] = 4.5,3.0 \n\n\n\n\n3. SSE \\(\\to\\) MSE\n- 학습률 선택하는 것이 중요\n- 손실함수를 SSE로 설정하면 학습률 선택에서 비효율적\n- \\(\\to\\) MSE !!!\n손실함수가 SSE일 때 코드\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    loss = torch.sum((y-yhat)**2)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.001 * What.grad\n    What.grad = None\n\n\nWhat.data\n\ntensor([[2.4290],\n        [4.0144]])\n\n\n손실함수가  MSE일 때 코드\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    loss = torch.sum((y-yhat)**2)/100 # torch.mean((y-yhat)**2)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n\nWhat.data\n\ntensor([[2.4290],\n        [4.0144]])\n\n\n\n\n4. 파이토치식 코딩패턴 1\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\nX = torch.stack([torch.ones(100),x],axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\nx = X[:,[1]]\n\n\nA. 기본 패턴 (★)\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    loss = torch.sum((y-yhat)**2)/100\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');\n\n\n\n\n\n\n\n\n\n\nB. Step2 loss값 계산 \\(\\to\\) loss_fn 이용\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    #loss = torch.sum((y-yhat)**2)/100\n    loss = loss_fn(yhat,y) # 여기서는 큰 상관없지만 습관적으로 yhat을 먼저넣는 연습을 하자!!\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');\n\n\n\n\n\n\n\n\n\n\nC. Step3 yhat 계산 \\(\\to\\) net 이용\n- 원래 방식\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nyhat= X@What\nyhat[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n# yhat = net(X) \nnet = torch.nn.Linear(\n    in_features=2, # X:(n,2) --&gt; 2 \n    out_features=1, # yhat:(n,1) --&gt; 1 \n    bias=False \n)\n\n- .T(전치를 꼭 해서 넣어줘야함)\n\nnet.weight.data = torch.tensor([[-5.0], [10.0]]).T\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n- 아래 값이 모두 같은 것을 알 수 있음\n\nnet(X)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(X@What)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(X@net.weight.T)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n- loss_fn, net 사용 코드\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat\n    # yhat = X@What \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    net.weight.data = net.weight.data - 0.1 * net.weight.grad\n    net.weight.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');\n\n\n\n\n\n\n\n\n\n\nD. Step4 update \\(\\to\\) optimizer 이용\n- 기존의 방식\n\n## -- 준비과정 -- ## \n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n\n\n## -- 1에폭진행 -- ## \n# step1: \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nprint(net.weight.data)\nnet.weight.grad = None\n\ntensor([[-5., 10.]])\ntensor([[-3.6577,  8.8111]])\n\n\n\n## -- 2에폭진행 -- ## \n# step1: 2에폭진행\nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nprint(net.weight.data)\nnet.weight.grad = None\n\ntensor([[-3.6577,  8.8111]])\ntensor([[-2.5548,  7.8612]])\n\n\n- optimizer 이용한 코드\n\n## -- 준비과정 -- ## \n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비\noptimizr = torch.optim.SGD(net.parameters(),lr=0.1) #이게 추가됨\n\n\n## -- 1에폭진행 -- ## \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\n#net.weight.data = net.weight.data - 0.1 * net.weight.grad\noptimizr.step()\nprint(net.weight.data)\n#net.weight.grad = None\noptimizr.zero_grad()\n\ntensor([[-5., 10.]])\ntensor([[-3.6577,  8.8111]])\n\n\n\n## -- 2에폭진행 -- ## \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\n#net.weight.data = net.weight.data - 0.1 * net.weight.grad\noptimizr.step()\nprint(net.weight.data)\n#net.weight.grad = None\noptimizr.zero_grad()\n\ntensor([[-3.6577,  8.8111]])\ntensor([[-2.5548,  7.8612]])\n\n\n- 최종 loss_fn, net, optimizer 사용 코드\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/3-2.로지스틱(sig,BCELoss,Adam).html",
    "href": "posts/3-2.로지스틱(sig,BCELoss,Adam).html",
    "title": "3-2. 로지스틱(sig, BCELoss, Adam)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport matplotlib.pyplot as plt \nimport numpy as np\nimport pandas as pd\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. 로지스틱 -sig(linr(x))\n\nA. 희귀모형과 로지스틱\n- 모형의 비교\n\n회귀모형: \\(y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)\\)[1]\n로지스틱: \\(y_i \\sim {\\cal B}\\big(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\big)\\)\n\n- 우리가 예측하고 싶은것\n\n회귀모형: 정규분포의 평균을 예측하고 싶음. 즉 \\(w_0+w_1x_i\\)를 예측하고 싶음. 예측값으로는 \\(\\hat{w}_0 + \\hat{w}_1x_i\\)를 사용!\n로지스틱: 베르누이의 평균을 예측하고 싶음. 즉 \\(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)를 예측하고 싶음. 예측값으로는 \\(\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}\\)를 사용!\n\n\n\nB. 데이터 - 스펙과 취업\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0,w1 = -1, 5\nprob = torch.exp(w0+w1*x) / (1+torch.exp(w0+w1*x)) \ny = torch.bernoulli(prob)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'.',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nC. Step1 : net 설계 (모델링)\n- 최초의 곡선\n\n임의의 \\(\\hat{w_0}, \\hat{w_1}\\) 설정\n초기값 \\(\\hat{w_0}=-0.8\\), \\(\\hat{w_1}=-0.3\\)\n실제값 \\(\\hat{w_0}=-1\\), \\(\\hat{w_1}=5\\)\n\n- 방법1 : l1, sigmoid\n\nl1 = torch.nn.Linear(1,1)\nl1(x)\n\ntensor([[ 0.6311],\n        [ 0.6304],\n        [ 0.6297],\n        ...,\n        [-0.6902],\n        [-0.6909],\n        [-0.6916]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n\n\ndef sigmoid(x):\n    return torch.exp(x)/(1+torch.exp(x))\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,sigmoid(l1(x)).data,'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 방법2 : l1, a1\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n\n\na1 = torch.nn.Sigmoid()\n\n- 직접 만든 함수함수와 결과 같음\n\nsigmoid(l1(x)), a1(l1(x))\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;DivBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;))\n\n\n- 방법3 : l1, a1 \\(\\to\\) net\n\n현재 구조\n\n\\[{\\bf x} \\overset{l_1}{\\to} {\\bf u} \\overset{a_1}{\\to} {\\bf v} = \\hat{\\bf y}\\]\n\n함수 \\(l_1, a_1\\) 의 합성을 하나로 묶기\n\n\\[(a_1\\circ l_1)({\\bf x}) := net({\\bf x})\\] - 한번에 이런 기능을 해주는 \\(net\\) 만들기\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\na1 = torch.nn.Sigmoid()\n\n\nnet = torch.nn.Sequential(l1,a1)\n\n- 셋 다 같은 결과\n\nnet(x), a1(l1(x)), sigmoid(l1(x))\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;DivBackward0&gt;))\n\n\n- net 구조 살펴보기\n\nnet[0], net[1]\n\n(Linear(in_features=1, out_features=1, bias=True), Sigmoid())\n\n\n\nl1 is net[0]\n\nTrue\n\n\n\na1 is net[1]\n\nTrue\n\n\n- 방법4 : net을 바로 만들기\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.3]])\nnet[0].bias.data = torch.tensor([-0.8])\nyhat = net(x)\n\n\nnet(x)\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\n\nD. Step 1~4\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n\nfor epoc in range(4900):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 5000 epochs')\n\nText(0.5, 1.0, 'after 5000 epochs')\n\n\n\n\n\n\n\n\n\n\n\n\n3. 학습과정 시각화, 문제인식\n\nA. 시각화를 위한 준비\n\ndef plot_loss(loss_fn, ax=None, Wstar=[-1,5]):\n    w0hat,w1hat =torch.meshgrid(torch.arange(-10,3,0.1),torch.arange(-1,10,0.1),indexing='ij')\n    w0hat = w0hat.reshape(-1)\n    w1hat = w1hat.reshape(-1)\n    def l(w0hat,w1hat):\n        yhat = torch.exp(w0hat+w1hat*x)/(1+torch.exp(w0hat+w1hat*x))\n        return loss_fn(yhat,y) \n    loss = list(map(l,w0hat,w1hat))\n    #---#\n    if ax is None: \n        fig = plt.figure()\n        ax = fig.add_subplot(1,1,1,projection='3d')\n    ax.scatter(w0hat,w1hat,loss,s=0.001) \n    ax.scatter(w0hat[::20],w1hat[::20],loss[::20],s=0.1,color='C0') \n    w0star,w1star = np.array(Wstar).reshape(-1)\n    ax.scatter(w0star,w1star,l(w0star,w1star),s=200,marker='*',color='red',label=f\"W=[{w0star:.1f},{w1star:.1f}]\")\n    #---#\n    ax.elev = 15\n    #ax.dist = -20\n    ax.azim = 75    \n    ax.legend()\n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-10,-5,0])  # x축 틱 간격 설정\n    ax.set_yticks([-10,0,10])  # y축 틱 간격 설정\n\n\ndef _learn_and_record(net, loss_fn, optimizr):\n    yhat_history = [] \n    loss_history = []\n    What_history = []\n    Whatgrad_history = []\n    What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n    for epoc in range(100): \n        ## step1 \n        yhat = net(x)\n        ## step2 \n        loss = loss_fn(yhat,y)\n        ## step3\n        loss.backward() \n        ## step4 \n        optimizr.step()\n        ## record \n        if epoc % 5 ==0: \n            yhat_history.append(yhat.reshape(-1).data.tolist())\n            loss_history.append(loss.item())\n            What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n            Whatgrad_history.append([net[0].bias.grad.item(), net[0].weight.grad.item()])\n        optimizr.zero_grad() \n        \n    return yhat_history, loss_history, What_history, Whatgrad_history\n    \ndef show_animation(net, loss_fn, optimizr):\n    yhat_history,loss_history,What_history,Whatgrad_history = _learn_and_record(net,loss_fn,optimizr)\n    \n    fig = plt.figure(figsize=(10,5))\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n    ## ax1: 왼쪽그림 \n    ax1.scatter(x,y,alpha=0.01)\n    ax1.scatter(x[0],y[0],color='C0',label=r\"observed data = $(x_i,y_i)$\")\n    ax1.plot(x,prob,'--',label=r\"prob (true) = $(x_i,\\frac{exp(-1+5x_i)}{1+exp(-1+5x_i)})$\")    \n    line, = ax1.plot(x,yhat_history[0],'--',label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    ## ax2: 오른쪽그림 \n    plot_loss(loss_fn,ax2)\n    ax2.scatter(np.array(What_history)[0,0],np.array(What_history)[0,1],loss_history[0],color='blue',s=200,marker='*')    \n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        w0hat = np.array(What_history)[epoc,0]\n        w1hat = np.array(What_history)[epoc,1]\n        w0hatgrad = np.array(Whatgrad_history)[epoc,0]\n        w1hatgrad = np.array(Whatgrad_history)[epoc,1]\n        ax2.scatter(w0hat,w1hat,loss_history[epoc],color='grey')\n        ax2.set_title(f\"What.grad=[{w0hatgrad:.4f},{w1hatgrad:.4f}]\",y=0.8)\n        fig.suptitle(f\"epoch={epoc*5} // What=[{w0hat:.2f},{w1hat:.2f}] // Loss={loss_fn.__class__.__name__} // Opt={optimizr.__class__.__name__}\")\n        return line\n    ani = animation.FuncAnimation(fig, animate, frames=20)    \n    plt.close()\n    return ani\n\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n\nloss_fn = torch.nn.MSELoss()\nplot_loss(loss_fn)\n\n\n\n\n\n\n\n\n\ntorch.manual_seed(42)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nB. 좋은 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n\n\nC. 가능성 있는 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n\n\nD. 최악의 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n\n\n\n4. 손실함수의 개선\n\nA. BCE Loss를 사용해서 학습\n- BCE Loss\n\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\)\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    #loss = torch.mean((y-yhat)**2) # loss_fn(yhat,y)\n    loss = -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat))\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n- BEC Loss 불러와서 쓰기\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) # yhat부터 써야함\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n\n\nB. Loss Function 시각화\n- MSE Loss\n\nplot_loss(torch.nn.MSELoss())\n\n\n\n\n\n\n\n\n- BCE Loss\n\nplot_loss(torch.nn.BCELoss())\n\n\n\n\n\n\n\n\n\nfig = plt.figure()\nax1 = fig.add_subplot(1,2,1,projection='3d')\nax2 = fig.add_subplot(1,2,2,projection='3d')\nplot_loss(torch.nn.MSELoss(),ax1)\nplot_loss(torch.nn.BCELoss(),ax2)\n\n\n\n\n\n\n\n\n\n\nC. 좋은 초기값 비교\n- MSE Loss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCE Loss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nD. 가능성 있는 초기값\n- MSE Loss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n- BCE Loss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n\n\nE. 최악의 초기값\n- MSE Loss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n- BCE Loss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n\n\n\n5. 옵티마이저 개선\n\nA. 좋은 초기값\n- MSE Loss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8470])\nnet[0].weight.data = torch.tensor([[-0.3467]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- MSE Loss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nB. 가능성 있는 초기값\n- MSE Loss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n- MSE Loss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n\n\nC. 최악의 초기값\n- MSE Loss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n#---#\n#show_animation(net,loss_fn,optimizr)\n\n- MSE Loss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n\n6. 로지스틱의 한계\n\nA. 기사\n\n스펙이 너무 높아도 취업이 안됨\n\n\n\nB. 가짜데이터 (스펙의 역설)\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\ndf\n\n\n\n\n\n\n\n\nx\nprob\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nC. 로지스틱 적합\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---# \nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data, '--', label= r\"prob (estimated) = $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nD. 로지스틱 한계극복 아이디어\n- sigmoid를 넣기 전의 상태가 직선이 아니라 꺽이는 직선이어야 함\n\na = torch.nn.Sigmoid()\n\n\nfig,ax = plt.subplots(4,2,figsize=(8,8))\nu1 = torch.tensor([-6,-4,-2,0,2,4,6])\nu2 = torch.tensor([6,4,2,0,-2,-4,-6])\nu3 = torch.tensor([-6,-2,2,6,2,-2,-6])\nu4 = torch.tensor([-6,-2,2,6,4,2,0])\nax[0,0].plot(u1,'--o',color='C0',label = r\"$u_1$\")\nax[0,0].legend()\nax[0,1].plot(a(u1),'--o',color='C0',label = r\"$a(u_1)=\\frac{exp(u_1)}{exp(u_1)+1}$\")\nax[0,1].legend()\nax[1,0].plot(u2,'--o',color='C1',label = r\"$u_2$\")\nax[1,0].legend()\nax[1,1].plot(a(u2),'--o',color='C1',label = r\"$a(u_2)=\\frac{exp(u_2)}{exp(u_2)+1}$\")\nax[1,1].legend()\nax[2,0].plot(u3,'--o',color='C2', label = r\"$u_3$\")\nax[2,0].legend()\nax[2,1].plot(a(u3),'--o',color='C2', label = r\"$a(u_3)=\\frac{exp(u_3)}{exp(u_3)+1}$\")\nax[2,1].legend()\nax[3,0].plot(u4,'--o',color='C3', label = r\"$u_4$\")\nax[3,0].legend()\nax[3,1].plot(a(u4),'--o',color='C3', label = r\"$a(u_4)=\\frac{exp(u_4)}{exp(u_4)+1}$\")\nax[3,1].legend()"
  },
  {
    "objectID": "posts/4-2.신경망(꺽인그래프한계,시벤코정리,MNIST).html",
    "href": "posts/4-2.신경망(꺽인그래프한계,시벤코정리,MNIST).html",
    "title": "4-2. 신경망(꺽인 그래프의 한계, 시벤코 정리, MNIST)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. 꺽인 그래프의 한계\n- 지난시간에 배운 기술은 sig를 취하기 전이 꺽은 선인 형태만 가능하다. 표현력이 부족하다.\n- 하지만 그렇게 나쁘지많은 또 않다\n\nA. Step은 표현 불가능하지 않을까?\n- 이상하게 만든 취업합격률 곡선\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(-1,1)\nu = 0*x-3\nu[x&lt;-0.2] = (15*x+6)[x&lt;-0.2]\nu[(-0.2&lt;x)&(x&lt;0.4)] = (0*x-1)[(-0.2&lt;x)&(x&lt;0.4)]\nsig = torch.nn.Sigmoid()\nv = π = sig(u)\ny = torch.bernoulli(v)\n\n\nplt.plot(x,y,'.',alpha=0.03, label=\"observed\")\nplt.plot(x,v,'--', label=\"unobserved\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU())\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03, label=\"observed\")\nplt.plot(x,v, label=\"true\")\nplt.plot(x,net(x).data,'--', label=\"estimated\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\nB. 곡선은 표현 가능한가?\n- 2024년 수능 미적30번 문제에 나온 곡선\n\\[y_i = e^{-x_i} \\times  |\\cos(5x_i)| \\times \\sin(5x) + \\epsilon_i, \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\]\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\nplt.plot(x,y,label=\"observed\",alpha=0.5)\nplt.plot(x,fx,label=\"true\")\n\n\n\n\n\n\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048), # 꺽이지않은 1024개의 직선\n    torch.nn.ReLU(), # 꺽인(렐루된) 1024개의 직선 \n    torch.nn.Linear(2048,1), # 합쳐진 하나의 꺽인 직선 \n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n## \nfor epoc in range(1000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,label=\"observed\",alpha=0.5)\nplt.plot(x,fx,label=\"true\")\nplt.plot(x,net(x).data,'--',label=\"estimated\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n\n3. 시벤코 정리\n\nA. 시벤코 정리의 소개\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n모든 보렐 가측함수 (Borel measurable function)\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다. 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 신경망이 원하는 정확도로 근사시킨다는 의미이다. 예를들면 아래와 같은 문제를 해결할 수 있다.\n\n\\({\\bf X}_{n\\times 2}\\)는 토익점수, GPA 이고 \\({\\bf y}_{n\\times 1}\\)는 취업여부일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 신경망은 항상 찾을 수 있다.\n\\({\\bf X}_{n \\times p}\\)는 주택이미지, 지역정보, 주택면적, 주택에 대한 설명 이고 \\({\\bf y}_{n\\times 1}\\)는 주택가격일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 신경망은 항상 찾을 수 있다.\n\n즉 하나의 은닉층을 가진 신경망의 표현력은 거의 무한대라 볼 수 있다.\n\n\n보렐가측함수에 대한 정의는 측도론에 대한 이해가 있어야 가능함. 측도론에 대한 내용이 궁금하다면 https://guebin.github.io/SS2024/ 을 공부해보세요\n\n\n\nB. 시벤코정리가 가능한 이유\n- 준비\n\nx = torch.linspace(-10,10,200).reshape(-1,1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(in_features=2,out_features=1)\n)\nl1,a1,l2 = net\n\n\nnet\n\nSequential(\n  (0): Linear(in_features=1, out_features=2, bias=True)\n  (1): Sigmoid()\n  (2): Linear(in_features=2, out_features=1, bias=True)\n)\n\n\n- 생각1 : 2개의 시그모이드를 우연히 잘 조합하면 하나의 계단함수를 만들 수 있다\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+10.00,+10.00])\n\n\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\n\n\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x)[:,[0]].data,label=r\"$-5x+10$\")\nax[0].plot(x,l1(x)[:,[1]].data,label=r\"$5x+10$\")\nax[0].set_title('$l_1(x)$')\nax[0].legend()\nax[1].plot(x,a1(l1(x))[:,[0]].data,label=r\"$v_1=sig(-5x+10)$\")\nax[1].plot(x,a1(l1(x))[:,[1]].data,label=r\"$v_2=sig(5x+10)$\")\nax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[1].legend()\nax[2].plot(x,l2(a1(l1(x))).data,color='C2',label=r\"$v_1+v_2-1$\")\nax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$')\nax[2].legend()\n\n\n\n\n\n\n\n\n- 생각2 : 계단함수의 모양이 꼭 생각 1과 같을 필요는 없다. 중심은 이동가능하고, 높이도 조절가능하다.\n- 예시1\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+0.00,+20.00])\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C0'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C0'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C0'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n\n\n\n\n\n\n\n- 예시2\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+20.00,+00.00])\nl2.weight.data = torch.tensor([[2.50,2.50]])\nl2.bias.data = torch.tensor([-2.50])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C1'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C1'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C1'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n\n\n\n\n\n\n\n- 생각3 : out_features=4로 하고 가중치를 적당히 하면 \\((l_2\\circ a_1 \\circ l_1)(x)\\)의 결과로 생각2의 예시1,2를 조합한 형태도 가능할 것 같다. 즉 4개의 시그모이드를 잘 조합하면 2단계 계단함수를 만들 수 있다.\n\nl1 = torch.nn.Linear(in_features=1,out_features=4)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=4,out_features=1)\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00],[-5.00],[5.00]])\nl1.bias.data = torch.tensor([0.00, 20.00, 20.00, 0])\nl2.weight.data = torch.tensor([[1.00,  1.00, 2.50,  2.50]])\nl2.bias.data = torch.tensor([-1.0-2.5])\n\n\nplt.plot(l2(a1(l1(x))).data,'--')\nplt.title(r\"$(l_2 \\circ a_1 \\circ l_1)(x)$\")\n\nText(0.5, 1.0, '$(l_2 \\\\circ a_1 \\\\circ l_1)(x)$')\n\n\n\n\n\n\n\n\n\n- 일단 2단계 계단함수라고 부르기\n- 생각4 : 2m개의 시그모이드를 우연히 잘 조합하면 m단계 계단함수를 만들 수 있다\n- 정리1 : 2개의 시그모이드를 우연히 잘 결합하면 아래외같은 ‘1단계-계단함수’ h를 만들 수 있음\n\ndef h(x):\n    sig = torch.nn.Sigmoid()\n    v1 = -sig(200*(x-0.5))\n    v2 = sig(200*(x+0.5))\n    return v1+v2 \n\n\nplt.plot(x,h(x))\nplt.title(\"$h(x)$\")\n\nText(0.5, 1.0, '$h(x)$')\n\n\n\n\n\n\n\n\n\n- 정리2: 위와 같은 함수 \\(h\\)를 이용한 아래의 네트워크를 고려하자. 이는 “m단계-계단함수”를 만든다.\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n그리고 위의 네트워크와 동일한 효과를 주는 아래의 네트워크가 항상 존재\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,2m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n- 생각5 그런데 어지간한 함수형태는 구불구불한 “m단계-계단함수”로 다 근사할 수 있지 않을까?\n아래의 네트워크에서 (1) ?? 를 충분히 키우고 (2) 적절하게 학습만 잘 된다면\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n위의 네트워크는 거의 무한한 표현력을 가진다. –&gt; 이런식으로 증명가능\n\n\n\nC. \\(h\\)의 위력\n- 소망: 아래와 같이 net을 설계해서, 그 위력을 체감해보고 싶은데..\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,??),\n    torch.nn.H(),\n    torch.nn.Linear(??,1)\n)\n- \\(h(x)\\)를 생성하는 클래스를 만들어보자.\n\nclass H(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,x):\n        def h(x):\n            sig = torch.nn.Sigmoid()\n            v1 = -sig(200*(x-0.5))\n            v2 = sig(200*(x+0.5))\n            return v1+v2 \n        out = h(x)\n        return out \n\n\nh = H()\n\n- h를 이용해보자\n- 예제1 : 스펙의 역설\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    H(),\n    torch.nn.Linear(2048,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,prob)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n- 예제2 : 수능곡선\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(x,fx)\n\n\n\n\n\n\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    H(),\n    torch.nn.Linear(2048,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(x,fx)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n\n\nD.의문점\n- 그냥 활성함수 h로 쓰면 되는거 아닌가? 왜 relu를 쓰지?\n- 왜 딥러닝이 2010년 이후에 떴지?\n- 은닉층이 깊을 수록 좋은거 아닌가?\n\n\n5. MNIST 해결\n\n\nA. 예비학습 - plt.imshow()\n- plt.imshow(...,camp='gray') 에서 ...이 shape가 (??,??)이면 흑백이미지를 출력\n\nimg = torch.tensor([[255,100],\n                    [255,0]])\nplt.imshow(img,cmap=\"gray\")\n\n\n\n\n\n\n\n\n- plt.imshow(...) 에서 ...의 shape이 (??,??,3)이면 칼라이미지를 출력\n\nr = torch.tensor([[255,0],\n                  [255,0]])\ng = torch.tensor([[0,255],\n                  [0,0]])\nb = torch.tensor([[0,0],\n                  [0,255]])\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n- plt.imshow(...) 에서 ...의 자료형이 int인지 float인지에 따라서 인식이 다름\n\nr = torch.tensor([[1,0],\n                  [1,0]])\ng = torch.tensor([[0,1],\n                  [0,0]])\nb = torch.tensor([[0,0],\n                  [0,1]])\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\nr = torch.tensor([[255,0],\n                  [255,0]])/255\ng = torch.tensor([[0,255],\n                  [0,0]])/255\nb = torch.tensor([[0,0],\n                  [0,255]])/255\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n- 자료형이 float임\n\nimg\n\ntensor([[[1., 0., 0.],\n         [0., 1., 0.]],\n\n        [[1., 0., 0.],\n         [0., 0., 1.]]])\n\n\n\nB. 데이터\n- 데이터 정리코드\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX3 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==3])\nX7 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==7])\nX = torch.concat([X3,X7],axis=0)\ny = torch.tensor([0.0]*len(X3) + [1.0]*len(X7))\n\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n\n\n100%|████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:03&lt;00:00, 3058648.55it/s]\n\n\nExtracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n\n\n100%|█████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00&lt;00:00, 147469.10it/s]\n\n\nExtracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n\n\n100%|████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:01&lt;00:00, 1479955.21it/s]\n\n\nExtracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 404: Not Found\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n\n\n100%|██████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00&lt;00:00, 3940945.13it/s]\n\n\nExtracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\n\n\n\nplt.plot(y,'.')\n\n\n\n\n\n\n\n\n\nplt.imshow(X[0][0], cmap='gray')\n\n\n\n\n\n\n\n\n\nplt.imshow(X[-2].reshape(28,28),cmap='gray')\n\n\n\n\n\n\n\n\n- 우리는 \\({\\bf X}: (n,1,28,28)\\) 에서 \\({\\bf y}: (n,1)\\)으로 가는 맵핑을 배우고 싶음. \\(\\to\\) 이런건 배운적이 없는데?.. \\(\\to\\) 그렇다면 \\({\\bf X}:(n,784) \\to {\\bf y}:(n,1)\\) 으로 가는 맵핑을 학습하자.\n\n#X[0].reshape(-1)\n\n\nX = torch.stack([img.reshape(-1) for img in X])\ny = y.reshape(-1,1)\n\n\nX.shape,y.shape\n\n(torch.Size([12396, 784]), torch.Size([12396, 1]))\n\n\n\n\n\nC. 학습\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y,'.')\nplt.plot(net(X).data,'.',alpha=0.2)\n\n\n\n\n\n\n\n\n\n((y == (net(X).data &gt; 0.5))*1.0).mean()\n\ntensor(0.9901)"
  },
  {
    "objectID": "posts/4-1.신경망(로지스틱의한계극복).html",
    "href": "posts/4-1.신경망(로지스틱의한계극복).html",
    "title": "4-1. 신경망(로지스틱의 한계 극복)",
    "section": "",
    "text": "1. imports\n\nimport torch\nimport matplotlib.pyplot as plt \nimport pandas as pd\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n2. 꺽인 직선을 만드는 방법\n- 로지스틱의 한계를 극복하기 위해서는 시그모이드를 취하기 전 꺽인 그래프 모양을 만들어야함\n- 아래와 같은 벡터 \\(x\\)가정\n\nx = torch.linspace(-1,1,1001).reshape(-1,1)\nx\n\ntensor([[-1.0000],\n        [-0.9980],\n        [-0.9960],\n        ...,\n        [ 0.9960],\n        [ 0.9980],\n        [ 1.0000]])\n\n\n- 목표: 아래와 같은 벡터 \\({\\bf y}\\)를 만들어보자.\n\\[{\\bf y} = [y_1,y_2,\\dots,y_{n}]^\\top, \\quad y_i = \\begin{cases} 9x_i +4.5& x_i &lt;0 \\\\ -4.5x_i + 4.5& x_i &gt;0 \\end{cases}\\]\n- 방법1 수식 그대로 구현\n\nplt.plot(x,9*x+4.5,color=\"blue\",alpha=0.1)\nplt.plot(x[x&lt;0], (9*x+4.5)[x&lt;0],color=\"blue\")\nplt.plot(x,-4.5*x+4.5,color=\"orange\",alpha=0.1)\nplt.plot(x[x&gt;0], (-4.5*x+4.5)[x&gt;0],color=\"orange\")\n\n\n\n\n\n\n\n\n\ny = x*0\ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n- 방법2 ReLU 이용\n\nrelu = torch.nn.ReLU()\n#plt.plot(x,-4.5*relu(x),color=\"red\")\n#plt.plot(x,-9*relu(-x),color=\"blue\")\ny = -4.5*relu(x) + -9*relu(-x) + 4.5\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n- ReLU 중간과정\n\nfig = plt.figure(figsize=(6, 4))\nspec = fig.add_gridspec(4, 3)\nax1 = fig.add_subplot(spec[:2,0]); ax1.set_title(r'$x$'); ax1.set_ylim(-1,1)\nax2 = fig.add_subplot(spec[2:,0]); ax2.set_title(r'$-x$'); ax2.set_ylim(-1,1)\nax3 = fig.add_subplot(spec[:2,1]); ax3.set_title(r'$relu(x)$'); ax3.set_ylim(-1,1)\nax4 = fig.add_subplot(spec[2:,1]); ax4.set_title(r'$relu(-x)$'); ax4.set_ylim(-1,1)\nax5 = fig.add_subplot(spec[1:3,2]); ax5.set_title(r'$-4.5 relu(x)-9 relu(-x)+4.5$')\n#---#\nax1.plot(x,'--',color='C0')\nax2.plot(-x,'--',color='C1')\nax3.plot(relu(x),'--',color='C0')\nax4.plot(relu(-x),'--',color='C1')\nax5.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',color='C2')\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- 방법3 ReLU의 브로드캐스팅 화룡\n- 아래와 같은 아이디어로 y를 계산해도 된다.\n\nx, relu 준비\nu = [x -x]\nv = relu(u) = [relu(x), relu(-x)] = [v1 v2]\ny = -4.5*v1 + -9*v2 + 4.5\n\n\nu = torch.concat([x,-x],axis=1)\nv = relu(u)\nv1 = v[:,[0]]\nv2 = v[:,[1]]\ny = -4.5*v1 -9*v2 + 4.5 \nplt.plot(x,y)\n\n\n\n\n\n\n\n\n- 방법4 y=linr(v)\n\nx \nu = torch.concat([x,-x],axis=1)\nv = relu(u) \ny = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \nplt.plot(x,y)\n\n\n\n\n\n\n\n\n- 방법5u=linr(x)\n\nx \nu = x @ torch.tensor([[1.0, -1.0]])\nv = relu(u) \ny = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \n\n\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n- 방법6 torch.nn.Linear()를 이용\n\n# u = l1(x) # l1은 x-&gt;u인 선형변환: (n,1) -&gt; (n,2) 인 선형변환\nl1 = torch.nn.Linear(1,2,bias=False)\nl1.weight.data = torch.tensor([[1.0, -1.0]]).T \na1 = relu \nl2 = torch.nn.Linear(2,1,bias=True)\nl2.weight.data = torch.tensor([[-4.5],[-9]]).T \nl2.bias.data = torch.tensor([4.5])\n#---#\nx\nu = l1(x)\nv = a1(u) \ny = l2(v) \n\n\nplt.plot(x,y.data)\n\n\n\n\n\n\n\n\n\npwlinr = torch.nn.Sequential(l1,a1,l2)\nplt.plot(x,pwlinr(x).data)\n\n\n\n\n\n\n\n\n- 수식적 표현\n\nNote\n수식표현\n(1) \\({\\bf X}=\\begin{bmatrix} x_1 \\\\ \\dots \\\\ x_n \\end{bmatrix}\\)\n(2) \\(l_1({\\bf X})={\\bf X}{\\bf W}^{(1)}\\overset{bc}{+} {\\boldsymbol b}^{(1)}=\\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n\\end{bmatrix}\\)\n\n\\({\\bf W}^{(1)}=\\begin{bmatrix} 1 & -1 \\end{bmatrix}\\)\n\\({\\boldsymbol b}^{(1)}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}\\)\n\n(3) \\((a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big)=\\begin{bmatrix} \\text{relu}(x_1) & \\text{relu}(-x_1) \\\\ \\text{relu}(x_2) & \\text{relu}(-x_2) \\\\ \\dots & \\dots \\\\ \\text{relu}(x_n) & \\text{relu}(-x_n)\\end{bmatrix}\\)\n(4) \\((l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad=\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\\({\\bf W}^{(2)}=\\begin{bmatrix} -4.5 \\\\ -9 \\end{bmatrix}\\)\n\\(b^{(2)}=4.5\\)\n\n(5) \\(\\textup{pwlinr}({\\bf X})=(l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad =\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\n\n3. 스펙의 역설 적합\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\n\n\n\n\n\n\n\n\n- Step1에 대한 생각: 네트워크를 어떻게 만들까? = 아키텍처를 어떻게 만들까? = 모델링\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n\n\\(l_1\\): torch.nn.Linear(1,2,bias=False)\n\\(a_1\\): torch.nn.ReLU()\n\\(l_2\\): torch.nn.Linear(2,1,bias=True)\n\\(a_2\\): torch.nn.Sigmoid()\n\n- Step1-4\n\nnet[0].weight.data\n\ntensor([[ 0.5153],\n        [-0.4414]])\n\n\n\nnet[2].weight.data\n\ntensor([[-0.1371,  0.3319]])\n\n\n\nnet[0].weight.data\n\ntensor([[ 1.7773],\n        [-3.0447]])\n\n\n\nnet[2].weight.data\n\ntensor([[-0.9945, -2.7176]])\n\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2,bias=False),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2,1,bias=True),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## step1\n    yhat = net(x)\n    ## step2\n    loss = loss_fn(yhat,y)\n    ## step3\n    loss.backward()\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,yhat.data,'--')\n\n\n\n\n\n\n\n\n- 5000번 더 반복\n\nfor epoc in range(5000):\n    ## step1\n    yhat = net(x)\n    ## step2\n    loss = loss_fn(yhat,y)\n    ## step3\n    loss.backward()\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,yhat.data,'--')\n\n\n\n\n\n\n\n\n\na= (1.5,2,2)\n\n\nint(a[0])\n\n1"
  }
]