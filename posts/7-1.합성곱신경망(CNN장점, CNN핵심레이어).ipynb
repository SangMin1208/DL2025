{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9457c36b-4f54-46e2-a32e-e9cb4e2c7823",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"7-1. 합성곱신경망(CNN 장점, CNN 핵심 레이어)\"\n",
    "author: \"이상민\"\n",
    "date: \"05/1/2025\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a27118a-2489-4f74-9c7a-e3eff9f011a5",
   "metadata": {},
   "source": [
    "### 1. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7e1927-6106-40ec-b7aa-d6223fe24944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578a974d-7287-4dca-8a29-338799a93c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (4.5, 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9391d5-b2c9-4681-9c53-e3d8e4156b09",
   "metadata": {},
   "source": [
    "### 2. CNN 장점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382ffe9b-a22f-4002-93e8-e53ca18cb93b",
   "metadata": {},
   "source": [
    "#### A. 성능이 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ccd4dc-74e2-4734-b713-cb010c895b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=False)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=False)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, range(5000))\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, range(1000))\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "X = torch.stack([to_tensor(img) for img, lbl in train_dataset]).to(\"cuda:0\")\n",
    "y = torch.tensor([lbl for img, lbl in train_dataset])\n",
    "y = torch.nn.functional.one_hot(y).float().to(\"cuda:0\")\n",
    "XX = torch.stack([to_tensor(img) for img, lbl in test_dataset]).to(\"cuda:0\")\n",
    "yy = torch.tensor([lbl for img, lbl in test_dataset])\n",
    "yy = torch.nn.functional.one_hot(yy).float().to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03583c78-b893-44db-b148-1595b7d19fe6",
   "metadata": {},
   "source": [
    "`-` 발악수준으로 설계한 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23f8d8f9-1692-4c3b-957a-4f028b7aa08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,2048),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2048,10)\n",
    ").to(\"cuda\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc510a3-5e51-4907-881f-a967a453d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(1,500):\n",
    "    #1\n",
    "    logits = net(X)\n",
    "    #2\n",
    "    loss = loss_fn(logits, y) \n",
    "    #3\n",
    "    loss.backward()\n",
    "    #4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ffccba-98a9-4a5e-be7f-c92f4a23bf48",
   "metadata": {},
   "source": [
    "`-` 과적합의 끝판왕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef8dc28e-738a-47d1-ab81-bc66c4f0fa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33f80419-4896-4c92-a73f-0ce81942fae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8530, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136c016-55f7-4ba1-b874-9e177b33deaf",
   "metadata": {},
   "source": [
    "`-` **대충대충 설계한 합성곱신경망**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e248e30-c939-4c89-bf25-d28bf674a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1,16,2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(2704,10),\n",
    ").to(\"cuda\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b9c54f-b345-4491-81ac-ac8c52a71ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(1,500):\n",
    "    #1\n",
    "    logits = net(X)\n",
    "    #2\n",
    "    loss = loss_fn(logits, y) \n",
    "    #3\n",
    "    loss.backward()\n",
    "    #4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c10594fa-7ca3-4e6b-84a9-9f7260b13d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9666, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b454fba-0827-40d3-9e69-184f0ff159ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8710, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc85f8-e8a5-4a58-ab9b-49a76c0b0fb6",
   "metadata": {},
   "source": [
    "#### B. 파라메터가 적음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cb2da75-9a6a-4243-8c48-a4a678b8c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,2048),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2048,10)\n",
    ")\n",
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1,16,2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(2704,10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cef88925-b482-4440-93b7-2070677ca253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 784])\n",
      "torch.Size([2048])\n",
      "torch.Size([10, 2048])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "net1_params = list(net1.parameters())\n",
    "print(net1_params[0].shape)\n",
    "print(net1_params[1].shape)\n",
    "print(net1_params[2].shape)\n",
    "print(net1_params[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d7dbae8-8db8-41f1-9f09-3701c8cec984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1628170"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2048*784 + 2048 + 2048*10 +10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0fbead3-08dd-416b-8436-02dffd9f91d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 2, 2])\n",
      "torch.Size([16])\n",
      "torch.Size([10, 2704])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "net2_params = list(net2.parameters())\n",
    "print(net2_params[0].shape)\n",
    "print(net2_params[1].shape)\n",
    "print(net2_params[2].shape)\n",
    "print(net2_params[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5fdb646-b63e-4d41-abc5-9de65a9d53f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27130"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*1*2*2 + 16 + 10*2704 + 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b9cd9e-536f-423a-b7e2-dd005335cba8",
   "metadata": {},
   "source": [
    "`-` net1 의 1.6퍼밖에 안됨.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe591c72-3acd-43df-93bf-dcd0f193350c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01666287918337766"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27130/1628170"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9c6002-7484-4768-a816-63ecd603d792",
   "metadata": {},
   "source": [
    "#### C. 유명함\n",
    "\n",
    "`-` 딥러닝이 있게함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6881ad26-b4b2-4a98-9137-53986a98a1f7",
   "metadata": {},
   "source": [
    "### 3. CNN 핵심 레이어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d97c0-4b9d-41eb-a5c0-736be3621ade",
   "metadata": {},
   "source": [
    "#### A. `torch.nn.ReLU`\n",
    "\n",
    "`-` (예시1) 연산방법 : 음수를 0으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64737bee-bf9b-4e4f-8b4d-10074dbabe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(1,1,4,4) # (4,4) 흑백이미지 한장\n",
    "relu = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a2576cc-40f1-4808-a083-ea46e14c71b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.4381,  0.2449, -0.6420,  2.6874],\n",
       "          [ 0.7790,  1.0558,  0.7939,  0.1099],\n",
       "          [ 0.3492,  1.7610,  1.6032,  2.4212],\n",
       "          [ 0.5416, -0.2153, -1.2772,  0.6885]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d34dff31-8301-4b93-aa78-ec8c145dd36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.4381, 0.2449, 0.0000, 2.6874],\n",
       "          [0.7790, 1.0558, 0.7939, 0.1099],\n",
       "          [0.3492, 1.7610, 1.6032, 2.4212],\n",
       "          [0.5416, 0.0000, 0.0000, 0.6885]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a27ee-f1e8-4f90-bba2-41188b01b303",
   "metadata": {},
   "source": [
    "#### B. `torch.nn.MaxPool2d`\n",
    "\n",
    "`-` (예시1) 연산방법, kernel_size 의 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "559d31da-fea0-407f-96ee-29493422cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1,1,4,4)\n",
    "mp = torch.nn.MaxPool2d(kernel_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38507d45-d952-4ef2-bba9-148baf6adf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8921, 0.4222, 0.5778, 0.2707],\n",
       "          [0.6921, 0.5627, 0.5356, 0.1048],\n",
       "          [0.5356, 0.7699, 0.9047, 0.5911],\n",
       "          [0.3617, 0.5345, 0.1218, 0.4772]]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd482fa5-46e8-46a1-a202-b863525170f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8921, 0.5778],\n",
       "          [0.7699, 0.9047]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1525b534-ed9b-4635-9a77-2b772c661694",
   "metadata": {},
   "source": [
    "`-` (예시2) 이미지 크기와 딱 맞지않는 커널일 경우?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb6a28df-498a-45c9-9480-04860fe41bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1,1,5,5)\n",
    "mp = torch.nn.MaxPool2d(kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bfdbe31-93d0-4662-9743-1def4ca2e23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9560, 0.4947, 0.1591, 0.2606, 0.9130],\n",
       "          [0.0603, 0.1255, 0.6520, 0.2504, 0.8759],\n",
       "          [0.7544, 0.5927, 0.5319, 0.2390, 0.2883],\n",
       "          [0.9470, 0.8519, 0.3501, 0.0725, 0.3881],\n",
       "          [0.7203, 0.0753, 0.8360, 0.1287, 0.9515]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c786440-7f58-4216-ab62-48c03019a73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9560]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b0630-34d6-4a5e-867e-dfc849214edd",
   "metadata": {},
   "source": [
    "`-` (예시3) 정사각형이 아닌 커널"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b20c9ee-b165-41f6-bfbc-7d705a7500dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1,1,4,4)\n",
    "mp = torch.nn.MaxPool2d(kernel_size=(4,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0e6b4ee-8dd9-4183-9ab4-03bdbad96ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4283, 0.9998, 0.3532, 0.3085],\n",
       "          [0.3278, 0.8575, 0.3331, 0.9769],\n",
       "          [0.0239, 0.2457, 0.8468, 0.8224],\n",
       "          [0.9593, 0.1292, 0.5930, 0.3652]]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbaad13c-dfe5-428c-a142-b40d03cd549e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9998, 0.9769]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de90ea2-4592-42ce-be02-7a3cf2d59e13",
   "metadata": {},
   "source": [
    "#### C. `torch.nn.Conv2d`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2486e20a-c371-4d53-b98a-25c502bddf76",
   "metadata": {},
   "source": [
    "`-`(예시1) 연산방법, stride=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85213799-ce19-4f20-9bef-7f8e0177193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1,1,4,4)\n",
    "conv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6ed8862-9bea-46ee-bd9c-3506af1cf5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n",
       "          [0.1166, 0.8762, 0.9373, 0.8573],\n",
       "          [0.5778, 0.8702, 0.9686, 0.5854],\n",
       "          [0.1373, 0.3530, 0.0529, 0.0139]]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a671e220-935d-405a-ab5c-f32b3a0dbb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1106, -0.1898],\n",
       "          [ 0.0529, -0.0976]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bdf288-88ce-48ae-9cd6-fcfb3b5a2c50",
   "metadata": {},
   "source": [
    "`-` 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6321561-668f-4fc4-b85d-89f8bc7e79ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.0218,  0.2400],\n",
       "           [-0.4914,  0.3394]]]]),\n",
       " tensor([-0.1958]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.data, conv.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1155e163-71cf-4379-9b5e-576e028619c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1106]),\n",
       " tensor([[[[ 0.1106, -0.1898],\n",
       "           [ 0.0529, -0.0976]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:,  :,  :2,  :2] * conv.weight.data).sum()+conv.bias.data, conv(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc9e0966-613f-474b-8386-b77e8d5b0466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.1898]),\n",
       " tensor([[[[ 0.1106, -0.1898],\n",
       "           [ 0.0529, -0.0976]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:,  :,  :2,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "017af55d-2682-4f3b-9384-6493eb87e100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0529]),\n",
       " tensor([[[[ 0.1106, -0.1898],\n",
       "           [ 0.0529, -0.0976]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:,  :,  2:,  :2] * conv.weight.data).sum()+conv.bias.data, conv(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14b9af85-778e-40f3-bee1-f68cb21d70b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0976]),\n",
       " tensor([[[[ 0.1106, -0.1898],\n",
       "           [ 0.0529, -0.0976]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:,  :,  2:,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
